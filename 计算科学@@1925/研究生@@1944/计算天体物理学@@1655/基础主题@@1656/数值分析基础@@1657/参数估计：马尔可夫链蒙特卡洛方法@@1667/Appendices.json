{"hands_on_practices": [{"introduction": "Metropolis-Hastings 算法是 MCMC 方法的核心，其精髓在于决定是接受还是拒绝一个新提议的状态。本练习将此关键步骤独立出来，让你能够直接应用接受概率公式。通过为一个给定的移动计算概率，你将具体理解算法如何平衡提议状态的后验可能性与提议分布的属性，以确保马尔可夫链正确地对目标分布进行采样 [@problem_id:3478680]。", "problem": "一个数值宇宙学流程（pipeline）使用Ia型超新星和宇宙微波背景摘要统计量，对一个平坦的$\\Lambda$冷暗物质模型进行贝叶斯参数推断。该流程通过Metropolis–Hastings马尔可夫链蒙特卡洛（MCMC）转移对后验分布$\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\sigma_{8}, H_{0})$进行采样，该转移强制执行关于后验密度$\\pi(\\boldsymbol{\\theta}) \\propto \\mathcal{L}(\\mathbf{d} \\mid \\boldsymbol{\\theta})\\,p(\\boldsymbol{\\theta})$的细致平衡，并使用一个通常非对称的提议密度$q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})$。在某一次迭代中，从当前状态$\\boldsymbol{\\theta}$到提议状态$\\boldsymbol{\\theta}'$，代码计算出的后验密度比为$\\pi(\\boldsymbol{\\theta}')/\\pi(\\boldsymbol{\\theta}) = 10$，提议密度比为$q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')/q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta}) = 2$。\n\n从针对$\\pi(\\boldsymbol{\\theta})$的马尔可夫链的细致平衡基本要求出发，并根据Metropolis–Hastings转移核由提议函数和接受函数定义的规则，确定此次移动的Metropolis–Hastings接受概率$\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}')$。然后，在宇宙学参数采样的背景下，解释这个值对此步骤中链的行为意味着什么。请以纯数形式提供接受概率，无需四舍五入。", "solution": "首先对问题进行严格的验证过程。\n\n### 步骤 1：提取已知条件\n问题陈述中明确提供了以下数据和定义：\n- **模型：** 平坦$\\Lambda$冷暗物质（$\\Lambda$CDM）模型。\n- **关注参数：** $\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\sigma_{8}, H_{0})$。\n- **推断方法：** Metropolis–Hastings马尔可夫链蒙特卡洛（MCMC）。\n- **目标概率密度：** 后验密度 $\\pi(\\boldsymbol{\\theta}) \\propto \\mathcal{L}(\\mathbf{d} \\mid \\boldsymbol{\\theta})\\,p(\\boldsymbol{\\theta})$，其中$\\mathcal{L}$是似然， $p$是先验。\n- **提议密度：** 一个通常非对称的密度，$q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})$。\n- **核心原则：** MCMC转移强制执行关于$\\pi(\\boldsymbol{\\theta})$的细致平衡。\n- **在从状态$\\boldsymbol{\\theta}$到$\\boldsymbol{\\theta}'$的某次特定迭代中：**\n    - 后验密度比为 $\\frac{\\pi(\\boldsymbol{\\theta}')}{\\pi(\\boldsymbol{\\theta})} = 10$。\n    - 提议密度比为 $\\frac{q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')}{q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})} = 2$。\n- **目标：** 确定Metropolis–Hastings接受概率$\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}')$并解释其含义。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据既定标准评估问题的有效性。\n- **科学基础：** 该问题牢固地植根于贝叶斯统计推断和计算物理学的标准理论框架中。Metropolis-Hastings算法是MCMC方法的一个基石，其在宇宙学参数估计（特别是$\\Lambda$CDM模型）中的应用是该领域一项常规且基础的任务。所有概念——后验密度、似然、先验、提议密度、细致平衡以及参数$\\Omega_{\\mathrm{m}}$、$\\sigma_{8}$、$H_{0}$——都是标准的且定义明确。\n- **良态问题：** 该问题提供了计算接受概率所需的所有必要信息。从给定的比率出发，Metropolis-Hastings接受规则的定义可以导出一个唯一且稳定的解。\n- **客观性：** 语言技术性强、精确，没有任何主观性、模糊性或意见。\n\n该问题没有表现出任何列出的无效性缺陷。它在科学上是合理的，可以直接形式化，是完整的，描述了一个计算上现实的场景，并且结构良好。\n\n### 步骤 3：结论与行动\n问题被判定为**有效**。将提供完整解答。\n\n### 解答推导\n马尔可夫链具有平稳分布$\\pi(\\boldsymbol{\\theta})$的基本要求是细致平衡条件。对于任意两个状态$\\boldsymbol{\\theta}$和$\\boldsymbol{\\theta}'$，细致平衡要求当链处于其平稳状态时，从$\\boldsymbol{\\theta}$转移到$\\boldsymbol{\\theta}'$的速率等于从$\\boldsymbol{\\theta}'$转移到$\\boldsymbol{\\theta}$的速率。这在数学上表示为：\n$$\n\\pi(\\boldsymbol{\\theta}) P(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta}) = \\pi(\\boldsymbol{\\theta}') P(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')\n$$\n其中$P(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})$是从状态$\\boldsymbol{\\theta}$移动到状态$\\boldsymbol{\\theta}'$的转移概率（或核）。\n\n在Metropolis–Hastings算法中，转移是一个两步过程：提议一个新状态，然后接受或拒绝它。从$\\boldsymbol{\\theta}$移动到不同状态$\\boldsymbol{\\theta}'$的转移概率是提议$\\boldsymbol{\\theta}'$的概率与接受它的概率的乘积：\n$$\nP(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta}) = q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta}) \\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') \\quad \\text{for } \\boldsymbol{\\theta} \\neq \\boldsymbol{\\theta}'\n$$\n其中$q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})$是提议密度，$\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}')$是接受概率。\n\n将这种形式的转移核代入细致平衡方程，得到：\n$$\n\\pi(\\boldsymbol{\\theta}) q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta}) \\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = \\pi(\\boldsymbol{\\theta}') q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}') \\alpha(\\boldsymbol{\\theta}', \\boldsymbol{\\theta})\n$$\n这个方程可以重新排列，以显示接受概率必须满足的关系：\n$$\n\\frac{\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}')}{\\alpha(\\boldsymbol{\\theta}', \\boldsymbol{\\theta})} = \\frac{\\pi(\\boldsymbol{\\theta}')}{\\pi(\\boldsymbol{\\theta})} \\frac{q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')}{q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})}\n$$\n在Metropolis–Hastings算法中，满足此条件同时最大化接受率的接受概率标准选择是：\n$$\n\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = \\min \\left( 1, \\frac{\\pi(\\boldsymbol{\\theta}')}{\\pi(\\boldsymbol{\\theta})} \\frac{q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')}{q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})} \\right)\n$$\n问题提供了最小函数内部两个比率的数值。\n后验密度比给定为：\n$$\n\\frac{\\pi(\\boldsymbol{\\theta}')}{\\pi(\\boldsymbol{\\theta})} = 10\n$$\n提议密度比，也称为Hastings修正因子，给定为：\n$$\n\\frac{q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')}{q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})} = 2\n$$\n我们将这些值代入接受概率的公式中：\n$$\n\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = \\min \\left( 1, (10) \\times (2) \\right)\n$$\n$$\n\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = \\min(1, 20)\n$$\n计算该最小函数的值，得到：\n$$\n\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = 1\n$$\n### 解释\n计算出的接受概率为$\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = 1$。这意味着从当前状态$\\boldsymbol{\\theta}$到新状态$\\boldsymbol{\\theta}'$的提议移动被确定性地接受。\n\n在宇宙学参数采样的背景下，这是此步骤中一个非常理想的结果。链在参数空间$\\{ \\Omega_{\\mathrm{m}}, \\sigma_{8}, H_{0} \\}$中找到了一个新点$\\boldsymbol{\\theta}'$，其后验概率密度是当前点$\\boldsymbol{\\theta}$的10倍。这表明提议的这组宇宙学参数能更好地拟合Ia型超新星和CMB的组合数据（由似然$\\mathcal{L}$捕获），和/或更受编码在$p(\\boldsymbol{\\theta})$中的先验知识的青睐。\n\n尽管如Hastings因子2所示，提议分布使得正向移动（$\\boldsymbol{\\theta} \\to \\boldsymbol{\\theta}'$）的概率是反向移动（$\\boldsymbol{\\theta}' \\to \\boldsymbol{\\theta}$）的一半，但后验密度的巨大改进压倒性地支持接受新状态。采样器正在高效地“攀登”后验概率景观的山丘，积极地向包含最可能宇宙学参数值的最高概率区域移动。接受这一移动确保了链能够有效地探索并收敛到真实的后验分布。", "answer": "$$\n\\boxed{1}\n$$", "id": "3478680"}, {"introduction": "一次成功的 MCMC 模拟不仅需要接受步进，更要求对整个参数空间进行有效探索。一个极高的接受率可能是一个欺骗性的指标，它常常掩盖了一个混合不佳的低效采样器。本练习让你诊断这个常见问题，迫使你批判性地思考提议步长、接受率和链的自相关性之间的关系，这是有效调节任何 MCMC 采样器的关键技能 [@problem_id:2442846]。", "problem": "您正在使用马尔可夫链蒙特卡洛（MCMC）方案中的Metropolis–Hastings算法，为一个动态随机一般均衡（DSGE）资产定价模型校准一个$k$维参数矢量$\\theta \\in \\mathbb{R}^k$的后验分布$\\pi(\\theta \\mid \\mathcal{D})$。您采用一个随机游走高斯提议分布$q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\sigma^2 I_k)$，其中标量调整参数$\\sigma  0$，并使用标准的Metropolis-Hastings接受/拒绝步骤。在仔细编码和预烧（burn-in）后，您观察到持续的经验接受率超过$95\\%$。哪种解释最能说明为何如此高的接受率通常表明马尔可夫链混合得不好（mixing poorly）且对状态空间的探索过慢？\n\nA. 高接受率意味着目标密度$\\pi(\\theta \\mid \\mathcal{D})$几乎是平坦的，因此来自$q(\\theta' \\mid \\theta)$的提议几乎独立于当前状态，从而保证了快速探索。\n\nB. 高接受率通常是$\\sigma$过小的症状，因此提议的移动$\\theta' - \\theta$非常短；尽管大多数移动被接受，但链执行的是具有高自相关的缓慢局部随机游走，导致对$\\mathbb{R}^k$的探索不充分。\n\nC. 高接受率确保了连续的抽样近似独立，因为拒绝很少发生，所以混合必然很快。\n\nD. 高接受率意味着Metropolis–Hastings接受规则通过拒绝几乎所有尾部提议，将链集中在后验众数附近，这会困住链并减慢探索速度。", "solution": "在尝试解答之前，对问题陈述进行验证。\n\n### 第1步：提取已知信息\n- 目标分布是一个$k$维参数矢量$\\theta \\in \\mathbb{R}^k$的后验分布$\\pi(\\theta \\mid \\mathcal{D})$。\n- 模型是一个动态随机一般均衡（DSGE）资产定价模型。\n- 算法是马尔可夫链蒙特卡洛（MCMC）框架内的Metropolis-Hastings（MH）算法。\n- 提议分布是随机游走高斯分布：$q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\sigma^2 I_k)$，其中$\\sigma  0$是一个标量调整参数，$I_k$是$k \\times k$的单位矩阵。\n- 观察到的经验接受率持续高于$95\\%$。\n- 问题是要找出最佳解释，说明为什么这个非常高的接受率表明链的混合性差且对状态空间的探索缓慢。\n\n### 第2步：使用提取的已知信息进行验证\n- **科学基础：** 该问题牢固地植根于贝叶斯计算的理论和实践中。Metropolis-Hastings算法是MCMC方法的基石，其在DSGE模型参数估计中的应用是计算经济学和计量经济学中的标准程序。提议方差、接受率和链效率（混合性）之间的关系是MCMC诊断中一个基础且被充分研究的课题。\n- **良态问题：** 该问题是良态的。它描述了在调整MCMC采样器时遇到的一个常见场景，并要求给出正确的理论解释。概念定义明确，并且在统计文献中存在一个单一的标准解释。\n- **客观性：** 问题以精确、客观和技术性的语言陈述，没有歧义或主观性陈述。\n\n### 第3步：结论与行动\n问题陈述是有效的。这是一个关于Metropolis-Hastings算法诊断的标准问题。将推导解答。\n\nMetropolis-Hastings算法的核心是从状态$\\theta$移动到新状态$\\theta'$的接受概率。这个概率由下式给出：\n$$\n\\alpha(\\theta', \\theta) = \\min\\left(1, \\frac{\\pi(\\theta' \\mid \\mathcal{D})q(\\theta \\mid \\theta')}{\\pi(\\theta \\mid \\mathcal{D})q(\\theta' \\mid \\theta)}\\right)\n$$\n在这个问题中，提议分布是对称的随机游走高斯分布，$q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\sigma^2 I_k)$。高斯概率密度函数的一个关键性质是它对其参数是对称的，这意味着从$\\theta$开始抽到$\\theta'$的密度与从$\\theta'$开始抽到$\\theta$的密度相同。形式上，$q(\\theta' \\mid \\theta) = q(\\theta \\mid \\theta')$。因此，提议密度的比率被抵消，接受概率简化为Metropolis规则：\n$$\n\\alpha(\\theta', \\theta) = \\min\\left(1, \\frac{\\pi(\\theta' \\mid \\mathcal{D})}{\\pi(\\theta \\mid \\mathcal{D})}\\right)\n$$\n经验接受率超过$95\\%$意味着对于绝大多数提议的步骤，移动都被接受了。这意味着$\\alpha(\\theta', \\theta)$非常频繁地接近$1$。根据公式，这发生在比率$\\frac{\\pi(\\theta' \\mid \\mathcal{D})}{\\pi(\\theta \\mid \\mathcal{D})}$通常大于或等于$1$时。这个条件，$\\pi(\\theta' \\mid \\mathcal{D}) \\approx \\pi(\\theta \\mid \\mathcal{D})$或$\\pi(\\theta' \\mid \\mathcal{D})  \\pi(\\theta \\mid \\mathcal{D})$，最常在提议$\\theta'$非常接近当前状态$\\theta$时得到满足。\n\n提议机制是$\\theta' \\sim \\mathcal{N}(\\theta, \\sigma^2 I_k)$，可以写成$\\theta' = \\theta + \\epsilon$，其中扰动$\\epsilon$从零均值高斯分布中抽取，$\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_k)$。步骤的典型幅度$\\|\\theta' - \\theta\\| = \\|\\epsilon\\|$由提议分布的标准差控制，它与标量调整参数$\\sigma$成正比。\n\n如果选择的$\\sigma$非常小，提议的步骤將非常短。新状态$\\theta'$將位于当前状态$\\theta$的一个极小邻域内。对于任何足够连续的目标密度$\\pi(\\cdot)$，如果$\\theta'$非常接近$\\theta$，那么它们的密度值也将非常接近，即$\\pi(\\theta' \\mid \\mathcal{D}) \\approx \\pi(\\theta \\mid \\mathcal{D})$。这使得比率$\\frac{\\pi(\\theta' \\mid \\mathcal{D})}{\\pi(\\theta \\mid \\mathcal{D})}$非常接近$1$，从而导致非常高的接受率。\n\n因此，超过$95\\%$的接受率是调整参数$\\sigma$过小的典型症状。\n\n这样做的后果是采样器性能不佳。虽然几乎每一步都被接受，但步长极小。链通过非常小、犹豫的步骤来探索参数空间$\\mathbb{R}^k$，实际上是在执行一个缓慢的随机游走。这意味着链需要极大量的迭代才能遍历后验分布$\\pi(\\theta \\mid \\mathcal{D})$的高概率区域。链中的连续样本$\\theta_t$和$\\theta_{t+1}$将高度相关。高自相关性就是混合性差的定义。缓慢的探索和差的混合性意味着采样器效率低下，除非链运行一个不切实际的长的时间，否则产生的样本不能很好地代表整个后验分布。\n\n现在，我们基于这个推理来评估每个选项。\n\n**A. 高接受率意味着目标密度$\\pi(\\theta \\mid \\mathcal{D})$几乎是平坦的，因此来自$q(\\theta' \\mid \\theta)$的提议几乎独立于当前状态，从而保证了快速探索。**\n这个陈述是不正确的。高接受率并不意味着目标密度全局平坦；它意味着提议是如此局部，以至于在所采取的小步骤上密度*看起来*是平坦的。提议$q(\\theta' \\mid \\theta)$以当前状态$\\theta$为中心，因此从根本上依赖于它。由于步长小而导致的高接受率会导致缓慢而非快速的探索。这个选项是一连串的错误。**不正确**。\n\n**B. 高接受率通常是$\\sigma$过小的症状，因此提议的移动$\\theta' - \\theta$非常短；尽管大多数移动被接受，但链执行的是具有高自相关的缓慢局部随机游走，导致对$\\mathbb{R}^k$的探索不充分。**\n这个陈述准确地诊断了情况。它正确地将高接受率与小的提议方差（小的$\\sigma$）联系起来，指出了其后果是短移动，并正确地将由此产生的动态描述为具有高自相关的缓慢局部随机游走，这与探索不充分是同义词。这与已建立的MCMC诊断理论完全一致。**正确**。\n\n**C. 高接受率确保了连续的抽样近似独立，因为拒绝很少发生，所以混合必然很快。**\n这根本上是错误的。当由小步长引起高接受率时，它确保了连续的抽样是高度*依赖*（相关）的，而不是独立的。如果从一个非常接近$\\theta_t$的提议$\\theta'$中接受了$\\theta_{t+1}$，那么$\\theta_{t+1} \\approx \\theta_t$。这是独立性的对立面，意味着混合性差、速度慢。**不正确**。\n\n**D. 高接受率意味着Metropolis–Hastings接受规则通过拒绝几乎所有尾部提议，将链集中在后验众数附近，这会困住链并减慢探索速度。**\n这个陈述是自相矛盾的。“非常高的接受率”意味着提议几乎总是被*接受*，而不是被*拒绝*。一个非常*低*的接受率才意味着大多数提议被拒绝。这种低接受率通常发生在$\\sigma$过大时，导致提议频繁地落在分布的低密度尾部，从而被拒绝。这个选项中描述的机制与高接受率的前提在事实上是不一致的。**不正确**。", "answer": "$$\\boxed{B}$$", "id": "2442846"}, {"introduction": "现代 MCMC 方法通常会动态地调整提议分布以提高效率，但这种调整必须谨慎进行，以确保采样器仍能收敛到正确的后验分布。这个动手编程挑战将带你从理论走向实践，要求你实现一个自适应算法，并验证其保证正确性的关键理论条件，例如递减适应性和约束性。成功完成此练习将为你提供构建和验证用于解决真实世界天体物理问题的、稳健的、先进的 MCMC 采样器所需的实践技能 [@problem_id:3528600]。", "problem": "考虑一个自适应随机游走 Metropolis 算法，该算法用于一个双参数天体物理模型中每个能量箱光子计数的参数推断。设未知参数矢量为 $\\theta = (\\log A, \\gamma)$，其中 $A$ 是在枢轴能量 $E_0$ 处的正流量归一化（任意单位），$\\gamma$ 是幂律模型中的谱指数。观测数据由能量箱中独立的的光子计数 $k_i$ 组成，其中心能量为 $E_i$，曝光时间为 $T_i$。模型假设 $k_i \\sim \\text{Poisson}(\\lambda_i)$，其中 $\\lambda_i = A \\, T_i \\, (E_i/E_0)^{-\\gamma}$。假设 $\\log A$ 和 $\\gamma$ 的高斯先验在各分量上是独立的。\n\n马尔可夫链蒙特卡洛（MCMC）链是通过随机游走 Metropolis 转移构建的，其提议为 $\\theta' = \\theta + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, C_t)$，$C_t$ 是一个依赖于自适应、由迭代索引的提议协方差。设后验密度为 $\\pi(\\theta)$，在迭代 $t$ 时的时齐非均匀马尔可夫转移核为 $K_t(\\theta, \\cdot)$，该核由 $C_t$ 驱动的随机游走 Metropolis 接受准则定义。\n\n自适应 MCMC 理论断言，在满足诸如递减自适应和包含性等条件下，可以保证收敛到目标 $\\pi(\\theta)$。使用以下基本依据：\n\n- 马尔可夫转移核 $K_t$ 的定义以及基于 Metropolis-Hastings 准则的随机游走 Metropolis 算法的接受概率。\n- 独立计数的泊松似然，$P(k_i \\mid \\lambda_i) = \\frac{\\lambda_i^{k_i} e^{-\\lambda_i}}{k_i!}$，以及 $\\log A$ 和 $\\gamma$ 的独立高斯先验。\n- 递减自适应的定义：$\\lim_{t \\to \\infty} \\sup_{\\theta} \\lVert K_{t+1}(\\theta, \\cdot) - K_t(\\theta, \\cdot) \\rVert = 0$，在操作上通过监测提议协方差矩阵 $C_t$ 的稳定性来解释。\n- 包含性的概念：自适应过程保持在漂移和次要化条件一致成立的区域内，在操作上通过限制参数轨迹并将提议协方差特征值保持在有界范围内来解释。\n\n您的任务是实现一个确定性模拟，在一个现实的天体物理推断问题上操作性地测试这些条件。使用以下固定的数据和先验：\n\n- 能量箱中心（单位：$\\text{keV}$）：$E = [\\,0.5,\\, 1.0,\\, 2.0,\\, 5.0\\,]$。\n- 曝光时间（单位：$\\text{s}$）：$T = [\\,10000,\\, 10000,\\, 10000,\\, 10000\\,]$。\n- 枢轴能量：$E_0 = 1.0$。\n- 观测到的计数：$k = [\\,80,\\, 20,\\, 5,\\, 1\\,]$。\n- $\\log A$ 的先验：$\\log A \\sim \\mathcal{N}(\\mu_A, \\sigma_A^2)$，其中 $\\mu_A = \\log(0.002)$，$\\sigma_A = 1.0$。\n- $\\gamma$ 的先验：$\\gamma \\sim \\mathcal{N}(\\mu_\\gamma, \\sigma_\\gamma^2)$，其中 $\\mu_\\gamma = 2.0$，$\\sigma_\\gamma = 1.0$。\n\n实现一个自适应随机游走 Metropolis 算法，该算法使用数值稳定的更新方法（例如，在线协方差更新）来维护链的经验协方差 $\\Sigma_t$ 的在线估计，并定义 $C_t = s_t^2 \\, (\\Sigma_t + \\varepsilon I)$，其中 $\\varepsilon  0$ 是一个小的稳定项。基础缩放因子 $s_t$ 及其演化将根据下面指定的测试案例而有所不同。\n\n定义以下操作诊断：\n\n- 递减自适应诊断：计算提议协方差随时间的相对变化，\n$$\nr_t = \\frac{\\lVert C_t - C_{t-1} \\rVert_F}{\\max\\{\\lVert C_{t-1} \\rVert_F, \\delta\\}},\n$$\n其中 $\\lVert \\cdot \\rVert_F$ 是弗罗贝尼乌斯范数，$\\delta  0$ 是一个小的稳定项。在老化期（burn-in）之后，对于最后 $L$ 次迭代的滑动窗口，如果该窗口内 $r_t$ 的平均值小于一个固定的阈值 $\\epsilon_{\\text{dim}}$，则报告递减自适应条件成立。\n- 包含性诊断：在整个运行过程中监测最大特征值 $\\lambda_{\\max}(C_t)$ 和欧几里得范数 $\\lVert \\theta_t \\rVert_2$；如果 $\\max_t \\lambda_{\\max}(C_t) \\leq V_{\\max}$ 且 $\\max_t \\lVert \\theta_t \\rVert_2 \\leq R_{\\max}$，则报告包含性条件成立。\n\n使用以下用于诊断和算法的超参数，这些参数不可更改：\n\n- 维度 $d = 2$，老化期迭代次数 $N_{\\text{burn}} = 1000$，总迭代次数 $N = 4000$，滑动窗口 $L = 500$，稳定项 $\\varepsilon = 10^{-6}$ 和 $\\delta = 10^{-12}$，基础提议缩放因子 $s_{\\text{base}} = (2.38)^2 / d$，递减阈值 $\\epsilon_{\\text{dim}} = 0.2$，包含性界限 $V_{\\max} = 100.0$ 和 $R_{\\max} = 50.0$。\n- 初始状态：$\\theta_0 = (\\log(0.02), 0.5)$。\n\n在以下三个测试案例上运行算法，每个案例定义了老化期后 $s_t$ 的缩放适应规则：\n\n- 案例 A（旨在满足两个条件）：对所有 $t$，$s_t = s_{\\text{base}}$；自适应仅来自经验协方差 $\\Sigma_t$，它使用样本间的均等权重进行在线更新，因此其增量变化随 $t$ 增加而减少。\n- 案例 B（旨在违反递减自适应）：对于 $t  N_{\\text{burn}}$，每隔 $P$ 次迭代（$P=50$），交替地将 $s_t$ 乘以 $f$ 和 $1/f$，其中 $f=3.0$（即，在交替的更新时刻，$s_t \\leftarrow f \\, s_t$ 然后 $s_t \\leftarrow s_t / f$）。这种持续的振荡旨在使提议协方差保持显著变化，从而违反递减自适应。\n- 案例 C（旨在违反包含性）：对于 $t  N_{\\text{burn}}$，在宽度为 $W = 50$ 的滑动窗口上，计算经验接受率 $a_t$，如果 $a_t  0.1$，则更新 $s_t \\leftarrow \\alpha s_t$；如果 $a_t  0.4$，则更新 $s_t \\leftarrow \\beta s_t$；否则保持 $s_t$ 不变，其中 $\\alpha = 1.2$ 和 $\\beta = 0.8$。不限制 $s_t$ 的上限。此规则可能导致 $C_t$ 的无界增长。\n\n对于每个案例，返回一个布尔值，指示两个诊断是否都满足，即当且仅当该运行的递减自适应和包含性都成立时返回 $\\text{True}$；否则返回 $\\text{False}$。\n\n您的程序必须使用每个案例固定的随机种子来确定性地实现上述模拟和诊断，并生成一行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，\"[resultA,resultB,resultC]\"）。每个案例的结果必须是布尔值。输出中无需报告任何物理单位，因为要求的结果是布尔值。\n\n测试套件和覆盖范围：\n\n- 案例 A：递减自适应应满足，包含性应满足；预期的布尔值为 $\\text{True}$。\n- 案例 B：由于持续振荡，递减自适应应失败；预期的布尔值为 $\\text{False}$。\n- 案例 C：由于无界提议增长，包含性应失败；预期的布尔值为 $\\text{False}$。\n\n您的程序必须计算并以 \"[True,False,False]\" 的确切格式打印结果列表。不应打印任何附加文本。", "solution": "该问题陈述经评估为 **有效**。它提出了一个定义明确且具有科学依据的计算天体物理学任务，特别侧重于自适应 MCMC 算法收敛条件的运行验证。模型、数据和参数是完整、一致且合理的。任务是实现一个确定性模拟，这是测试算法属性的标准方法。\n\n问题的核心是模拟一个随机游走 Metropolis MCMC 算法，以从光子计数数据中推断天体物理幂律模型的两个参数 $\\theta = (\\log A, \\gamma)$。算法的提议协方差矩阵 $C_t$ 根据链的历史进行自适应调整。这种自适应的有效性通过两个操作性诊断来评估：递减自适应和包含性。\n\n首先，我们定义 MCMC 算法旨在采样的目标概率分布，即后验分布 $\\pi(\\theta)$。根据贝叶斯定理，后验分布正比于似然和先验的乘积，$\\pi(\\theta) \\propto \\mathcal{L}(\\theta | \\text{data}) \\cdot p(\\theta)$。在计算上，处理后验的对数更为稳定：\n$$\n\\log \\pi(\\theta) = \\log \\mathcal{L}(\\theta | \\text{data}) + \\log p(\\theta) + \\text{const.}\n$$\n数据由能量箱 $E_i$ 中曝光时间为 $T_i$ 的光子计数 $k_i$ 组成。计数被建模为独立的泊松变量，$k_i \\sim \\text{Poisson}(\\lambda_i)$，其中期望计数率 $\\lambda_i$ 由幂律模型 $\\lambda_i = A T_i (E_i/E_0)^{-\\gamma}$ 给出。根据我们的参数矢量 $\\theta = (\\log A, \\gamma) = (\\theta_0, \\theta_1)$，我们有 $A = e^{\\theta_0}$，所以 $\\lambda_i = e^{\\theta_0} T_i (E_i/E_0)^{-\\theta_1}$。对数似然是各个对数泊松概率之和：\n$$\n\\log \\mathcal{L}(\\theta | k) = \\sum_{i} \\left( k_i \\log(\\lambda_i(\\theta)) - \\lambda_i(\\theta) - \\log(k_i!) \\right)\n$$\n对于 MCMC 目的，项 $\\log(k_i!)$ 是一个关于 $\\theta$ 的常数，可以舍去。\n\n$\\log A = \\theta_0$ 和 $\\gamma = \\theta_1$ 的先验概率被指定为独立的高斯分布：$\\theta_0 \\sim \\mathcal{N}(\\mu_A, \\sigma_A^2)$ 和 $\\theta_1 \\sim \\mathcal{N}(\\mu_\\gamma, \\sigma_\\gamma^2)$。对数先验为：\n$$\n\\log p(\\theta) = -\\frac{1}{2} \\left( \\frac{\\theta_0 - \\mu_A}{\\sigma_A} \\right)^2 - \\frac{1}{2} \\left( \\frac{\\theta_1 - \\mu_\\gamma}{\\sigma_\\gamma} \\right)^2 + \\text{const.}\n$$\n未归一化的对数后验函数是未归一化的对数似然和对数先验项之和。\n\nMCMC 模拟通过随机游走 Metropolis 算法进行。在每次迭代 $t$ 中，从当前状态 $\\theta_t$ 使用对称提议分布 $\\theta' \\sim \\mathcal{N}(\\theta_t, C_t)$ 提议一个新的状态 $\\theta'$。提议的状态以以下概率被接受：\n$$\n\\alpha(\\theta_t, \\theta') = \\min\\left(1, \\frac{\\pi(\\theta')}{\\pi(\\theta_t)}\\right) = \\min\\left(1, \\exp(\\log\\pi(\\theta') - \\log\\pi(\\theta_t))\\right)\n$$\n如果提议被接受，则 $\\theta_{t+1} = \\theta'$；否则，它被拒绝，并且 $\\theta_{t+1} = \\theta_t$。\n\n关键特征是提议协方差 $C_t$ 的自适应。它被定义为 $C_t = \\lambda_t (\\Sigma_t + \\varepsilon I)$，其中 $\\Sigma_t$ 是链历史 $\\{\\theta_0, \\dots, \\theta_t\\}$ 的经验协方差，$\\varepsilon$ 是一个小的正稳定项，$\\lambda_t$ 是一个缩放因子。为了高效计算 $\\Sigma_t$，使用一种数值稳定的在线算法（Welford 算法的变体）在每次迭代中更新样本均值和离差平方和矩阵。\n\n问题表示法中关于缩放因子存在一个细微的歧义。问题定义了 $C_t = s_t^2 (\\Sigma_t + \\varepsilon I)$，设置了基础值 $s_{\\text{base}} = (2.38)^2 / d$，并为案例 A 指定了 $s_t=s_{\\text{base}}$。字面解释意味着方差缩放因子是 $s_{\\text{base}}^2$，这与理论上的最优值 $(2.38)^2/d$ 有显著差异。鉴于案例 A 预期会通过其诊断，我们推断其可能的意图是，我们称之为 $\\lambda_t$ 的被自适应调整的量，其基础值为 $(2.38)^2/d$。因此，我们的实现将使用 $\\lambda_t$ 作为协方差矩阵的缩放因子，其中 $\\lambda_t$ 根据每个案例给出的规则进行调整（$\\lambda_t$ 的基础值是问题中称为 $s_{\\text{base}}$ 的量）。\n\n模拟运行 $N=4000$ 次迭代，其中前 $N_{\\text{burn}}=1000$ 次作为老化期被丢弃。模拟了三个测试案例，每个案例在老化期后都有不同的缩放因子 $\\lambda_t$ 调整规则：\n- **案例 A**：$\\lambda_t$ 保持其基础值 $\\lambda_{\\text{base}} = (2.38)^2/d$ 不变。自适应仅通过 $\\Sigma_t$ 的更新发生。这预期会满足收敛诊断。\n- **案例 B**：$\\lambda_t$ 被一个乘法因子 $f=3.0$ 及其倒数 $1/f$ 周期性地扰动。这种持续的、非递减的提议核变化旨在违反递减自适应条件。\n- **案例 C**：$\\lambda_t$ 根据最近窗口内的接受率进行调整。如果接受率太低，$\\lambda_t$ 增加；如果太高，则减少。这种自适应没有上限，可能导致提议协方差的无界增长，从而违反包含性条件。\n\n对于每个案例，计算两个诊断：\n1.  **包含性**：如果任何提议协方差的最大特征值 $\\max_t \\lambda_{\\max}(C_t)$ 和任何状态的最大范数 $\\max_t \\lVert \\theta_t \\rVert_2$ 保持在它们各自的预定义界限 $V_{\\max}$ 和 $R_{\\max}$ 以下，则此条件满足。\n2.  **递减自适应**：如果在最后 $L=500$ 次迭代中，提议协方差的平均相对变化 $r_t = \\lVert C_t - C_{t-1} \\rVert_F / \\max(\\lVert C_{t-1} \\rVert_F, \\delta)$ 低于阈值 $\\epsilon_{\\text{dim}}$，则此条件满足。\n\n每个案例的最终输出是一个单一的布尔值，当且仅当两个诊断都满足时为 `True`。通过为每个案例使用固定的、不同的随机种子来确保确定性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the MCMC simulations and diagnostics for all test cases.\n    \"\"\"\n\n    # --- Problem Definition ---\n    # Fixed data\n    E = np.array([0.5, 1.0, 2.0, 5.0])  # Energy bin centers (keV)\n    T = np.array([10000.0, 10000.0, 10000.0, 10000.0])  # Exposure times (s)\n    E0 = 1.0  # Pivot energy (keV)\n    k = np.array([80, 20, 5, 1])  # Observed counts\n\n    # Prior parameters\n    mu_A = np.log(0.002)\n    sigma_A = 1.0\n    mu_gamma = 2.0\n    sigma_gamma = 1.0\n\n    # Hyperparameters\n    d = 2  # Dimension\n    N_burn = 1000\n    N = 4000\n    L = 500\n    eps = 1e-6\n    delta = 1e-12\n    # This is the variance scaling factor, which the problem confusingly calls s_base\n    variance_scale_base = (2.38**2) / d\n    epsilon_dim = 0.2\n    V_max = 100.0\n    R_max = 50.0\n    theta_0 = np.array([np.log(0.02), 0.5])\n\n    # Case-specific hyperparameters\n    P_B = 50\n    f_B = 3.0\n    W_C = 50\n    alpha_C = 1.2\n    beta_C = 0.8\n\n    # --- Log-Posterior Function ---\n    log_E_ratios = np.log(E / E0)\n\n    def log_posterior(theta):\n        \"\"\"Computes the unnormalized log-posterior probability.\"\"\"\n        log_A, gamma = theta[0], theta[1]\n        \n        if log_A  20: # Prevent overflow in exp(log_A)\n            return -np.inf\n\n        # Log-likelihood\n        lambda_i = np.exp(log_A) * T * np.exp(-gamma * log_E_ratios)\n\n        # Check for invalid lambda values\n        if np.any(lambda_i = 0):\n            return -np.inf\n\n        log_like = np.sum(k * np.log(lambda_i) - lambda_i)\n\n        # Log-prior\n        log_prior_A = -0.5 * ((log_A - mu_A) / sigma_A)**2\n        log_prior_gamma = -0.5 * ((gamma - mu_gamma) / sigma_gamma)**2\n        log_prior = log_prior_A + log_prior_gamma\n        \n        return log_like + log_prior\n\n    def run_mcmc_case(case_name, seed):\n        \"\"\"Runs the MCMC simulation for a single case.\"\"\"\n        rng = np.random.default_rng(seed)\n\n        # Histories\n        theta_hist = np.zeros((N, d))\n        theta_hist[0] = theta_0\n        acceptance_history = []\n        \n        # Online covariance statistics (Welford's algorithm)\n        mean = theta_0.copy()\n        M2 = np.zeros((d, d))\n        count = 1\n\n        # Adaptive quantities\n        variance_scale = variance_scale_base\n        Sigma = np.zeros((d, d))\n        \n        # Initial proposal covariance C_0\n        C = variance_scale * (Sigma + eps * np.identity(d))\n        if np.all(Sigma == 0):\n             C = variance_scale * eps * np.identity(d) # A more robust initialization\n\n        # History for diagnostics\n        C_history = [C]\n        theta_norm_history = [np.linalg.norm(theta_0)]\n        lambda_max_history = [np.max(np.linalg.eigvalsh(C))]\n\n        # Case B specific state\n        if case_name == 'B':\n            osc_factor = f_B\n\n        # Main MCMC loop\n        for t in range(N - 1): # t from 0 to N-2\n            \n            # --- Propose and Accept/Reject ---\n            current_theta = theta_hist[t]\n            try:\n                proposal = rng.multivariate_normal(current_theta, C)\n            except np.linalg.LinAlgError:\n                # If C is not positive semidefinite, chain is stuck.\n                proposal = current_theta\n\n            logp_curr = log_posterior(current_theta)\n            logp_prop = log_posterior(proposal)\n            \n            accepted = False\n            if logp_prop > -np.inf and (logp_prop - logp_curr >= 0 or np.log(rng.uniform())  logp_prop - logp_curr):\n                theta_hist[t + 1] = proposal\n                accepted = True\n            else:\n                theta_hist[t + 1] = current_theta\n            \n            acceptance_history.append(accepted)\n            \n            # --- Update and Adapt for next step ---\n            # 1. Update online moments\n            count += 1\n            x = theta_hist[t + 1]\n            delta_pre = x - mean\n            mean += delta_pre / count\n            delta_post = x - mean\n            M2 += np.outer(delta_pre, delta_post)\n\n            if count > 1:\n                Sigma = M2 / (count - 1)\n\n            # 2. Adapt variance scale\n            time_idx = t + 1\n            \n            if case_name == 'B' and time_idx > N_burn and (time_idx - N_burn) % P_B == 0:\n                variance_scale *= osc_factor\n                osc_factor = 1.0 / osc_factor\n            \n            if case_name == 'C' and time_idx > N_burn:\n                window_start = max(0, time_idx - W_C)\n                acc_rate = np.mean(acceptance_history[window_start:time_idx])\n                if acc_rate  0.1:\n                    variance_scale *= alpha_C\n                elif acc_rate > 0.4:\n                    variance_scale *= beta_C\n            \n            # 3. Form new covariance for next step\n            C = variance_scale * (Sigma + eps * np.identity(d))\n\n            # 4. Store diagnostics for step t+1\n            C_history.append(C)\n            theta_norm_history.append(np.linalg.norm(theta_hist[t + 1]))\n            try:\n                lambda_max_history.append(np.max(np.linalg.eigvalsh(C)))\n            except np.linalg.LinAlgError:\n                lambda_max_history.append(np.inf) # Penalize non-PSD covariance\n\n        # --- Perform Diagnostics ---\n        # 1. Containment\n        containment_ok = (max(lambda_max_history) = V_max) and (max(theta_norm_history) = R_max)\n\n        # 2. Diminishing Adaptation\n        r_ts = []\n        for t in range(N - L, N):\n            C_t = C_history[t]\n            C_t_minus_1 = C_history[t - 1]\n            norm_diff = np.linalg.norm(C_t - C_t_minus_1, 'fro')\n            norm_prev = np.linalg.norm(C_t_minus_1, 'fro')\n            r_t = norm_diff / max(norm_prev, delta)\n            r_ts.append(r_t)\n        \n        avg_r = np.mean(r_ts)\n        diminishing_ok = avg_r  epsilon_dim\n        \n        return containment_ok and diminishing_ok\n\n    # --- Run all cases and collect results ---\n    results = [\n        run_mcmc_case('A', seed=42),\n        run_mcmc_case('B', seed=43),\n        run_mcmc_case('C', seed=44)\n    ]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(str(r).capitalize() for r in results)}]\")\n\nsolve()\n\n```", "id": "3528600"}]}