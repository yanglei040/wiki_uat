{"hands_on_practices": [{"introduction": "本练习深入探讨多重网格求解器的核心组成部分：平滑器。平滑器的作用是有效衰减在粗网格上不可见的高频误差分量。通过对加权雅可比方法进行局部傅里叶分析（LFA），您将定量地理解其平滑特性，并确定最优松弛参数 $\\omega$ 以最大化其效率，这项分析是设计高效多重网格循环的基础。[@problem_id:3524229]", "problem": "在计算天体物理学的自引力介质模拟中，引力势 $\\phi$ 是通过求解一个泊松方程获得的。在一维模型中，该方程经过无量纲化后，简化为一个带有标准三点拉普拉斯算子的离散亥姆霍兹问题。考虑在间距为 $h>0$ 的均匀无限网格上，一个由模板 $\\{-1,\\,2,\\,-1\\}/h^{2}$ 定义的离散算子 $A$，使得对于网格索引 $j \\in \\mathbb{Z}$，有 $(A u)_{j} = \\frac{1}{h^{2}}\\left(-u_{j-1} + 2u_{j} - u_{j+1}\\right)$。对于 $A u = f$，加权雅可比松弛法由以下迭代给出\n$$\nu^{(k+1)} = u^{(k)} + \\omega D^{-1}\\left(f - A u^{(k)}\\right),\n$$\n其中 $D$ 是 $A$ 的对角部分，$\\omega \\in (0,1)$ 是松弛权重。对于多重网格求解器，加权雅可比法作为光滑子的有效性，是通过局部傅里叶分析 (Local Fourier Analysis, LFA) 下每个傅里叶模式每次迭代的误差放大因子来量化的。设误差 $e^{(k)} = u^{(k)} - u^{*}$ 在无限网格上分解为傅里叶分量，其代表模式为 $e_{j}(\\theta) = \\exp(i j \\theta)$，其中角度 $\\theta \\in [0, \\pi]$ 以弧度为单位。将误差放大因子 $\\mu(\\theta)$ 定义为作用于此傅里叶模式的误差传播算子的特征值的模。\n\n从上述定义出发，仅使用离散拉普拉斯算子、雅可比迭代和局部傅里叶分析 (LFA) 的基本性质，推导出 $\\mu(\\theta)$ 作为 $\\theta$ 和 $\\omega$ 的函数的符号表达式。相对于标准的因子为2的粗化，高频分量是指 $\\theta \\in [\\pi/2, \\pi]$ (以弧度为单位) 的分量。确定能够最小化高频段 $\\theta \\in [\\pi/2, \\pi]$ 上 $\\mu(\\theta)$ 的最坏情况 (上确界) 的松弛权重 $\\omega$ 的精确值，并报告在此最优 $\\omega$ 下达到的最小化的最坏情况高频放大因子。\n\n您的最终答案必须包括：\n- $\\mu(\\theta)$ 关于 $\\theta$ 和 $\\omega$ 的闭式表达式。\n- 最小化 $\\sup_{\\theta \\in [\\pi/2, \\pi]} \\mu(\\theta)$ 的精确最优 $\\omega$ 值。\n- 在此最优 $\\omega$ 下 $\\sup_{\\theta \\in [\\pi/2, \\pi]} \\mu(\\theta)$ 的精确最小化值。\n\n角度必须以弧度表示。无需四舍五入；请提供精确值。", "solution": "该问题要求推导并分析应用于一维离散泊松方程的加权雅可比方法的误差放大因子。该过程包括三个主要步骤：首先，使用局部傅里叶分析 (LFA) 推导放大因子的一般表达式；其次，确定指定高频段上的最坏情况放大因子；第三，找到最小化此最坏情况因子的最优松弛权重 $\\omega$。\n\n对于系统 $A u = f$，加权雅可比迭代法如下：\n$$\nu^{(k+1)} = u^{(k)} + \\omega D^{-1}\\left(f - A u^{(k)}\\right)\n$$\n其中 $k$ 是迭代索引，$\\omega$ 是松弛权重，$D$ 是算子 $A$ 的对角部分。\n\n设 $u^{*}$ 为精确解，满足 $A u^{*} = f$。第 $k$ 次迭代的误差为 $e^{(k)} = u^{(k)} - u^{*}$。从迭代公式中减去 $u^{*}$，得到误差传播方程：\n$$\nu^{(k+1)} - u^{*} = u^{(k)} - u^{*} + \\omega D^{-1}\\left(A u^{*} - A u^{(k)}\\right)\n$$\n$$\ne^{(k+1)} = e^{(k)} - \\omega D^{-1} A \\left(u^{(k)} - u^{*}\\right)\n$$\n$$\ne^{(k+1)} = \\left(I - \\omega D^{-1} A\\right) e^{(k)}\n$$\n误差在每一步都被迭代算子 $S = I - \\omega D^{-1} A$ 变换。\n\n局部傅里叶分析 (LFA) 考察此算子对误差的单个傅里叶模式的影响。无限网格上的一个傅里叶模式表示为 $e_j(\\theta) = \\exp(i j \\theta)$，其中 $j \\in \\mathbb{Z}$ 是网格索引，$\\theta \\in [0, \\pi]$ 是无量纲波数。当像 $A$ 或 $S$ 这样的算子作用于此模式时，该模式被乘以一个复标量，该标量是算子对于该模式的特征值，也称为其符号。误差放大因子 $\\mu(\\theta)$ 是迭代算子 $S$ 的特征值 (符号) 的模。\n$$\nS e_j(\\theta) = \\lambda(\\theta) e_j(\\theta) \\quad \\text{且} \\quad \\mu(\\theta) = |\\lambda(\\theta)|\n$$\n\n首先，我们求出算子 $A$ 的符号，记作 $\\hat{A}(\\theta)$。算子 $A$ 定义为 $(A u)_{j} = \\frac{1}{h^{2}}\\left(-u_{j-1} + 2u_{j} - u_{j+1}\\right)$。将其应用于模式 $e_j(\\theta)$：\n$$\n(A e(\\theta))_j = \\frac{1}{h^{2}}\\left(-\\exp(i(j-1)\\theta) + 2\\exp(ij\\theta) - \\exp(i(j+1)\\theta)\\right)\n$$\n$$\n= \\frac{\\exp(ij\\theta)}{h^{2}}\\left(-\\exp(-i\\theta) + 2 - \\exp(i\\theta)\\right)\n$$\n$$\n= \\frac{e_j(\\theta)}{h^{2}}\\left(2 - (\\exp(i\\theta) + \\exp(-i\\theta))\\right)\n$$\n使用恒等式 $2\\cos(\\theta) = \\exp(i\\theta) + \\exp(-i\\theta)$，我们得到：\n$$\n(A e(\\theta))_j = \\frac{e_j(\\theta)}{h^{2}}\\left(2 - 2\\cos(\\theta)\\right) = \\frac{2}{h^{2}}(1 - \\cos(\\theta)) e_j(\\theta)\n$$\n使用半角恒等式 $1 - \\cos(\\theta) = 2\\sin^2(\\frac{\\theta}{2})$，这变为：\n$$\n(A e(\\theta))_j = \\frac{4}{h^{2}}\\sin^2\\left(\\frac{\\theta}{2}\\right) e_j(\\theta)\n$$\n因此，$A$ 的符号为 $\\hat{A}(\\theta) = \\frac{4}{h^{2}}\\sin^2\\left(\\frac{\\theta}{2}\\right)$。\n\n算子 $D$ 是 $A$ 的对角部分。从模板 $\\{-1, 2, -1\\}/h^2$ 可知，对角元素为 $A_{jj} = 2/h^2$。因此，在此背景下 $D$ 是一个标量算子，$D = \\frac{2}{h^2}I$，其符号为 $\\hat{D} = 2/h^2$。因此，$D^{-1}$ 的符号为 $\\hat{D}^{-1} = h^2/2$。\n\n迭代算子 $S = I - \\omega D^{-1} A$ 的符号为：\n$$\n\\lambda(\\theta) = 1 - \\omega \\hat{D}^{-1} \\hat{A}(\\theta) = 1 - \\omega \\left(\\frac{h^2}{2}\\right) \\left(\\frac{4}{h^{2}}\\sin^2\\left(\\frac{\\theta}{2}\\right)\\right)\n$$\n$$\n\\lambda(\\theta) = 1 - 2\\omega\\sin^2\\left(\\frac{\\theta}{2}\\right)\n$$\n代回 $2\\sin^2(\\frac{\\theta}{2}) = 1 - \\cos(\\theta)$，我们发现：\n$$\n\\lambda(\\theta) = 1 - \\omega(1 - \\cos(\\theta))\n$$\n误差放大因子 $\\mu(\\theta)$ 是 $\\lambda(\\theta)$ 的模：\n$$\n\\mu(\\theta) = |1 - \\omega(1 - \\cos(\\theta))|\n$$\n这是第一个要求的表达式。\n\n接下来，我们需要找到最优松弛权重 $\\omega \\in (0,1)$，它最小化高频段 $\\theta \\in [\\pi/2, \\pi]$ 上的最坏情况放大因子。需要最小化的量是 $\\sup_{\\theta \\in [\\pi/2, \\pi]} \\mu(\\theta)$。\n\n让我们分析 $\\mu(\\theta)$ 在此频段上的行为。令 $x = 1 - \\cos(\\theta)$。当 $\\theta$ 从 $\\pi/2$ 变化到 $\\pi$ 时，$\\cos(\\theta)$ 从 $0$ 变化到 $-1$。因此，$x$ 从 $1 - 0 = 1$ 变化到 $1 - (-1) = 2$。对应于高频段的 $x$ 的定义域是区间 $[1, 2]$。\n我们希望找到 $\\omega$ 来解决这个极小化极大问题：\n$$\n\\min_{\\omega \\in (0,1)} \\left( \\sup_{x \\in [1,2]} |1 - \\omega x| \\right)\n$$\n令 $M(\\omega) = \\sup_{x \\in [1,2]} |1 - \\omega x|$。函数 $f(x) = 1 - \\omega x$ 是关于 $x$ 的线性函数。其绝对值在闭区间上的最大值必定出现在端点之一。因此：\n$$\nM(\\omega) = \\max\\left( |1 - \\omega \\cdot 1|, |1 - \\omega \\cdot 2| \\right) = \\max\\left( |1 - \\omega|, |1 - 2\\omega| \\right)\n$$\n对于给定的范围 $\\omega \\in (0, 1)$，项 $1 - \\omega$ 总是正的，所以 $|1 - \\omega| = 1 - \\omega$。我们需要最小化 $M(\\omega) = \\max(1 - \\omega, |1 - 2\\omega|)$。\n\n我们分两个 $\\omega$ 的子区间来分析：\n情况 1: $\\omega \\in (0, 1/2]$。\n在此区间内，$1 - 2\\omega \\ge 0$，所以 $|1 - 2\\omega| = 1 - 2\\omega$。\n$$\nM(\\omega) = \\max(1 - \\omega, 1 - 2\\omega)\n$$\n因为 $\\omega > 0$，我们有 $2\\omega > \\omega$，这意味着 $-2\\omega  -\\omega$，且 $1 - 2\\omega  1 - \\omega$。\n所以，$M(\\omega) = 1 - \\omega$。这个函数在 $(0, 1/2]$ 上是递减的。它在此区间上的最小值在 $\\omega = 1/2$ 处取得，此时 $M(1/2) = 1 - 1/2 = 1/2$。\n\n情况 2: $\\omega \\in (1/2, 1)$。\n在此区间内，$1 - 2\\omega  0$，所以 $|1 - 2\\omega| = -(1 - 2\\omega) = 2\\omega - 1$。\n$$\nM(\\omega) = \\max(1 - \\omega, 2\\omega - 1)\n$$\n我们正在寻找两个函数最大值的最小值。一个函数 $f_1(\\omega) = 1-\\omega$ 是递减的，而另一个函数 $f_2(\\omega) = 2\\omega-1$ 是递增的。它们最大值的最小值出现在它们相等的地方：\n$$\n1 - \\omega = 2\\omega - 1 \\implies 3\\omega = 2 \\implies \\omega = \\frac{2}{3}\n$$\n这个值 $\\omega = 2/3$ 位于区间 $(1/2, 1)$ 内。在这个最优点，最大值为：\n$$\nM(2/3) = 1 - \\frac{2}{3} = \\frac{1}{3} \\quad \\text{且} \\quad M(2/3) = 2\\left(\\frac{2}{3}\\right) - 1 = \\frac{4}{3} - 1 = \\frac{1}{3}\n$$\n\n比较两种情况下的最小值，我们有来自情况1的 $1/2$ (在边界 $\\omega=1/2$) 和来自情况2的 $1/3$ (在 $\\omega=2/3$)。对于 $\\omega \\in (0,1)$，$M(\\omega)$ 的全局最小值是 $1/3$。\n\n因此，最优松弛权重为 $\\omega_{opt} = 2/3$。\n最小化的最坏情况高频放大因子为 $\\sup_{\\theta \\in [\\pi/2, \\pi]} \\mu(\\theta) = 1/3$。\n\n所求的三个量是：\n1.  $\\mu(\\theta)$ 的表达式：$|1 - \\omega(1 - \\cos(\\theta))|$\n2.  最优权重 $\\omega$：$2/3$\n3.  最小化的最坏情况放大因子：$1/3$", "answer": "$$\n\\boxed{\\begin{pmatrix} |1 - \\omega(1 - \\cos(\\theta))|  \\frac{2}{3}  \\frac{1}{3} \\end{pmatrix}}\n$$", "id": "3524229"}, {"introduction": "一旦高频误差被平滑，多重网格方法将在更粗的网格上处理剩余的平滑误差。本练习将演示伽辽金条件（Galerkin condition）$A_{c} = R A_{f} P$ 如何为构建粗网格算子提供一种稳健的方法。您将通过推导证明，对于标准的插值和限制算子，所得到的粗网格算子能出色地保持原拉普拉斯算子的结构，这是确保多重网格方法在不同尺度上保持一致性的关键。[@problem_id:3524220]", "problem": "在为一维分层天体物理介质沿坐标 $x \\in [0,L]$ 的自引力势建模时，引力势 $\\phi(x)$ 满足泊松方程 $-\\frac{d^{2}\\phi}{dx^{2}} = \\rho(x)$ 和齐次狄利克雷边界条件 $\\phi(0)=\\phi(L)=0$。考虑一个具有 $N_{f}$ 个内部点、间距为 $h_{f} = \\frac{L}{N_{f}+1}$ 的均匀细网格，以及一个间距为 $h_{c} = 2 h_{f}$ 的嵌套粗网格。\n\n令细网格离散算子 $A_{f}$ 为作用于内部节点的负拉普拉斯算子的标准二阶中心有限差分近似，其定义为\n$$(A_{f} y)_{i} = \\frac{-y_{i-1} + 2 y_{i} - y_{i+1}}{h_{f}^{2}}.$$\n通过线性插值定义从粗网格到细网格的延拓（插值）算子 $P$，\n$$(P v)_{2j} = v_{j}, \\quad (P v)_{2j+1} = \\frac{v_{j} + v_{j+1}}{2},$$\n并通过完全加权定义从细网格到粗网格的限制算子 $R$，\n$$(R w)_{j} = \\frac{w_{2j-1} + 2 w_{2j} + w_{2j+1}}{4}.$$\n伽辽金粗网格算子定义为 $A_{c} = R A_{f} P$。\n\n仅从这些定义出发，显式计算 $A_{c}$ 的内部三点模板，并证明它与按 $1/h_{c}^{2}$ 缩放的标准三对角拉普拉斯算子一致。你的推导不应借助任何未经证明的恒等式，且必须通过将 $P$、$A_{f}$ 和 $R$ 复合作用于一个任意粗网格向量来进行。\n\n答案规格：仅以单个 LaTeX 行矩阵的形式报告与粗网格节点 $j-1$、$j$ 和 $j+1$ 对应的三点模板权重，包括显式的缩放因子。无需进行数值四舍五入。", "solution": "目标是确定粗网格算子 $A_{c}$ 对任意粗网格向量 $v$ 的作用。具体来说，我们必须计算向量 $A_{c}v$ 对于一个一般的内部粗网格节点 $j$ 的第 $j$ 个分量。该算子定义为复合算子 $A_{c} = R A_{f} P$。我们从右到左计算该复合算子。\n\n设 $v$ 是粗网格上的一个向量。设索引 $j-1, j, j+1$ 对应于内部粗网格节点。\n\n**1. 延拓算子 $P$ 的作用**\n首先，我们将延拓算子 $P$ 作用于粗网格向量 $v$，得到一个细网格向量，记作 $w = P v$。我们需要 $w$ 的分量，这些分量将随后用于计算 $(A_c v)_j$。$(A_c v)_j$ 的计算涉及 $(R(A_f w))_j$，而这又取决于细网格分量 $(A_f w)_{2j-1}, (A_f w)_{2j}, (A_f w)_{2j+1}$。这些分量又进而取决于 $w$ 从索引 $2j-2$ 到 $2j+2$ 的分量。\n使用 $P$ 的定义：\n- $w_{2j-2} = (P v)_{2(j-1)} = v_{j-1}$\n- $w_{2j-1} = (P v)_{2(j-1)+1} = \\frac{v_{j-1} + v_{j}}{2}$\n- $w_{2j} = (P v)_{2j} = v_{j}$\n- $w_{2j+1} = (P v)_{2j+1} = \\frac{v_{j} + v_{j+1}}{2}$\n- $w_{2j+2} = (P v)_{2(j+1)} = v_{j+1}$\n\n**2. 细网格算子 $A_f$ 的作用**\n接下来，我们将细网格算子 $A_{f}$ 作用于向量 $w$。令 $z = A_{f} w$。我们计算限制算子所需的 $z$ 的分量，即 $z_{2j-1}$、 $z_{2j}$ 和 $z_{2j+1}$。\n\n对于分量 $z_{2j}$：\n$$\nz_{2j} = (A_{f} w)_{2j} = \\frac{-w_{2j-1} + 2w_{2j} - w_{2j+1}}{h_{f}^{2}}\n$$\n代入 $w$ 的分量表达式：\n$$\nz_{2j} = \\frac{1}{h_{f}^{2}} \\left( -\\frac{v_{j-1} + v_{j}}{2} + 2v_{j} - \\frac{v_{j} + v_{j+1}}{2} \\right)\n= \\frac{1}{h_{f}^{2}} \\left( \\frac{-v_{j-1} - v_{j} + 4v_{j} - v_{j} - v_{j+1}}{2} \\right)\n= \\frac{1}{2h_{f}^{2}} (-v_{j-1} + 2v_{j} - v_{j+1})\n$$\n\n对于分量 $z_{2j-1}$：\n$$\nz_{2j-1} = (A_{f} w)_{2j-1} = \\frac{-w_{2j-2} + 2w_{2j-1} - w_{2j}}{h_{f}^{2}}\n$$\n代入 $w$ 的分量表达式：\n$$\nz_{2j-1} = \\frac{1}{h_{f}^{2}} \\left( -v_{j-1} + 2\\left(\\frac{v_{j-1} + v_{j}}{2}\\right) - v_{j} \\right)\n= \\frac{1}{h_{f}^{2}} (-v_{j-1} + v_{j-1} + v_{j} - v_{j}) = 0\n$$\n\n对于分量 $z_{2j+1}$：\n$$\nz_{2j+1} = (A_{f} w)_{2j+1} = \\frac{-w_{2j} + 2w_{2j+1} - w_{2j+2}}{h_{f}^{2}}\n$$\n代入 $w$ 的分量表达式：\n$$\nz_{2j+1} = \\frac{1}{h_{f}^{2}} \\left( -v_{j} + 2\\left(\\frac{v_{j} + v_{j+1}}{2}\\right) - v_{j+1} \\right)\n= \\frac{1}{h_{f}^{2}} (-v_{j} + v_{j} + v_{j+1} - v_{j+1}) = 0\n$$\n这一结果，即有限差分算子在“中间”的细网格点上的作用为零，是线性插值（延拓算子 $P$）产生局部线性函数这一事实的直接推论，而线性函数的二阶有限差分为零。\n\n**3. 限制算子 $R$ 的作用**\n最后，我们将限制算子 $R$ 作用于向量 $z$，以获得最终粗网格向量 $A_c v$ 的第 $j$ 个分量。\n$$\n(A_{c}v)_{j} = (R z)_{j} = \\frac{z_{2j-1} + 2z_{2j} + z_{2j+1}}{4}\n$$\n代入计算出的 $z$ 的分量值：\n$$\n(A_{c}v)_{j} = \\frac{0 + 2z_{2j} + 0}{4} = \\frac{z_{2j}}{2}\n$$\n现在，代入 $z_{2j}$ 的表达式：\n$$\n(A_{c}v)_{j} = \\frac{1}{2} \\left( \\frac{1}{2h_{f}^{2}} (-v_{j-1} + 2v_{j} - v_{j+1}) \\right) = \\frac{-v_{j-1} + 2v_{j} - v_{j+1}}{4h_{f}^{2}}\n$$\n\n**4. 最终形式与模板识别**\n问题指明了粗网格和细网格间距之间的关系为 $h_{c} = 2h_{f}$。将此关系平方得到 $h_{c}^{2} = 4h_{f}^{2}$。我们将其代入 $(A_{c}v)_{j}$ 的表达式中：\n$$\n(A_{c}v)_{j} = \\frac{-v_{j-1} + 2v_{j} - v_{j+1}}{h_{c}^{2}}\n$$\n这个结果正是负拉普拉斯算子的标准二阶中心有限差分近似，只不过是在间距为 $h_c$ 的粗网格上。这表明，对于所选的延拓和限制算子，伽辽金粗网格算子 $A_c = R A_f P$ 保持了原始微分算子的形式。\n\n算子 $A_c$ 在内部节点 $j$ 处的三点模板给出了粗网格值 $v_{j-1}$、$v_{j}$ 和 $v_{j+1}$ 的权重。从推导出的表达式可知，这些权重分别为 $-\\frac{1}{h_{c}^{2}}$、$\\frac{2}{h_{c}^{2}}$ 和 $-\\frac{1}{h_{c}^{2}}$。\n\n问题要求将这些权重以单个 LaTeX 行矩阵的形式报告。权重是 $(v_{j-1}, v_{j}, v_{j+1})$ 的系数。因此，模板为 $(\\frac{1}{h_{c}^{2}})[-1, 2, -1]$。", "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{1}{h_{c}^{2}}  \\frac{2}{h_{c}^{2}}  -\\frac{1}{h_{c}^{2}} \\end{pmatrix}}\n$$", "id": "3524220"}, {"introduction": "这最后一个练习将多重网格的核心概念整合到一个完整的实际应用中。您将从头开始构建一个三维几何多重网格求解器，用于计算均匀密度球体的引力势——一个天体物理学中的经典问题。除了实现V循环本身，本练习还要求您分析数值模拟的一个关键方面：由有限计算边界引起的截断误差，从而在理想化算法与真实世界的科学建模之间架起一座桥梁。[@problem_id:3524177]", "problem": "考虑真空和物质区域中的牛顿引力，其中引力势满足泊松方程。本问题的基本依据是牛顿引力的泊松方程，该方程指出引力势 $\\,\\Phi(\\mathbf{x})\\,$ 遵循\n$$\n\\nabla^2 \\Phi(\\mathbf{x}) = 4\\pi G \\rho(\\mathbf{x}),\n$$\n其中 $\\,G\\,$ 是引力常数，$\\,\\rho(\\mathbf{x})\\,$ 是质量密度。在真空中，$\\,\\rho(\\mathbf{x})=0\\,$，该方程简化为拉普拉斯方程。对于一个以原点为中心、半径为 $\\,R_{\\mathrm{s}}\\,$ 的均匀密度球体，其密度在 $\\,\\|\\mathbf{x}\\|\\le R_{\\mathrm{s}}\\,$ 时为常数 $\\,\\rho(\\mathbf{x})=\\rho_0\\,$，其他地方为 $\\,\\rho(\\mathbf{x})=0\\,$，其精确的无限域势 $\\,\\Phi_{\\mathrm{exact}}(r)\\,$（其中 $\\,r=\\|\\mathbf{x}\\|\\,$ 且势的零点选在无穷远处）由一个在 $\\,r=R_{\\mathrm{s}}\\,$ 处平滑的分段函数给出。\n\n您的任务是编写一个完整且可运行的程序，该程序：\n- 使用二阶中心有限差分法，在覆盖立方体 $\\,[-L,L]^3\\,$ 的均匀笛卡尔网格上离散化三维泊松方程。该网格包含 $\\,N\\times N\\times N\\,$ 个点，间距为 $\\,h=2L/(N-1)\\,$。\n- 在立方体域的所有面上施加均匀狄利克雷边界条件 $\\,\\Phi=0\\,$。\n- 实现一个几何多重网格 V 循环求解器来计算数值解 $\\,\\Phi_h\\,$，使用：\n  - 加权雅可比平滑，权重为 $\\,\\omega\\in(0,1)\\,$，并在每个层级上进行固定次数的前平滑和后平滑扫描。\n  - 从细网格到粗网格的全加权限制 (full-weighting restriction)。\n  - 从粗网格到细网格的三线性插值 (prolongation)。\n  - 当网格点数较少时，通过额外的平滑操作来求解小网格（您应选择一个合理的阈值）。\n- 构建离散的右侧项 $\\,f=4\\pi G\\rho\\,$，其中球体以原点为中心，在球内 $\\,r\\le R_{\\mathrm{s}}\\,$ 处 $\\,\\rho=\\rho_0\\,$，在球外 $\\,\\rho=0\\,$。\n\n您必须将数值解与总质量为 $\\,M=\\frac{4}{3}\\pi \\rho_0 R_{\\mathrm{s}}^3\\,$ 的均匀密度球体在无限域中的解析解（势的零点在无穷远处）进行比较。解析势 $\\,\\Phi_{\\mathrm{exact}}(r)\\,$ 为：\n- 对于 $\\,r\\ge R_{\\mathrm{s}}\\,$, $\\,\\Phi_{\\mathrm{exact}}(r)=-\\dfrac{G M}{r}\\,$。\n- 对于 $\\,r\\le R_{\\mathrm{s}}\\,$, $\\,\\Phi_{\\mathrm{exact}}(r)=-\\dfrac{G M}{2R_{\\mathrm{s}}^3}\\left(3R_{\\mathrm{s}}^2-r^2\\right)\\,$。\n\n通过对所有内部网格点（不包括边界层）的内部相对 $\\,L^2\\,$ 误差来定义一个定量误差度量：\n$$\n\\varepsilon = \\sqrt{\\frac{\\sum_{i,j,k\\in\\text{interior}}\\left(\\Phi_h-\\Phi_{\\mathrm{exact}}\\right)^2}{\\sum_{i,j,k\\in\\text{interior}}\\Phi_{\\mathrm{exact}}^2}}.\n$$\n该度量用于检测在 $\\,r\\approx L\\,$ 处设置有限计算边界并令 $\\,\\Phi=0\\,$ 的影响。这种设置近似了无穷远处的条件，但引入了边界截断误差，该误差随着 $\\,L\\,$ 的减小而增大。\n\n在所有运行中使用无量纲单位和以下固定参数：\n- $\\,G=1\\,$，\n- $\\,\\rho_0=1\\,$，\n- $\\,R_{\\mathrm{s}}=1\\,$，\n- $\\,N=65\\,$，\n- 一个 V 循环，其中包含合理的 $\\,\\omega\\,$ 选择、前平滑和后平滑扫描次数，以及一个多重网格层次结构，该结构在每次粗化时将每个轴上的点数（大约）减半，直到达到一个小的阈值。当相对残差范数降至容差 $\\,10^{-10}\\,$ 以下或达到固定的最大 V 循环次数时，终止外层迭代。\n\n测试套件：\n评估以下三种外部半域尺寸 $\\,L\\,$（固定 $\\,R_{\\mathrm{s}}=1\\,$）的 $\\,\\varepsilon\\,$ 值，这三种情况用于探究当外部边界向内移动时的边界截断效应：\n- 情况 A: $\\,L=4.0\\,R_{\\mathrm{s}}\\,$，\n- 情况 B: $\\,L=2.0\\,R_{\\mathrm{s}}\\,$，\n- 情况 C: $\\,L=1.25\\,R_{\\mathrm{s}}\\,$。\n\n您的程序必须按顺序计算并返回情况 A、B、C 的三个内部相对 $\\,L^2\\,$ 误差。要求的最终输出格式为：\n- 单行输出，包含一个用方括号括起来的、由逗号分隔的三个浮点数误差列表，没有空格，例如 $\\,\\texttt{[e\\_A,e\\_B,e\\_C]}\\,$，其中每个条目都是标准的十进制或科学记数法浮点数。\n\n不需要物理单位；所有量都是无量纲的。此问题不涉及角度，因此无需指定角度单位。此问题不使用百分比。报告的数值必须是浮点数。请确保求解器和比较过程是自包含的，不需要输入。程序不得从文件或网络读取数据，也不得提示用户输入。为了分离改变 $\\,L\\,$ 的影响，三种测试中的算法选择必须保持一致。实现语言可以是任何通用的现代语言；但是，您提供的最终答案必须是可执行的 Python 代码。对于所有三个测试用例，其物理学、离散化和算法选择必须在科学上是合理且自洽的。", "solution": "该问题要求在一个立方体域上，为带有均匀狄利克雷边界条件的三维泊松方程 $\\nabla^2 \\Phi = 4\\pi G \\rho$ 实现一个几何多重网格求解器。然后将此数值解与已知的解析解进行比较，以量化由有限计算域引入的误差。整个过程封装在一个 Python 程序中，该程序计算三种不同域尺寸下的误差。\n\n### 1. 离散化与问题设置\n连续的泊松方程在域 $[-L, L]^3$ 上一个大小为 $N \\times N \\times N$ 的均匀笛卡尔网格上进行离散化。网格间距为 $h = 2L / (N-1)$。对拉普拉斯算子 $\\nabla^2$ 使用二阶中心有限差分格式，我们得到了关于每个网格点上势 $\\Phi_h$ 的线性方程组 $A_h \\Phi_h = f_h$。算子 $A_h$ 应用于网格点 $(i,j,k)$ 的形式为：\n$$ (A_h \\Phi_h)_{i,j,k} = \\frac{\\Phi_{i+1,j,k} + \\Phi_{i-1,j,k} + \\Phi_{i,j+1,k} + \\Phi_{i,j-1,k} + \\Phi_{i,j,k+1} + \\Phi_{i,j,k-1} - 6\\Phi_{i,j,k}}{h^2} $$\n这个 7 点格式应用于所有内部网格点，即索引 $i,j,k \\in \\{1, \\dots, N-2\\}$。通过将网格边界（索引为 0 和 N-1）上的 $\\Phi_h$ 值固定为零来施加边界条件 $\\Phi_h=0$。\n\n右侧项 (RHS) $f_h$ 代表源项 $4\\pi G \\rho$。对于一个以原点为中心、半径为 $R_s$、密度为 $\\rho_0$ 的均匀球体，每个网格点 $(x_i, y_j, z_k)$ 处的 $f_h$ 值，如果其径向距离 $r = \\sqrt{x_i^2 + y_j^2 + z_k^2}$ 小于或等于 $R_s$，则为 $4\\pi G \\rho_0$，否则为 0。\n\n### 2. 几何多重网格 V 循环求解器\n为了高效求解该线性系统，我们采用几何多重网格方法。该方法在一系列从细网格（0级）到最粗网格的层次结构上操作。网格尺寸 $N=65$ 非常方便，因为 $N-1=64=2^6$，这允许进行多次粗化步骤，在每个维度上将网格点数减半。V 循环算法作为一个递归过程实现：\n\n1.  **平滑**：在给定的网格层级上，通过应用几次平滑器扫描来改进当前解的近似值。我们使用权重为 $\\omega = 2/3$ 的加权雅可比方法。点 $(i,j,k)$ 的更新规则是：\n    $$ \\Phi_{i,j,k}^{\\text{new}} = (1-\\omega)\\Phi_{i,j,k}^{\\text{old}} + \\frac{\\omega}{6} \\left( \\sum_{\\text{neighbors}} \\Phi_{\\text{neighbor}}^{\\text{old}} - h^2 f_{i,j,k} \\right) $$\n    在转移到更粗的网格之前，执行固定次数的前平滑扫描（$\\nu_1=2$）。\n\n2.  **残差计算与限制 (Restriction)**：前平滑后，计算残差 $r_h = f_h - A_h \\Phi_h$。该残差代表当前解中的误差。然后使用一个限制算子将其转移到下一个更粗的网格。我们使用全加权限制，其中粗网格点上的值是 $3\\times3\\times3$ 块中 27 个对应细网格点的加权平均值。\n\n3.  **递归求解**：在更粗的网格上求解残差方程 $A_{2h} e_{2h} = r_{2h}$ 以得到误差项 $e_{2h}$。这是通过递归调用 V 循环函数来完成的。\n\n4.  **粗网格求解**：递归在最粗的层级停止（此处选择为 $5 \\times 5 \\times 5$ 的网格）。在此层级，方程不是直接求解，而是通过应用更多次数的平滑扫描（例如 20 次）来近似求解，因为系统规模很小。\n\n5.  **延长 (Prolongation) 与校正**：将在粗网格上计算出的校正量 $e_{2h}$ 使用一个延长算子插值回细网格。我们使用三线性插值。然后将插值后的校正量加到细网格的解上：$\\Phi_h \\leftarrow \\Phi_h + e_h$。\n\n6.  **后平滑**：最后，应用几次后平滑扫描（$\\nu_2=2$），以抑制由延长步骤引入的高频误差。\n\n整个 V 循环过程不断迭代，直到残差的相对 $L^2$-范数, $\\|f_h - A_h \\Phi_h\\| / \\|f_h\\|$ 降至容差 $10^{-10}$ 以下。\n\n### 3. 误差分析\n获得数值解 $\\Phi_h$ 后，将其与无限域中均匀球体的精确解析解 $\\Phi_{\\text{exact}}(r)$ 进行比较。数值解与精确解之间的差异主要来自两个来源：离散化误差（由于有限的 $h$）和边界截断误差（由于有限的域尺寸 $L$ 和 $\\Phi=0$ 的边界条件，这只是对 $\\Phi(\\infty)=0$ 的近似）。\n\n该问题关注边界截断误差，通过改变 $L$ 同时保持所有其他参数固定来探究该误差。误差使用内部相对 $L^2$ 误差进行量化：\n$$ \\varepsilon = \\sqrt{\\frac{\\sum_{i,j,k\\in\\text{interior}}\\left(\\Phi_h - \\Phi_{\\text{exact}}\\right)^2}{\\sum_{i,j,k\\in\\text{interior}}\\Phi_{\\mathrm{exact}}^2}} $$\n求和是在所有内部网格点上进行的，不包括边界层。当计算边界 $L$ 移近源球体（即 $L$ 减小）时，在 $r \\approx L$ 处的人为边界条件 $\\Phi=0$ 对于远场行为 $\\Phi \\propto -1/r$ 的近似效果会变差，截断误差 $\\varepsilon$ 预计会增加。程序在 $R_s=1$ 的情况下计算了 $L \\in \\{4.0, 2.0, 1.25\\}$ 时的这个误差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import ndimage\n\ndef solve():\n    \"\"\"\n    Main function to solve the Poisson equation for gravity and compute errors.\n    \"\"\"\n\n    # --- Multigrid and Simulation Parameters ---\n    G_CONST = 1.0\n    RHO_0 = 1.0\n    R_S = 1.0\n    GRID_N = 65\n    \n    # Multigrid settings\n    OMEGA = 2.0 / 3.0  # Weighted Jacobi parameter\n    PRE_SWEEPS = 2\n    POST_SWEEPS = 2\n    COARSE_GRID_SWEEPS = 20\n    MIN_GRID_SIZE = 5\n    MAX_V_CYCLES = 100\n    TOLERANCE = 1e-10\n\n    # --- Helper Functions for Multigrid ---\n\n    def apply_laplacian(phi, h):\n        \"\"\"Computes the action of the 7-point stencil Laplacian on phi.\"\"\"\n        lap_phi = np.zeros_like(phi)\n        # Vectorized operation on interior points\n        lap_phi[1:-1, 1:-1, 1:-1] = (\n            phi[0:-2, 1:-1, 1:-1] + phi[2:, 1:-1, 1:-1] +\n            phi[1:-1, 0:-2, 1:-1] + phi[1:-1, 2:, 1:-1] +\n            phi[1:-1, 1:-1, 0:-2] + phi[1:-1, 1:-1, 2:] -\n            6.0 * phi[1:-1, 1:-1, 1:-1]\n        ) / h**2\n        return lap_phi\n\n    def smoother(phi, f, h, num_sweeps):\n        \"\"\"Applies a specified number of weighted Jacobi smoothing sweeps.\"\"\"\n        for _ in range(num_sweeps):\n            phi_old = phi.copy()\n            # Vectorized update for all interior points\n            sum_neighbors = (\n                phi_old[0:-2, 1:-1, 1:-1] + phi_old[2:, 1:-1, 1:-1] +\n                phi_old[1:-1, 0:-2, 1:-1] + phi_old[1:-1, 2:, 1:-1] +\n                phi_old[1:-1, 1:-1, 0:-2] + phi_old[1:-1, 1:-1, 2:]\n            )\n            \n            phi[1:-1, 1:-1, 1:-1] = (1.0 - OMEGA) * phi_old[1:-1, 1:-1, 1:-1] + \\\n                                   OMEGA / 6.0 * (sum_neighbors - h**2 * f[1:-1, 1:-1, 1:-1])\n        return phi\n\n    def restrict(r_fine):\n        \"\"\"Restricts a fine grid residual to a coarse grid using full-weighting.\"\"\"\n        W1d = np.array([0.25, 0.5, 0.25])\n        W3d = np.einsum('i,j,k->ijk', W1d, W1d, W1d)\n        \n        convolved = ndimage.convolve(r_fine, W3d, mode='constant', cval=0.0)\n        r_coarse = convolved[::2, ::2, ::2]\n        return r_coarse\n\n    def prolong(e_coarse):\n        \"\"\"Prolongs a coarse grid correction to a fine grid using trilinear interpolation.\"\"\"\n        Nc = e_coarse.shape[0]\n        Nf = (Nc - 1) * 2 + 1\n        e_fine = np.zeros((Nf, Nf, Nf))\n\n        # Injection\n        e_fine[::2, ::2, ::2] = e_coarse\n\n        # Interpolate along axes\n        e_fine[1::2, ::2, ::2] = 0.5 * (e_fine[:-2:2, ::2, ::2] + e_fine[2::2, ::2, ::2])\n        e_fine[::2, 1::2, ::2] = 0.5 * (e_fine[::2, :-2:2, ::2] + e_fine[::2, 2::2, ::2])\n        e_fine[::2, ::2, 1::2] = 0.5 * (e_fine[::2, ::2, :-2:2] + e_fine[::2, ::2, 2::2])\n\n        # Interpolate on faces\n        e_fine[1::2, 1::2, ::2] = 0.25 * (e_fine[:-2:2, :-2:2, ::2] + e_fine[2::2, :-2:2, ::2] +\n                                       e_fine[:-2:2, 2::2, ::2] + e_fine[2::2, 2::2, ::2])\n        e_fine[1::2, ::2, 1::2] = 0.25 * (e_fine[:-2:2, ::2, :-2:2] + e_fine[2::2, ::2, :-2:2] +\n                                       e_fine[:-2:2, ::2, 2::2] + e_fine[2::2, ::2, 2::2])\n        e_fine[::2, 1::2, 1::2] = 0.25 * (e_fine[::2, :-2:2, :-2:2] + e_fine[::2, 2::2, :-2:2] +\n                                       e_fine[::2, :-2:2, 2::2] + e_fine[::2, 2::2, 2::2])\n        \n        # Interpolate in centers\n        e_fine[1::2, 1::2, 1::2] = 0.125 * (e_fine[:-2:2, :-2:2, :-2:2] + e_fine[2::2, :-2:2, :-2:2] +\n                                           e_fine[:-2:2, 2::2, :-2:2] + e_fine[2::2, 2::2, :-2:2] +\n                                           e_fine[:-2:2, :-2:2, 2::2] + e_fine[2::2, :-2:2, 2::2] +\n                                           e_fine[:-2:2, 2::2, 2::2] + e_fine[2::2, 2::2, 2::2])\n        return e_fine\n\n    def v_cycle_recursive(phi, f, level, h_levels, grid_sizes):\n        \"\"\"A single recursive V-cycle.\"\"\"\n        h = h_levels[level]\n        \n        # 1. Pre-smoothing\n        phi = smoother(phi, f, h, PRE_SWEEPS)\n\n        # 2. Coarse grid correction\n        if grid_sizes[level] == MIN_GRID_SIZE:\n            # Coarsest level: solve by more smoothing\n            phi = smoother(phi, f, h, COARSE_GRID_SWEEPS)\n        else:\n            # Compute residual\n            residual = f - apply_laplacian(phi, h)\n            \n            # Restrict residual to coarse grid\n            r_coarse = restrict(residual)\n            e_coarse = np.zeros_like(r_coarse)\n            \n            # Recursive call\n            e_coarse = v_cycle_recursive(e_coarse, r_coarse, level + 1, h_levels, grid_sizes)\n            \n            # Prolongate correction and add to solution\n            e_fine = prolong(e_coarse)\n            phi += e_fine\n        \n        # 3. Post-smoothing\n        phi = smoother(phi, f, h, POST_SWEEPS)\n        return phi\n\n    def run_simulation_for_L(L):\n        \"\"\"Performs a full simulation for a given domain size L.\"\"\"\n        # 1. Setup Grid and RHS\n        h = 2.0 * L / (GRID_N - 1)\n        coords = np.linspace(-L, L, GRID_N)\n        xx, yy, zz = np.meshgrid(coords, coords, coords, indexing='ij')\n        rr = np.sqrt(xx**2 + yy**2 + zz**2)\n\n        rho = np.zeros((GRID_N, GRID_N, GRID_N))\n        rho[rr = R_S] = RHO_0\n        f_source = 4.0 * np.pi * G_CONST * rho\n\n        # 2. Setup Multigrid Hierarchy\n        grid_sizes = []\n        h_levels = []\n        n_curr, h_curr = GRID_N, h\n        while n_curr >= MIN_GRID_SIZE:\n            grid_sizes.append(n_curr)\n            h_levels.append(h_curr)\n            if (n_curr - 1) % 2 != 0: break\n            n_curr = (n_curr - 1) // 2 + 1\n            h_curr *= 2.0\n\n        # 3. Run Multigrid Solver\n        phi_h = np.zeros((GRID_N, GRID_N, GRID_N))\n        \n        # Initial residual norm for convergence check\n        res_0_norm = np.linalg.norm(f_source)\n        if res_0_norm == 0.0: res_0_norm = 1.0\n\n        for cycle in range(MAX_V_CYCLES):\n            phi_h = v_cycle_recursive(phi_h, f_source, 0, h_levels, grid_sizes)\n            \n            residual = f_source - apply_laplacian(phi_h, h)\n            res_norm = np.linalg.norm(residual)\n            \n            if res_norm / res_0_norm  TOLERANCE:\n                break\n        \n        # 4. Compute Error\n        M = 4.0 / 3.0 * np.pi * RHO_0 * R_S**3\n        phi_exact = np.zeros((GRID_N, GRID_N, GRID_N))\n        \n        mask_in = rr = R_S\n        phi_exact[mask_in] = -G_CONST * M / (2.0 * R_S**3) * (3.0 * R_S**2 - rr[mask_in]**2)\n        \n        mask_out = rr > R_S\n        rr_safe = np.copy(rr)\n        rr_safe[rr_safe == 0] = 1.0  # Avoid division by zero, masked out anyway\n        phi_exact[mask_out] = -G_CONST * M / rr_safe[mask_out]\n\n        # Interior L2 relative error\n        phi_h_int = phi_h[1:-1, 1:-1, 1:-1]\n        phi_exact_int = phi_exact[1:-1, 1:-1, 1:-1]\n\n        err_num = np.sum((phi_h_int - phi_exact_int)**2)\n        err_den = np.sum(phi_exact_int**2)\n        \n        if err_den == 0: return 0.0\n        \n        epsilon = np.sqrt(err_num / err_den)\n        return epsilon\n\n    # --- Main Execution Logic ---\n    test_cases = [4.0, 2.0, 1.25]\n    results = []\n    for L_val in test_cases:\n        error = run_simulation_for_L(L_val * R_S)\n        results.append(error)\n    \n    print(f\"[{','.join(f'{r:.7e}' for r in results)}]\")\n\nsolve()\n```", "id": "3524177"}]}