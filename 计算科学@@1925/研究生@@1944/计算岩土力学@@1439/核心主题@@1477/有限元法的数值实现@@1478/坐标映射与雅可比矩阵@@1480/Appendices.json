{"hands_on_practices": [{"introduction": "此练习提供了计算雅可比矩阵的基础实践。通过一个具体的双线性等参映射示例，您将直接体验构成雅可比矩阵的偏导数计算，将抽象的定义与具体的数值结果联系起来。这项技能是理解有限元方法中计算域如何变换的基石 [@problem_id:2216463]。", "problem": "在求解偏微分方程的数值方法中，通常使用变换将复杂的物理域映射到简单的、结构化的计算域上。考虑这样一个变换，它将 $(\\xi, \\eta)$ 坐标系中由 $-1 \\le \\xi \\le 1$ 和 $-1 \\le \\eta \\le 1$ 定义的方形参考域，映射到物理 $(x, y)$ 坐标系中的一个四边形区域。\n\n该变换由以下映射函数给出：\n$$\nx(\\xi, \\eta) = \\frac{1}{4} \\left[ (1-\\xi)(1-\\eta)x_1 + (1+\\xi)(1-\\eta)x_2 + (1+\\xi)(1+\\eta)x_3 + (1-\\xi)(1+\\eta)x_4 \\right]\n$$\n$$\ny(\\xi, \\eta) = \\frac{1}{4} \\left[ (1-\\xi)(1-\\eta)y_1 + (1+\\xi)(1-\\eta)y_2 + (1+\\xi)(1+\\eta)y_3 + (1-\\xi)(1+\\eta)y_4 \\right]\n$$\n其中 $(x_i, y_i)$（$i=1, 2, 3, 4$）是物理平面中四边形顶点的坐标，对应于参考方形的角点。顶点按逆时针方向编号，其坐标如下：\n$P_1 = (x_1, y_1) = (1, 1)$\n$P_2 = (x_2, y_2) = (5, 2)$\n$P_3 = (x_3, y_3) = (4, 5)$\n$P_4 = (x_4, y_4) = (2, 4)$\n\n你的任务是计算该变换的雅可比矩阵 $J = \\frac{\\partial(x,y)}{\\partial(\\xi,\\eta)}$ 在参考方形中心点 $(\\xi, \\eta) = (0, 0)$ 处的值。请将答案表示为一个包含精确有理数（分数）的 2x2 矩阵。", "solution": "给定双线性等参映射\n$$\nx(\\xi,\\eta)=\\frac{1}{4}\\left[(1-\\xi)(1-\\eta)x_{1}+(1+\\xi)(1-\\eta)x_{2}+(1+\\xi)(1+\\eta)x_{3}+(1-\\xi)(1+\\eta)x_{4}\\right],\n$$\n$$\ny(\\xi,\\eta)=\\frac{1}{4}\\left[(1-\\xi)(1-\\eta)y_{1}+(1+\\xi)(1-\\eta)y_{2}+(1+\\xi)(1+\\eta)y_{3}+(1-\\xi)(1+\\eta)y_{4}\\right].\n$$\n雅可比矩阵为 $J=\\partial(x,y)/\\partial(\\xi,\\eta)$，其元素为 $J_{11}=\\partial x/\\partial \\xi$，$J_{12}=\\partial x/\\partial \\eta$，$J_{21}=\\partial y/\\partial \\xi$，$J_{22}=\\partial y/\\partial \\eta$。进行符号微分：\n$$\n\\frac{\\partial x}{\\partial \\xi}=\\frac{1}{4}\\left[-(1-\\eta)x_{1}+(1-\\eta)x_{2}+(1+\\eta)x_{3}-(1+\\eta)x_{4}\\right],\n$$\n$$\n\\frac{\\partial x}{\\partial \\eta}=\\frac{1}{4}\\left[-(1-\\xi)x_{1}-(1+\\xi)x_{2}+(1+\\xi)x_{3}+(1-\\xi)x_{4}\\right],\n$$\n$$\n\\frac{\\partial y}{\\partial \\xi}=\\frac{1}{4}\\left[-(1-\\eta)y_{1}+(1-\\eta)y_{2}+(1+\\eta)y_{3}-(1+\\eta)y_{4}\\right],\n$$\n$$\n\\frac{\\partial y}{\\partial \\eta}=\\frac{1}{4}\\left[-(1-\\xi)y_{1}-(1+\\xi)y_{2}+(1+\\xi)y_{3}+(1-\\xi)y_{4}\\right].\n$$\n在中心点 $(\\xi,\\eta)=(0,0)$ 处，我们有 $(1\\pm \\xi)=(1\\pm \\eta)=1$，因此\n$$\n\\left.\\frac{\\partial x}{\\partial \\xi}\\right|_{(0,0)}=\\frac{1}{4}\\left[-x_{1}+x_{2}+x_{3}-x_{4}\\right],\\quad\n\\left.\\frac{\\partial x}{\\partial \\eta}\\right|_{(0,0)}=\\frac{1}{4}\\left[-x_{1}-x_{2}+x_{3}+x_{4}\\right],\n$$\n$$\n\\left.\\frac{\\partial y}{\\partial \\xi}\\right|_{(0,0)}=\\frac{1}{4}\\left[-y_{1}+y_{2}+y_{3}-y_{4}\\right],\\quad\n\\left.\\frac{\\partial y}{\\partial \\eta}\\right|_{(0,0)}=\\frac{1}{4}\\left[-y_{1}-y_{2}+y_{3}+y_{4}\\right].\n$$\n代入给定的顶点坐标 $P_{1}=(x_{1},y_{1})=(1,1)$，$P_{2}=(5,2)$，$P_{3}=(4,5)$，$P_{4}=(2,4)$，计算可得\n$$\n\\left.\\frac{\\partial x}{\\partial \\xi}\\right|_{(0,0)}=\\frac{1}{4}(-1+5+4-2)=\\frac{6}{4}=\\frac{3}{2},\\quad\n\\left.\\frac{\\partial x}{\\partial \\eta}\\right|_{(0,0)}=\\frac{1}{4}(-1-5+4+2)=0,\n$$\n$$\n\\left.\\frac{\\partial y}{\\partial \\xi}\\right|_{(0,0)}=\\frac{1}{4}(-1+2+5-4)=\\frac{2}{4}=\\frac{1}{2},\\quad\n\\left.\\frac{\\partial y}{\\partial \\eta}\\right|_{(0,0)}=\\frac{1}{4}(-1-2+5+4)=\\frac{6}{4}=\\frac{3}{2}.\n$$\n因此，在 $(\\xi,\\eta)=(0,0)$ 处的雅可比矩阵为\n$$\nJ(0,0)=\\begin{pmatrix}\n\\frac{3}{2} & 0 \\\\\n\\frac{1}{2} & \\frac{3}{2}\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{3}{2} & 0 \\\\ \\frac{1}{2} & \\frac{3}{2}\\end{pmatrix}}$$", "id": "2216463"}, {"introduction": "在基础计算之上，本练习探讨了坐标映射的复杂性与数值积分精度之间的关键联系。您将研究一个雅可比行列式不为常数的弯曲单元，并量化求积规则的选择如何影响积分计算的精度。此实践突显了为何理解雅可比行列式在整个单元上的行为对于确保有限元解的可靠性至关重要 [@problem_id:3511595]。", "problem": "要求您研究在与计算岩土力学相关的平面等参映射中，雅可比行列式的变异性对求积误差的影响。从多重积分的变量替换和雅可比矩阵的定义入手。考虑一个从参考正方形 $\\hat{\\Omega} = [-1,1]\\times[-1,1]$ 到由曲率振幅 $a \\in \\mathbb{R}$ 参数化的弯曲物理单元 $\\Omega$ 的光滑双射映射：\n$$\n\\boldsymbol{x}(\\boldsymbol{\\xi}) = \\begin{bmatrix}\nx(\\xi,\\eta) \\\\\ny(\\xi,\\eta)\n\\end{bmatrix} = \\begin{bmatrix}\n\\xi + \\dfrac{a}{2}(\\xi^2 - 1)\\,\\eta \\\\\n\\eta + \\dfrac{a}{2}\\,\\xi\\,(\\eta^2 - 1)\n\\end{bmatrix}, \\quad \\boldsymbol{\\xi} = \\begin{bmatrix}\\xi\\\\ \\eta\\end{bmatrix} \\in \\hat{\\Omega}.\n$$\n对于非零的 $a$，此构造在保持参考边界的同时扭曲了内部，并为弯曲几何形状产生了非恒定的雅可比行列式。雅可比矩阵为 $J(\\boldsymbol{\\xi}) = \\dfrac{\\partial \\boldsymbol{x}}{\\partial \\boldsymbol{\\xi}}$，变量替换公式表明，对于一个足够光滑的标量场 $f(\\boldsymbol{x})$，\n$$\n\\int_{\\Omega} f(\\boldsymbol{x})\\, d\\boldsymbol{x} = \\int_{\\hat{\\Omega}} f(\\boldsymbol{x}(\\boldsymbol{\\xi}))\\, \\det J(\\boldsymbol{\\xi}) \\, d\\boldsymbol{\\xi}.\n$$\n\n为了单独研究 $\\det J(\\boldsymbol{\\xi})$ 在求积误差中的作用，考虑常数场 $f(\\boldsymbol{x}) = 1$ 的体积积分，因此\n$$\nI(a) \\equiv \\int_{\\Omega} 1\\, d\\boldsymbol{x} = \\int_{\\hat{\\Omega}} \\det J(\\boldsymbol{\\xi};a) \\, d\\boldsymbol{\\xi}.\n$$\n根据构造，当映射保持为正方形到其自身的微分同胚时，$I(a)$ 等于正方形的面积，即 $I(a) = 4$，而 $\\det J(\\boldsymbol{\\xi};a)$ 量化了局部度量畸变。在 $\\hat{\\Omega}$ 上的数值求积采用阶数为 $q$ 的张量积高斯-勒让德法则，其横坐标为 $\\{\\xi_i\\}_{i=1}^q$、$\\{\\eta_j\\}_{j=1}^q$，权重为 $\\{w_i\\}_{i=1}^q$、$\\{w_j\\}_{j=1}^q$，产生近似值\n$\nI_q(a) = \\sum_{i=1}^{q} \\sum_{j=1}^{q} w_i w_j \\, \\det J(\\xi_i,\\eta_j;a).\n$\n因为 $f(\\boldsymbol{x})=1$，任何求积误差都完全源于 $\\det J(\\boldsymbol{\\xi};a)$ 在 $\\hat{\\Omega}$ 上的变异性和光滑性，以及所选的求积阶数 $q$。\n\n您的任务是编写一个完整的程序，该程序：\n- 实现上述映射 $\\boldsymbol{x}(\\boldsymbol{\\xi})$。\n- 推导并计算雅可比矩阵 $J(\\boldsymbol{\\xi})$ 及其行列式 $\\det J(\\boldsymbol{\\xi};a)$。\n- 使用阶数为 $q$ 的张量积高斯-勒让德求积法来近似 $I(a)$，从而得到 $I_q(a)$。\n- 使用一个通过在 $\\hat{\\Omega}$ 上进行高阶高斯-勒让德张量积求积计算得到的高精度参考值 $I_{\\text{ref}}(a)$，作为误差估计的基准。您必须使用足够大的阶数来数值构造 $I_{\\text{ref}}(a)$，以使其误差与目标求积阶数的误差相比可以忽略不计。\n- 计算绝对求积误差 $E(a,q) = \\lvert I_q(a) - I_{\\text{ref}}(a)\\rvert$。\n\n您可以使用的基本原理：\n- 多重积分的变量替换公式。\n- 雅可比矩阵及其行列式的定义。\n- 区间 $[-1,1]$ 上的高斯-勒让德求积及其张量积扩展的性质。\n\n设计一套曲率振幅和求积阶数的测试组，以探究 $\\det J$ 变异性对 $E(a,q)$ 的影响：\n- 曲率振幅 $a \\in \\{0, 0.25, 0.5, 0.9\\}$，范围从仿射映射到高度弯曲但非退化的几何形状。\n- 求积阶数 $q \\in \\{1,2,3\\}$，从低到中等精度。\n\n对于每一对 $(a,q)$，其中 $a$ 按顺序 $[0, 0.25, 0.5, 0.9]$ 迭代，对于每个 $a$，$q$ 按顺序 $[1,2,3]$ 迭代，计算 $E(a,q)$。您的程序必须只输出一行结果，该结果是一个用方括号括起来的浮点数逗号分隔列表，顺序如下：\n$$\n[E(0,1), E(0,2), E(0,3), E(0.25,1), E(0.25,2), E(0.25,3), E(0.5,1), E(0.5,2), E(0.5,3), E(0.9,1), E(0.9,2), E(0.9,3)].\n$$\n\n注意：\n- 由于积分是无量纲的，因此不需要物理单位。\n- 不使用角度。\n- 必须在您的程序中选择高阶参考求积法，并在您的解题思路中证明其合理性，以确保其误差与报告值相比可以忽略不计。", "solution": "用户想要解决一个与计算岩土力学相关的数值分析问题。\n\n### 第 1 步：提取已知信息\n- **映射函数**：从具有坐标 $\\boldsymbol{\\xi} = [\\xi, \\eta]^T$ 的参考正方形 $\\hat{\\Omega} = [-1,1]\\times[-1,1]$ 到具有坐标 $\\boldsymbol{x} = [x, y]^T$ 的物理单元 $\\Omega$。\n$$\n\\boldsymbol{x}(\\boldsymbol{\\xi}) = \\begin{bmatrix}\nx(\\xi,\\eta) \\\\\ny(\\xi,\\eta)\n\\end{bmatrix} = \\begin{bmatrix}\n\\xi + \\dfrac{a}{2}(\\xi^2 - 1)\\,\\eta \\\\\n\\eta + \\dfrac{a}{2}\\,\\xi\\,(\\eta^2 - 1)\n\\end{bmatrix}\n$$\n- **曲率参数**：$a \\in \\mathbb{R}$。\n- **雅可比矩阵**：$J(\\boldsymbol{\\xi}) = \\dfrac{\\partial \\boldsymbol{x}}{\\partial \\boldsymbol{\\xi}}$。\n- **目标积分**：通过变量替换计算的物理单元 $\\Omega$ 的面积。\n$$\nI(a) \\equiv \\int_{\\Omega} 1\\, d\\boldsymbol{x} = \\int_{\\hat{\\Omega}} \\det J(\\boldsymbol{\\xi};a) \\, d\\boldsymbol{\\xi}\n$$\n- **数值求积**：阶数为 $q$ 的张量积高斯-勒让德法则。\n$$\nI_q(a) = \\sum_{i=1}^{q} \\sum_{j=1}^{q} w_i w_j \\, \\det J(\\xi_i,\\eta_j;a)\n$$\n- **误差度量**：绝对求积误差 $E(a,q) = \\lvert I_q(a) - I_{\\text{ref}}(a)\\rvert$，其中 $I_{\\text{ref}}(a)$ 是一个高精度的参考值。\n- **测试参数**：\n    - 曲率振幅 $a \\in \\{0, 0.25, 0.5, 0.9\\}$。\n    - 求积阶数 $q \\in \\{1, 2, 3\\}$。\n- **输出格式**：一个包含 $E(a,q)$ 浮点值的单行逗号分隔列表，按 $a$ 排序，然后按 $q$ 排序。\n\n### 第 2 步：使用提取的已知信息进行验证\n对问题进行验证。\n- **科学依据**：该问题植根于多元微积分（变量替换、雅可比矩阵）和数值分析（高斯-勒让德求积）的基本原理。等参映射的概念是有限元方法的核心，特别是在计算力学和岩土力学中。该设置在科学上是合理的。\n- **适定性**：该问题提供了继续进行所需的所有必要定义和数据。映射是光滑的。要积分的函数 ($\\det J$) 定义明确。数值方法已指定。测试组的参数是明确的。\n- **客观性**：该问题使用精确的数学语言陈述，没有主观性或歧义。\n\n一项解析检查证实了问题的内部一致性。让我们推导雅可比行列式：\n偏导数是：\n$\\frac{\\partial x}{\\partial \\xi} = 1 + a\\xi\\eta$, $\\frac{\\partial x}{\\partial \\eta} = \\frac{a}{2}(\\xi^2 - 1)$\n$\\frac{\\partial y}{\\partial \\xi} = \\frac{a}{2}(\\eta^2 - 1)$, $\\frac{\\partial y}{\\partial \\eta} = 1 + a\\xi\\eta$\n行列式是：\n$$\n\\det J(\\boldsymbol{\\xi}; a) = (1 + a\\xi\\eta)^2 - \\frac{a^2}{4}(\\xi^2 - 1)(\\eta^2 - 1)\n$$\n这是一个二元多项式。$\\xi$ 的最高次幂是 2，$\\eta$ 的最高次幂也是 2。\n一维 $q$ 点高斯-勒让德法则能精确积分最高为 $2q-1$ 次的多项式。为了使张量积法则对 $\\det J$ 精确，一维法则必须对 2 次多项式精确。这要求 $2q-1 \\ge 2$，即 $q \\ge 1.5$。因此，阶数 $q=2$（或更高）的高斯-勒让德法则将精确积分 $\\det J$。\n这意味着对于 $q=2$ 和 $q=3$，计算出的积分 $I_q(a)$ 将与精确值相同，因此误差 $E(a,2)$ 和 $E(a,3)$ 将为零（在机器精度范围内）。\n可以解析地确认积分的精确值为 $I(a) = 4$，如问题所述。\n对于 $q=1$，张量积法则在 $(\\xi,\\eta)=(0,0)$ 处使用一个点，权重为 4。\n$I_1(a) = 4 \\cdot \\det J(0,0;a) = 4 \\cdot (1 - \\frac{a^2}{4}) = 4 - a^2$。\n误差为 $E(a,1) = |I_1(a) - I(a)| = |(4-a^2)-4| = a^2$。\n只要在 $\\hat{\\Omega}$ 上 $\\det J > 0$，该映射就是微分同胚。对于给定的 $a$ 值，最大值为 $a=0.9$，此条件成立。对于 $|a|=1$，行列式在边界处变为零，但 $a=0.9$ 安全地处于非退化范围内。\n\n该问题内部一致，有科学依据，且适定。\n\n### 第 3 步：结论与行动\n该问题是**有效的**。将提供一个解决方案。\n\n### 基于原则的设计\n解决方案首先实现雅可比行列式 $\\det J(\\boldsymbol{\\xi}; a)$ 的解析公式。然后开发一个通用函数，使用任意阶数 $q$ 的张量积高斯-勒让德求积法则来计算参考正方形 $\\hat{\\Omega}$ 上的二维积分。该函数利用 `scipy.special.roots_legendre` 例程来获取区间 $[-1,1]$ 上所需的一维求积横坐标和权重。\n\n算法的核心涉及对每个指定的曲率振幅 $a$ 进行两个主要计算：\n1.  **参考积分 $I_{\\text{ref}}(a)$**：计算积分的一个高精度参考值。根据我们的分析，任何求积阶数 $q \\ge 2$ 都能得到精确结果。为了遵守问题中“高阶”法则的要求，并提供一个稳健的数值基准，我们选择一个远大于测试阶数的参考阶数 $q_{\\text{ref}}$（例如，$q_{\\text{ref}}=20$）。得到的值 $I_{\\text{ref}}(a)$ 在机器精度范围内将与解析值 4.0 在数值上相等。\n\n2.  **近似积分 $I_q(a)$**：对于每个测试阶数 $q \\in \\{1, 2, 3\\}$，使用相同的求积函数计算积分。\n\n最后，对于每一对 $(a,q)$，计算绝对误差 $E(a,q) = \\lvert I_q(a) - I_{\\text{ref}}(a)\\rvert$。对所有指定的 $a$ 和 $q$ 值系统地重复该过程，并按规定的顺序收集所得误差。\n\n为了提高效率，使用 `numpy` 进行了矢量化实现。具体来说，使用 `np.meshgrid` 将来自 `roots_legendre` 的求积点扩展为二维网格。然后，在单次操作中对此整个点网格计算雅可比行列式，最终积分通过对加权值网格进行一次求和来计算。这种方法既计算高效，又使实现清晰易读。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef solve():\n    \"\"\"\n    Computes the quadrature error for the integral of the Jacobian determinant\n    of a given isoparametric mapping.\n    \"\"\"\n\n    def det_J(xi, eta, a):\n        \"\"\"\n        Calculates the determinant of the Jacobian matrix for the given mapping.\n        The function is vectorized to accept numpy arrays for xi and eta.\n\n        The Jacobian determinant is det(J) = (1 + a*xi*eta)^2 - (a/2)^2 * (xi^2 - 1) * (eta^2 - 1).\n\n        Args:\n            xi (float or np.ndarray): The reference coordinate(s) in the first direction.\n            eta (float or np.ndarray): The reference coordinate(s) in the second direction.\n            a (float): The curvature amplitude.\n\n        Returns:\n            float or np.ndarray: The value(s) of the Jacobian determinant.\n        \"\"\"\n        term1 = (1 + a * xi * eta)**2\n        term2 = (a / 2)**2 * (xi**2 - 1) * (eta**2 - 1)\n        return term1 - term2\n\n    def compute_integral(a, q):\n        \"\"\"\n        Approximates the integral of det(J) over the reference square [-1,1]x[-1,1]\n        using a q-point tensor-product Gauss-Legendre quadrature rule.\n\n        Args:\n            a (float): The curvature amplitude.\n            q (int): The order of the Gauss-Legendre quadrature.\n\n        Returns:\n            float: The approximate value of the integral.\n        \"\"\"\n        # Get 1D Gauss-Legendre points and weights for the interval [-1, 1]\n        points, weights = roots_legendre(q)\n\n        # Create 2D grids of points and weights for the tensor-product rule\n        xi_grid, eta_grid = np.meshgrid(points, points)\n        w_xi_grid, w_eta_grid = np.meshgrid(weights, weights)\n\n        # Evaluate the integrand (det_J) at all quadrature points simultaneously\n        integrand_values = det_J(xi_grid, eta_grid, a)\n\n        # Compute the integral by summing the weighted integrand values\n        integral = np.sum(w_xi_grid * w_eta_grid * integrand_values)\n        return integral\n\n    # Define the test cases from the problem statement.\n    a_values = [0.0, 0.25, 0.5, 0.9]\n    q_values = [1, 2, 3]\n\n    # Set a high quadrature order for the reference integral.\n    # From analysis, q_ref >= 2 is sufficient for exactness.\n    # A larger value is used to be robust and follow the problem's spirit.\n    q_ref = 20\n\n    results = []\n    # Iterate through each parameter set to compute the errors.\n    for a in a_values:\n        # Compute the \"ground truth\" reference integral for the current 'a'.\n        I_ref = compute_integral(a, q_ref)\n        \n        for q in q_values:\n            # Compute the integral for the current test order 'q'.\n            I_q = compute_integral(a, q)\n            \n            # Calculate the absolute quadrature error and append to the list.\n            error = np.abs(I_q - I_ref)\n            results.append(error)\n            \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3511595"}, {"introduction": "这最后一个高级实践将从分析转向设计，将您对雅可比矩阵的知识应用于一个实际的网格优化问题。您将实现一个基于障碍的优化算法，通过最大化最小雅可比行列式来主动改善网格质量，从而防止单元反转并增强数值稳定性。此练习展示了雅可比矩阵不仅可作为一个描述符，更可作为构建稳健岩土力学计算模型的关键控制指标 [@problem_id:3511549]。", "problem": "给定一个二维协调三角网格，该网格表示一个凸四边形域，此域被离散化为4个从单一内部顶点发出的三角形。目标是实现一种基于障碍函数的网格优化方法，通过最小化一个惩罚小单元雅可比行列式的光滑、严格凸泛函，来最大化所有单元上的最小雅可比行列式值。网格定义如下。\n\n- 几何与节点：\n  - 域为单位正方形 $\\{(x,y)\\in\\mathbb{R}^2 \\mid 0 \\le x \\le 1, 0 \\le y \\le 1\\}$。\n  - 共有5个节点：4个边界节点，按逆时针顺序列出，分别为 $(0,0)$、$(1,0)$、$(1,1)$、$(0,1)$；以及一个内部节点（中心点），其在参考构型中的初始位置为 $(0.5,0.5)$。\n  - 这4个三角形被构造为有向三元组 $(\\text{中心点}, \\text{角点}_i, \\text{角点}_{i+1})$，其中 $i \\in \\{0,1,2,3\\}$，下标对4取模，以确保在参考构型中为逆时针方向。\n\n- 从参考构型到当前构型的映射与雅可比行列式：\n  - 对于每个参考顶点为 $(\\mathbf{X}_1,\\mathbf{X}_2,\\mathbf{X}_3)$、当前顶点为 $(\\mathbf{x}_1,\\mathbf{x}_2,\\mathbf{x}_3)$ 的三角形 $e$，单元映射是仿射的：$\\mathbf{x}(\\boldsymbol{\\xi}) = \\mathbf{F}_e \\boldsymbol{\\xi} + \\mathbf{b}_e$，其中变形梯度 $\\mathbf{F}_e \\in \\mathbb{R}^{2\\times 2}$ 在单元上是恒定的。\n  - 雅可比行列式定义为 $\\det \\mathbf{J}_e = \\det \\mathbf{F}_e$，其值等于当前三角形与参考三角形的有向面积之比：$\\det \\mathbf{F}_e = \\dfrac{\\det \\left[\\mathbf{x}_2-\\mathbf{x}_1 \\ \\ \\mathbf{x}_3-\\mathbf{x}_1\\right]}{\\det \\left[\\mathbf{X}_2-\\mathbf{X}_1 \\ \\ \\mathbf{X}_3-\\mathbf{X}_1\\right]}$。\n  - 映射必须保持方向，即对于所有单元 $e$ 都有 $\\det \\mathbf{J}_e > 0$。\n\n- 目标泛函：\n  - 设 $\\phi(s)$ 为一个光滑障碍函数，当 $s \\to 0^+$ 时发散；使用 $\\phi(s) = -\\log s$。\n  - 在边界节点固定的情况下，通过最小化以下泛函来优化内部节点的位置 $\\mathbf{x}_c \\in \\mathbb{R}^2$：\n    $$E(\\mathbf{x}_c) = \\dfrac{w_r}{2} \\|\\mathbf{x}_c - \\mathbf{x}_{c,0}\\|_2^2 + w_b \\sum_{e=1}^4 \\phi\\!\\left(\\det \\mathbf{J}_e(\\mathbf{x}_c)\\right),$$\n    其中 $w_r > 0$ 是一个小的正则化权重，用于将内部节点锚定在其参考位置 $\\mathbf{x}_{c,0} = (0.5,0.5)$；$w_b > 0$ 是障碍权重。障碍函数强制要求 $\\det \\mathbf{J}_e(\\mathbf{x}_c) > 0$。\n\n- 在您的推导和实现中应使用的基本依据和建模假设：\n  - 使用有限元方法 (FEM) 中线性三角形的仿射映射，这意味着每个单元上的 $\\mathbf{F}_e$ 是恒定的。\n  - 三角形的雅可比行列式等于当前构型与参考构型之间的有符号面积缩放比。\n  - 使用经典多元微积分（链式法则、关于行列式的矩阵微积分知识）和线性代数。\n\n- 必需的算法方法：\n  - 对 $E(\\mathbf{x}_c)$ 实现一个基于梯度的下降算法，使用回溯线搜索，以在迭代过程中强制所有单元 $e$ 满足 $\\det \\mathbf{J}_e > 0$。\n  - 下降方向是 $E$ 的负梯度。\n  - 线搜索必须减小步长，直到所有 $\\det \\mathbf{J}_e$ 值的正性条件和 $E$ 的充分下降条件都得到满足。\n\n- 测试套件：\n  - 将障碍和正则化参数固定为 $w_b = 1.0$ 和 $w_r = 10^{-3}$。\n  - 使用最多200次迭代，梯度范数容差为 $10^{-10}$，Armijo回溯参数为 $\\alpha = 10^{-4}$，收缩因子为 $\\beta = 0.5$。\n  - 提供三个测试用例，它们仅在初始内部节点位置 $\\mathbf{x}_c^{(0)}$ 上有所不同：\n    1. 用例A（理想路径）：$\\mathbf{x}_c^{(0)} = (0.45, 0.55)$。\n    2. 用例B（更扭曲）：$\\mathbf{x}_c^{(0)} = (0.30, 0.70)$。\n    3. 用例C（各向异性扭曲）：$\\mathbf{x}_c^{(0)} = (0.60, 0.40)$。\n\n- 必需的输出：\n  - 对于每个用例，在优化收敛后，计算逐单元的雅可比行列式列表 $\\{\\det \\mathbf{J}_e\\}_{e=1}^4$，并报告这4个三角形中的最小值。\n  - 您的程序应生成单行输出，其中包含用逗号分隔并用方括号括起来的结果列表，顺序为 [用例A结果, 用例B结果, 用例C结果]。\n  - 将每个结果表示为四舍五入到6位小数的浮点数。", "solution": "我们利用有限元方法 (FEM) 中仿射三角形映射的第一性原理以及行列式的性质来推导梯度并设计算法。目标是最小化一个惩罚小雅可比行列式的能量，从而在保持内部节点靠近其参考位置的同时，最大化所有单元上的最小行列式值。\n\n1. 网格与映射基础：\n- 考虑一个有向三角形 $e$，其参考顶点为 $(\\mathbf{X}_1,\\mathbf{X}_2,\\mathbf{X}_3)$，当前顶点为 $(\\mathbf{x}_1,\\mathbf{x}_2,\\mathbf{x}_3)$。从参考单元到当前单元的仿射映射具有一个恒定的变形梯度：\n$$\\mathbf{F}_e = \\left[\\mathbf{x}_2-\\mathbf{x}_1 \\ \\ \\mathbf{x}_3-\\mathbf{x}_1\\right]\\left[\\mathbf{X}_2-\\mathbf{X}_1 \\ \\ \\mathbf{X}_3-\\mathbf{X}_1\\right]^{-1}.$$\n- 雅可比行列式是面积缩放因子：\n$$\\det \\mathbf{J}_e = \\det \\mathbf{F}_e = \\frac{\\det\\left[\\mathbf{x}_2-\\mathbf{x}_1 \\ \\ \\mathbf{x}_3-\\mathbf{x}_1\\right]}{\\det\\left[\\mathbf{X}_2-\\mathbf{X}_1 \\ \\ \\mathbf{X}_3-\\mathbf{X}_1\\right]}.$$\n- 定义当前面积的分子为 $A_e(\\mathbf{x}_1,\\mathbf{x}_2,\\mathbf{x}_3) = \\det\\left[\\mathbf{x}_2-\\mathbf{x}_1 \\ \\ \\mathbf{x}_3-\\mathbf{x}_1\\right] = \\operatorname{cross}(\\mathbf{e}_1,\\mathbf{e}_2)$，其中 $\\mathbf{e}_1 = \\mathbf{x}_2 - \\mathbf{x}_1$ 且 $\\mathbf{e}_2 = \\mathbf{x}_3 - \\mathbf{x}_1$，并定义参考面积的分母为 $A_{e,0} = \\det\\left[\\mathbf{X}_2-\\mathbf{X}_1 \\ \\ \\mathbf{X}_3-\\mathbf{X}_1\\right] > 0$。于是 $\\det \\mathbf{J}_e = A_e / A_{e,0}$，且保持方向需要 $A_e > 0$。\n\n2. 障碍-正则化能量：\n- 使用障碍函数 $\\phi(s) = -\\log s$ 并定义能量泛函：\n$$E(\\mathbf{x}_c) = \\frac{w_r}{2}\\|\\mathbf{x}_c - \\mathbf{x}_{c,0}\\|_2^2 + w_b \\sum_{e=1}^4 \\phi\\!\\left(\\det \\mathbf{J}_e(\\mathbf{x}_c)\\right).$$\n- 由于 $\\phi(\\det \\mathbf{J}_e) = -\\log(A_e/A_{e,0}) = -\\log A_e + \\log A_{e,0}$，且 $\\log A_{e,0}$ 是常数，因此梯度仅依赖于 $-\\log A_e$。\n\n3. 面积关于顶点位置的梯度：\n- 设 $\\mathbf{e}_1 = \\mathbf{x}_2 - \\mathbf{x}_1 = (e_{1x}, e_{1y})^\\top$ 且 $\\mathbf{e}_2 = \\mathbf{x}_3 - \\mathbf{x}_1 = (e_{2x}, e_{2y})^\\top$。标量面积分子为 $A_e = e_{1x} e_{2y} - e_{1y} e_{2x}$。\n- 其偏导数为：\n$$\\frac{\\partial A_e}{\\partial \\mathbf{e}_1} = \\begin{bmatrix} e_{2y} \\\\ -e_{2x} \\end{bmatrix}, \\quad \\frac{\\partial A_e}{\\partial \\mathbf{e}_2} = \\begin{bmatrix} -e_{1y} \\\\ e_{1x} \\end{bmatrix}.$$\n- 通过对 $\\mathbf{x}_1,\\mathbf{x}_2,\\mathbf{x}_3$ 应用链式法则，可得：\n  - 由于 $\\mathbf{e}_1 = \\mathbf{x}_2 - \\mathbf{x}_1$ 且 $\\mathbf{e}_2 = \\mathbf{x}_3 - \\mathbf{x}_1$，我们有\n  $$\\frac{\\partial A_e}{\\partial \\mathbf{x}_2} = \\frac{\\partial A_e}{\\partial \\mathbf{e}_1}, \\quad \\frac{\\partial A_e}{\\partial \\mathbf{x}_3} = \\frac{\\partial A_e}{\\partial \\mathbf{e}_2}, \\quad \\frac{\\partial A_e}{\\partial \\mathbf{x}_1} = -\\left(\\frac{\\partial A_e}{\\partial \\mathbf{e}_1} + \\frac{\\partial A_e}{\\partial \\mathbf{e}_2}\\right) = \\begin{bmatrix} e_{1y} - e_{2y} \\\\ e_{2x} - e_{1x} \\end{bmatrix}.$$\n\n4. 能量的梯度：\n- 对于单元 $e$，障碍项的贡献是 $w_b \\cdot \\phi(\\det \\mathbf{J}_e) = -w_b \\log(A_e/A_{e,0})$。由于 $A_{e,0}$ 是常数，其导数为：\n$$\\nabla_{\\mathbf{x}} \\left(-w_b \\log A_e\\right) = -w_b \\frac{1}{A_e} \\nabla_{\\mathbf{x}} A_e.$$\n- 对所有单元求和并加上正则化项 $ \\frac{w_r}{2}\\|\\mathbf{x}_c - \\mathbf{x}_{c,0}\\|_2^2$，得到关于内部节点 $\\mathbf{x}_c$ 的梯度为：\n$$\\nabla_{\\mathbf{x}_c} E(\\mathbf{x}_c) = w_r(\\mathbf{x}_c - \\mathbf{x}_{c,0}) - w_b \\sum_{e=1}^4 \\frac{1}{A_e} \\frac{\\partial A_e}{\\partial \\mathbf{x}_c},$$\n其中对于每个三角形，$\\mathbf{x}_1=\\mathbf{x}_c$，而 $\\mathbf{x}_2$ 和 $\\mathbf{x}_3$ 是相应的边界顶点，且：\n$$\\frac{\\partial A_e}{\\partial \\mathbf{x}_c} = \\frac{\\partial A_e}{\\partial \\mathbf{x}_1} = \\begin{bmatrix} e_{1y} - e_{2y} \\\\ e_{2x} - e_{1x} \\end{bmatrix}, \\quad \\text{其中 } \\mathbf{e}_1 = \\mathbf{x}_2 - \\mathbf{x}_c, \\ \\mathbf{e}_2 = \\mathbf{x}_3 - \\mathbf{x}_c.$$\n\n5. 算法设计：\n- 从测试用例初始化 $\\mathbf{x}_c$。\n- 在每次迭代中：\n  - 对所有4个三角形计算 $A_e(\\mathbf{x}_c)$。如果存在任何 $A_e \\le 0$，则该点位于可行域之外，必须减小步长。\n  - 使用上述公式计算 $E(\\mathbf{x}_c)$ 和梯度 $\\nabla E(\\mathbf{x}_c)$。\n  - 如果 $\\|\\nabla E(\\mathbf{x}_c)\\|_2 \\le \\text{tol}$，则停止。\n  - 设置下降方向 $\\mathbf{p} = -\\nabla E(\\mathbf{x}_c)$ 并执行回溯线搜索：在几何序列 $t = \\beta^k$（其中 $\\beta \\in (0,1)$）中找到最大的步长 $t$，使得所有 $A_e(\\mathbf{x}_c + t\\mathbf{p}) > 0$ 且Armijo条件成立：\n  $$E(\\mathbf{x}_c + t\\mathbf{p}) \\le E(\\mathbf{x}_c) + \\alpha t \\nabla E(\\mathbf{x}_c)^\\top \\mathbf{p},$$\n  其中 $\\alpha \\in (0,1)$。\n  - 更新 $\\mathbf{x}_c \\leftarrow \\mathbf{x}_c + t\\mathbf{p}$ 并重复。\n- 收敛后，为每个单元 $e$ 计算雅可比行列式 $\\det \\mathbf{J}_e = A_e / A_{e,0}$，并报告这4个单元中的最小值。\n\n6. 测试套件与输出：\n- 使用 $w_b = 1.0$，$w_r = 10^{-3}$，最大迭代次数200，容差 $10^{-10}$，$\\alpha = 10^{-4}$，以及 $\\beta = 0.5$。\n- 对以下情况运行优化：\n  - 用例A：初始 $\\mathbf{x}_c^{(0)} = (0.45, 0.55)$。\n  - 用例B：初始 $\\mathbf{x}_c^{(0)} = (0.30, 0.70)$。\n  - 用例C：初始 $\\mathbf{x}_c^{(0)} = (0.60, 0.40)$。\n- 对于每个用例，打印一行结果，格式为逗号分隔的Python列表：$[\\text{min\\_detJ\\_A}, \\text{min\\_detJ\\_B}, \\text{min\\_detJ\\_C}]$，其中每个值四舍五入到6位小数。\n\n该设计通过一个光滑凸代理函数，直接编码了用于最大化最小雅可比行列式的障碍函数法，并通过在迭代过程中使用回溯线搜索强制面积严格为正来确保可行性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_triangle_area_numerator(x1, x2, x3):\n    \"\"\"\n    Compute A_e = det([x2-x1, x3-x1]) = cross(e1, e2) for a 2D triangle.\n    \"\"\"\n    e1 = x2 - x1\n    e2 = x3 - x1\n    return e1[0]*e2[1] - e1[1]*e2[0]\n\ndef energy_and_grad(center, corners, w_r, w_b, center_ref):\n    \"\"\"\n    Compute energy E and gradient grad_E with respect to the center node.\n    Triangles are (center, corner_i, corner_{i+1}), i=0..3 with modulo 4.\n    Barrier is -log(A_e) with A_e = det([x2-x1, x3-x1]) and x1=center.\n    Regularization is (w_r/2)*||center - center_ref||^2.\n    \"\"\"\n    # Regularization term\n    diff = center - center_ref\n    E_reg = 0.5 * w_r * np.dot(diff, diff)\n    grad = w_r * diff.copy()\n\n    # Barrier term: sum over 4 triangles\n    E_bar = 0.0\n    for i in range(4):\n        x1 = center\n        x2 = corners[i]\n        x3 = corners[(i + 1) % 4]\n        e1 = x2 - x1\n        e2 = x3 - x1\n        A = e1[0]*e2[1] - e1[1]*e2[0]  # area numerator (signed)\n        if A = 0.0:\n            # Infeasible: return +inf energy and zero gradient (caller handles)\n            return np.inf, np.zeros_like(center)\n        E_bar += -np.log(A)\n\n        # dA/dx1 = [e1y - e2y, e2x - e1x]\n        dA_dx1 = np.array([e1[1] - e2[1], e2[0] - e1[0]], dtype=float)\n        grad += -w_b * (1.0 / A) * dA_dx1\n\n    E = E_reg + w_b * E_bar\n    return E, grad\n\ndef compute_min_detJ(center, corners, corners_ref, center_ref):\n    \"\"\"\n    Compute the minimum Jacobian determinant detJ across the 4 triangles\n    using reference and current configurations.\n    Triangles: (center, corner_i, corner_{i+1}).\n    detJ = A_current / A_ref for each triangle.\n    \"\"\"\n    min_detJ = np.inf\n    for i in range(4):\n        x1 = center\n        x2 = corners[i]\n        x3 = corners[(i + 1) % 4]\n        X1 = center_ref\n        X2 = corners_ref[i]\n        X3 = corners_ref[(i + 1) % 4]\n        A_cur = compute_triangle_area_numerator(x1, x2, x3)\n        A_ref = compute_triangle_area_numerator(X1, X2, X3)\n        detJ = A_cur / A_ref\n        if detJ  min_detJ:\n            min_detJ = detJ\n    return min_detJ\n\ndef optimize_center(initial_center, corners, corners_ref, center_ref,\n                    w_r=1e-3, w_b=1.0, max_iters=200, tol=1e-10,\n                    alpha=1e-4, beta=0.5):\n    \"\"\"\n    Gradient descent with backtracking line search ensuring A_e > 0 and Armijo decrease.\n    \"\"\"\n    c = initial_center.copy()\n    E, g = energy_and_grad(c, corners, w_r, w_b, center_ref)\n    if not np.isfinite(E):\n        # Project to feasible by small move towards reference center\n        # (Should not happen for provided tests, but safety)\n        t = 1.0\n        p = center_ref - c\n        while t > 1e-12:\n            c_try = c + t * p\n            E_try, _ = energy_and_grad(c_try, corners, w_r, w_b, center_ref)\n            if np.isfinite(E_try):\n                c = c_try\n                E, g = energy_and_grad(c, corners, w_r, w_b, center_ref)\n                break\n            t *= beta\n\n    for _ in range(max_iters):\n        grad_norm = np.linalg.norm(g)\n        if grad_norm = tol:\n            break\n        p = -g\n        t = 1.0\n        # Backtracking line search: enforce feasibility and sufficient decrease\n        while True:\n            c_new = c + t * p\n            E_new, g_new = energy_and_grad(c_new, corners, w_r, w_b, center_ref)\n            feasible = np.isfinite(E_new)\n            if feasible and (E_new = E + alpha * t * np.dot(g, p)):\n                c, E, g = c_new, E_new, g_new\n                break\n            t *= beta\n            if t  1e-16:\n                # Step too small; stop\n                return c\n    return c\n\ndef solve():\n    # Reference configuration\n    corners_ref = np.array([\n        [0.0, 0.0],\n        [1.0, 0.0],\n        [1.0, 1.0],\n        [0.0, 1.0],\n    ], dtype=float)\n    center_ref = np.array([0.5, 0.5], dtype=float)\n\n    # Current boundary corners are fixed and identical to reference\n    corners = corners_ref.copy()\n\n    # Parameters\n    w_b = 1.0\n    w_r = 1e-3\n    max_iters = 200\n    tol = 1e-10\n    alpha = 1e-4\n    beta = 0.5\n\n    # Test cases: initial centers\n    test_cases = [\n        np.array([0.45, 0.55], dtype=float),  # Case A\n        np.array([0.30, 0.70], dtype=float),  # Case B\n        np.array([0.60, 0.40], dtype=float),  # Case C\n    ]\n\n    results = []\n    for c0 in test_cases:\n        c_opt = optimize_center(\n            initial_center=c0,\n            corners=corners,\n            corners_ref=corners_ref,\n            center_ref=center_ref,\n            w_r=w_r,\n            w_b=w_b,\n            max_iters=max_iters,\n            tol=tol,\n            alpha=alpha,\n            beta=beta,\n        )\n        min_detJ = compute_min_detJ(c_opt, corners, corners_ref, center_ref)\n        # Round to 6 decimal places\n        results.append(f\"{min_detJ:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3511549"}]}