{"hands_on_practices": [{"introduction": "为理解复杂的线搜索策略，最好从最简单的情形入手：在理想的二次目标函数上进行精确搜索。本练习将引导您推导此场景下的最优步长，从而建立一个理论基准。[@problem_id:3538517] 关键的是，本练习将挑战您思考为何这种“精确”搜索在涉及非光滑塑性的实际岩土力学模型中会失效，从而阐明为何我们需要更稳健的非精确方法。", "problem": "考虑一个通过有限元法离散化的准静态、小应变、弹塑性边值问题。全局平衡可写为非线性代数方程 $\\,\\boldsymbol{r}(\\boldsymbol{u})=\\boldsymbol{0}\\,$，其中 $\\,\\boldsymbol{r}(\\boldsymbol{u})=\\boldsymbol{f}_{\\mathrm{int}}(\\boldsymbol{u})-\\boldsymbol{f}_{\\mathrm{ext}}\\,$ 是残差向量，$\\,\\boldsymbol{u}\\,$ 是节点位移，$\\,\\boldsymbol{f}_{\\mathrm{int}}(\\boldsymbol{u})\\,$ 是由本构模型引起的内力向量，$\\,\\boldsymbol{f}_{\\mathrm{ext}}\\,$ 是外力向量。在牛顿-拉夫逊（NR）方法的第 $\\,k\\,$ 次牛顿迭代中，搜索方向 $\\,\\boldsymbol{p}_{k}\\,$ 求解 $\\,\\boldsymbol{K}_{k}\\,\\boldsymbol{p}_{k}=-\\boldsymbol{r}_{k}\\,$，其中 $\\,\\boldsymbol{K}_{k}=\\partial \\boldsymbol{r}/\\partial \\boldsymbol{u}\\,$ 是一致切线矩阵，$\\,\\boldsymbol{r}_{k}=\\boldsymbol{r}(\\boldsymbol{u}_{k})\\,$。\n\n为改善收敛性，沿 $\\,\\boldsymbol{p}_{k}\\,$ 应用线性搜索，通过最小化标量评价函数\n$$\n\\phi(\\alpha)=\\tfrac{1}{2}\\,\\boldsymbol{r}\\big(\\boldsymbol{u}_{k}+\\alpha\\,\\boldsymbol{p}_{k}\\big)^{\\mathsf{T}}\\boldsymbol{W}\\,\\boldsymbol{r}\\big(\\boldsymbol{u}_{k}+\\alpha\\,\\boldsymbol{p}_{k}\\big),\n$$\n其中 $\\,\\boldsymbol{W}\\,$ 是一个固定的对称正定加权矩阵。假设在当前迭代中，$\\,\\phi(\\alpha)\\,$ 在射线 $\\,\\boldsymbol{u}_{k}+\\alpha\\,\\boldsymbol{p}_{k}\\,$ 上的限制精确地是 $\\,\\alpha\\,$ 的一个二次函数，其形式为\n$$\n\\phi(\\alpha)=\\phi_{0}+g\\,\\alpha+\\tfrac{1}{2}\\,H\\,\\alpha^{2},\n$$\n其中 $\\,\\phi_{0}=\\phi(0)\\,$，$\\,g=\\left.\\dfrac{\\mathrm{d}\\phi}{\\mathrm{d}\\alpha}\\right|_{\\alpha=0}\\,$，以及 $\\,H=\\left.\\dfrac{\\mathrm{d}^{2}\\phi}{\\mathrm{d}\\alpha^{2}}\\right|_{\\alpha=0}\\,$。\n\n任务：\n1) 从 $\\,\\phi(\\alpha)\\,$、$\\,g\\,$ 和 $\\,H\\,$ 的定义出发，推导沿 $\\,\\boldsymbol{p}_{k}\\,$ 方向最小化 $\\,\\phi(\\alpha)\\,$ 的精确线性搜索步长 $\\,\\alpha^{\\star}\\,$。你的结果应仅用 $\\,g\\,$ 和 $\\,H\\,$ 表示。\n2) 在具有非光滑屈服面（例如 Mohr–Coulomb 或 Drucker–Prager 族中的角点或顶点过渡）的弹塑性岩土力学背景下，从理论上讨论当本构响应沿 $\\,\\boldsymbol{p}_{k}\\,$ 切换分支时，为何精确二次线性搜索可能无法改善收敛性。你的讨论必须指明使二次最小化失效的关于 $\\,g\\,$ 和 $\\,H\\,$ 的条件，并解释屈服面的不可微性如何影响 $\\,\\phi(\\alpha)\\,$ 的曲率。\n\n最终答案仅报告 $\\,\\alpha^{\\star}\\,$ 的封闭形式表达式。无需进行数值计算，也不涉及任何单位。", "solution": "该问题是有效的。它在科学上基于连续介质力学和非线性固体力学数值方法的原理。问题是适定的、客观的，并包含足够的信息来推导所要求的表达式和支持所需的理论讨论。\n\n解答按照题目要求分为两部分。\n\n**第一部分：最优线性搜索步长 $\\alpha^{\\star}$ 的推导**\n\n线性搜索旨在找到使标量评价函数 $\\phi(\\alpha)$ 最小化的步长 $\\alpha$。题目假设在当前迭代中，$\\phi(\\alpha)$ 精确地是 $\\alpha$ 的一个二次函数：\n$$\n\\phi(\\alpha)=\\phi_{0}+g\\,\\alpha+\\tfrac{1}{2}\\,H\\,\\alpha^{2}\n$$\n其中 $\\phi_{0}$、$g$ 和 $H$ 是对于当前线性搜索的常数，由 $\\alpha=0$ 时的状态定义。\n\n为了找到最小化 $\\phi(\\alpha)$ 的 $\\alpha$ 值，我们应用极值的一阶必要条件，即函数对变量的一阶导数必须为零。我们将 $\\phi(\\alpha)$ 对 $\\alpha$ 求导：\n$$\n\\frac{\\mathrm{d}\\phi}{\\mathrm{d}\\alpha} = \\frac{\\mathrm{d}}{\\mathrm{d}\\alpha}\\left(\\phi_{0}+g\\,\\alpha+\\tfrac{1}{2}\\,H\\,\\alpha^{2}\\right) = g+H\\,\\alpha\n$$\n令此导数为零，得到最优步长，我们记为 $\\alpha^{\\star}$：\n$$\ng+H\\,\\alpha^{\\star} = 0\n$$\n解出 $\\alpha^{\\star}$，我们得到：\n$$\n\\alpha^{\\star} = -\\frac{g}{H}\n$$\n此表达式在 $H \\neq 0$ 的条件下有效。\n\n为使此极值为最小值，必须满足二阶充分条件，即函数的二阶导数必须为正。我们计算 $\\phi(\\alpha)$ 的二阶导数：\n$$\n\\frac{\\mathrm{d}^{2}\\phi}{\\mathrm{d}\\alpha^{2}} = \\frac{\\mathrm{d}}{\\mathrm{d}\\alpha}\\left(g+H\\,\\alpha\\right) = H\n$$\n因此，当且仅当曲率 $H > 0$ 时，$\\alpha^{\\star} = -g/H$ 对应于唯一的最小值。\n\n**第二部分：关于弹塑性问题中二次线性搜索失效的理论讨论**\n\n评价函数 $\\phi(\\alpha)$ 精确二次的假设是一个很强的理想化。在具有非光滑屈服面的弹塑性岩土力学背景下，这个假设通常不成立，可能导致线性搜索失败或表现不佳。\n\n首先，我们来分析系数 $g$ 和 $H$。$\\phi(\\alpha)$ 对 $\\alpha$ 的导数可以通过链式法则求得：\n$$\n\\frac{\\mathrm{d}\\phi}{\\mathrm{d}\\alpha} = \\frac{\\mathrm{d}}{\\mathrm{d}\\alpha}\\left(\\tfrac{1}{2}\\,\\boldsymbol{r}(\\alpha)^{\\mathsf{T}}\\boldsymbol{W}\\,\\boldsymbol{r}(\\alpha)\\right) = \\boldsymbol{r}(\\alpha)^{\\mathsf{T}}\\boldsymbol{W}\\,\\frac{\\mathrm{d}\\boldsymbol{r}}{\\mathrm{d}\\alpha}\n$$\n其中 $\\boldsymbol{r}(\\alpha) = \\boldsymbol{r}(\\boldsymbol{u}_{k}+\\alpha\\,\\boldsymbol{p}_{k})$。残差向量对 $\\alpha$ 的导数是：\n$$\n\\frac{\\mathrm{d}\\boldsymbol{r}}{\\mathrm{d}\\alpha} = \\frac{\\partial\\boldsymbol{r}}{\\partial\\boldsymbol{u}}\\frac{\\mathrm{d}\\boldsymbol{u}(\\alpha)}{\\mathrm{d}\\alpha} = \\boldsymbol{K}(\\alpha)\\,\\boldsymbol{p}_{k}\n$$\n其中 $\\boldsymbol{K}(\\alpha)$ 是在状态 $\\boldsymbol{u}_{k}+\\alpha\\,\\boldsymbol{p}_{k}$ 处的一致切线矩阵。因此，$\\phi$ 的方向导数为 $\\frac{\\mathrm{d}\\phi}{\\mathrm{d}\\alpha} = \\boldsymbol{r}(\\alpha)^{\\mathsf{T}}\\boldsymbol{W}\\,\\boldsymbol{K}(\\alpha)\\,\\boldsymbol{p}_{k}$。\n\n系数 $g$ 是此导数在 $\\alpha=0$ 处的值：\n$$\ng = \\left.\\frac{\\mathrm{d}\\phi}{\\mathrm{d}\\alpha}\\right|_{\\alpha=0} = \\boldsymbol{r}(\\boldsymbol{u}_k)^{\\mathsf{T}}\\boldsymbol{W}\\,\\boldsymbol{K}(\\boldsymbol{u}_k)\\,\\boldsymbol{p}_{k} = \\boldsymbol{r}_{k}^{\\mathsf{T}}\\boldsymbol{W}\\,\\boldsymbol{K}_{k}\\,\\boldsymbol{p}_{k}\n$$\n根据牛顿搜索方向的定义，$\\boldsymbol{K}_{k}\\,\\boldsymbol{p}_{k} = -\\boldsymbol{r}_{k}$。代入可得：\n$$\ng = -\\boldsymbol{r}_{k}^{\\mathsf{T}}\\boldsymbol{W}\\,\\boldsymbol{r}_{k}\n$$\n由于 $\\boldsymbol{W}$ 是对称正定矩阵，对于任何非零残差 $\\boldsymbol{r}_k \\neq \\boldsymbol{0}$，都有 $g  0$。这证实了在 $\\alpha=0$ 处，$\\boldsymbol{p}_k$ 是 $\\phi(\\alpha)$ 的一个下降方向。\n\n二次最小化在以下两种主要情况下会失效：\n\n1.  **二次模型的无效性**：公式 $\\alpha^{\\star} = -g/H$ 基于函数 $\\phi(\\alpha)$ 具有恒定正曲率 $H$ 的假设。评价函数的实际曲率是其二阶导数：\n    $$\n    \\frac{\\mathrm{d}^{2}\\phi}{\\mathrm{d}\\alpha^{2}} = H(\\alpha) = \\left(\\boldsymbol{K}(\\alpha)\\boldsymbol{p}_{k}\\right)^{\\mathsf{T}} \\boldsymbol{W} \\left(\\boldsymbol{K}(\\alpha)\\boldsymbol{p}_{k}\\right) + \\boldsymbol{r}(\\alpha)^{\\mathsf{T}} \\boldsymbol{W} \\frac{\\mathrm{d}\\boldsymbol{K}(\\alpha)}{\\mathrm{d}\\alpha}\\boldsymbol{p}_{k}\n    $$\n    一般来说，这个表达式不是恒定的。项 $\\frac{\\mathrm{d}\\boldsymbol{K}(\\alpha)}{\\mathrm{d}\\alpha}$ 反映了材料刚度沿搜索方向如何变化。在具有非光滑屈服面（例如 Mohr-Coulomb）的弹塑性问题中，如果某个材料点的应力状态在某个 $\\alpha_c  0$ 时从屈服面的光滑面移动到角点或顶点，本构律会发生突变。应力率和应变率之间的关系变得非唯一或遵循不同的法则。这导致一致切线模量在 $\\alpha_c$ 处不连续。因此，全局切线矩阵 $\\boldsymbol{K}(\\alpha)$ 相对于 $\\alpha$ 是不可微的，甚至是不连续的。\n    这意味着真实评价函数的曲率 $H(\\alpha)$ 不是恒定的；它是分段定义的，并且可以有跳跃。函数 $\\phi(\\alpha)$ 不是一个单一的二次函数，而是一个由多段组成的更复杂的函数。使用初始曲率 $H = H(0)$ 通过 $\\alpha^{\\star} = -g/H$ 来预测最小值是有缺陷的，因为它忽略了系统响应沿路径的变化。对一个不正确的模型进行这种“精确”最小化，计算出的步长可能是严重的过高或过低估计，可能导致残差增加和收敛失败。\n\n2.  **使最小化失效的关于 $g$ 和 $H$ 的条件**：表达式 $\\alpha^{\\star} = -g/H$ 仅在 $H0$ 时找到最小值。虽然通常可以保证 $g0$，但初始曲率 $H=\\left.\\frac{\\mathrm{d}^2\\phi}{\\mathrm{d}\\alpha^2}\\right|_{\\alpha=0}$ 可能不为正。\n    *   如果 $H=0$，二次模型变为一条直线 $\\phi(\\alpha) = \\phi_0 + g\\alpha$。由于 $g0$，这条直线斜率为负，对于 $\\alpha \\ge 0$ 没有最小值。$\\alpha^{\\star}$ 的公式涉及除以零，因此未定义。\n    *   如果 $H0$，二次模型描述了一个开口向下的抛物线。值 $\\alpha^{\\star}=-g/H$ 对应于一个最大值（因为 $g0$，所以 $\\alpha^{\\star}0$，这不是一个前向步）。对于 $\\alpha \\ge 0$，该函数无界递减，不存在最小值。\n    因此，在线性搜索开始时 $H \\le 0$ 的条件从形式上使得二次最小化过程无效，因为它意味着假设的目标函数对于正步长不存在最小值。这种情况在实践中可能出现，例如，当切线矩阵 $\\boldsymbol{K}_k$ 不是正定的时候，这可能发生在涉及材料软化或结构失稳的问题中。\n\n总而言之，岩土力学模型中屈服面的不可微性破坏了评价函数是光滑二次函数的基本假设。真实评价函数的曲率变得不连续，使得初始二次近似的最小化点成为一个不可靠且可能有害的步长选择。此外，如果初始曲率 $H$ 非正，二次最小化模型本身就无法产生有效的步长。", "answer": "$$\n\\boxed{-\\frac{g}{H}}\n$$", "id": "3538517"}, {"introduction": "由于精确最小化通常不切实际或无法实现，实际的求解器依赖于能够高效找到“足够好”步长的非精确线搜索。本练习将带您从理论走向编码实践，要求您实现并比较两种广泛使用的回溯策略：Armijo 条件和 Goldstein 条件。[@problem_id:3538526] 通过将它们应用于一个非线性多孔介质力学问题，您将获得关于它们在强材料耦合和非线性情况下的性能和稳健性的一手经验。", "problem": "考虑一个非线性代数系统，该系统源于准静态Biot多孔介质力学的一个最小化、无量纲简化，保留了基本的压力-位移耦合。设主未知量为标量位移$u$和标量孔隙压力$p$。基于残差的耦合平衡由向量值映射 $\\mathbf{r}:\\mathbb{R}^2 \\to \\mathbb{R}^2$ 规定，\n$$\n\\mathbf{r}(u,p) = \n\\begin{bmatrix}\nr_u(u,p) \\\\\nr_p(u,p)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nk\\,u + b\\,p + \\beta\\,u^3 - f \\\\\nb\\,u + s\\,p + \\gamma\\,p^3 - g\n\\end{bmatrix},\n$$\n其中 $k0$ 是骨架刚度，$s0$ 是比储水系数，$b \\in (0,1]$ 是Biot系数（压力-位移耦合），$\\beta \\ge 0$ 和 $\\gamma \\ge 0$ 分别模拟非线性的骨架和流体响应。所有量均为无量纲。假设有一个一致、精确的雅可比矩阵\n$$\n\\mathbf{J}(u,p) = \n\\begin{bmatrix}\n\\frac{\\partial r_u}{\\partial u}  \\frac{\\partial r_u}{\\partial p} \\\\\n\\frac{\\partial r_p}{\\partial u}  \\frac{\\partial r_p}{\\partial p}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nk + 3\\beta u^2  b \\\\\nb  s + 3\\gamma p^2\n\\end{bmatrix}.\n$$\n\n定义残差范数平方的目标函数 $\\phi:\\mathbb{R}^2 \\to \\mathbb{R}$，\n$$\n\\phi(u,p) = \\tfrac{1}{2}\\,\\|\\mathbf{r}(u,p)\\|_2^2.\n$$\n\n您将为牛顿-拉弗森（Newton-Raphson, NR）方法设计两种全局化策略，使用沿精确牛顿方向 $\\mathbf{s}$ 的回溯线搜索，其中 $\\mathbf{J}(u,p)\\,\\mathbf{s}=-\\mathbf{r}(u,p)$。线搜索策略必须是：\n\n- 带有参数 $c_a \\in (0,1)$ 的 Armijo 回溯法，强制 $\\phi$ 充分下降。\n- 带有参数 $c_g \\in (0,\\tfrac{1}{2})$ 的 Goldstein 回溯法，强制 $\\phi$ 处于一个双边下降窗口内。\n\n从基本定义（残差平衡、精确雅可比矩阵和上面定义的目标函数）出发。由此，推导 $\\phi$ 沿 $\\mathbf{s}$ 的方向导数，并根据 $\\phi$、试验步长 $\\alpha \\in (0,\\infty)$ 以及当前迭代点的方向导数，构建每种线搜索的接受条件。您的实现必须确保牛顿方向是 $\\phi$ 的一个下降方向，并且必须包含一个鲁棒的回溯策略，该策略在给定的参数体系下总能终止，或者在固定的试验评估预算内无法满足接受条件时返回一个失败指示符。\n\n算法要求：\n\n- 在每次迭代中使用由 $\\mathbf{J}(u,p)\\,\\mathbf{s}=-\\mathbf{r}(u,p)$ 给出的精确牛顿方向 $\\mathbf{s}$。\n- 当减小步长 $\\alpha$ 时，使用一个回溯因子 $\\tau \\in (0,1)$。\n- 对于 Goldstein 法，如果步长相对于双边下降窗口太小，您必须增加 $\\alpha$（例如，用 $\\alpha/\\tau$ 替换 $\\alpha$），但这受限于有限的试验评估次数；如果步长太大（下降不充分），您必须通过乘以 $\\tau$ 来减小 $\\alpha$。\n- 重用任何已接受的残差评估 $\\mathbf{r}(u+\\alpha s_u, p+\\alpha s_p)$ 来更新迭代点，以避免重复计算残差评估次数。\n- 当给定容差 $\\varepsilon0$ 满足 $\\|\\mathbf{r}(u,p)\\|_2 \\le \\varepsilon$ 时，或达到最大牛顿迭代次数时终止。如果未达到收敛，则返回下面指定的失败指示符。\n\n需要为每个测试用例和每种线搜索策略计算的性能指标：\n\n- 收敛所用的总牛顿迭代次数 $N_{\\text{it}}$。\n- 产生的总残差评估次数 $N_{\\text{res}}$，包括初始猜测下的初始残差、线搜索过程中的所有试验残差评估，以及每次迭代时已接受的残差（如果尚未在试验中计数）。\n\n如果求解器在迭代次数上限内未能收敛，或在试验次数上限内找不到可接受的步长，则报告该策略在该测试用例上的结果为 $N_{\\text{it}}=-1$ 和 $N_{\\text{res}}=-1$。\n\n测试套件（所有量均为无量纲）。使用相同的初始猜测 $(u_0,p_0)=(0,0)$，容差 $\\varepsilon=10^{-10}$，最大牛顿迭代次数 $N_{\\max}=50$，回溯因子 $\\tau=0.5$，以及每个牛顿步的最大线搜索试验评估次数 $M_{\\max}=50$。\n\n提供四个探测不同情况的测试用例：\n\n- 用例1（中等耦合与轻度非线性；理想路径）：$(k,s,b,\\beta,\\gamma,f,g,c_a,c_g) = (10,1,0.8,0.2,0.1,1.0,0.2,10^{-4},0.25)$。\n- 用例2（强耦合，存储项接近不可压缩；具有挑战性的条件数）：$(k,s,b,\\beta,\\gamma,f,g,c_a,c_g) = (1000,10^{-3},0.95,0.1,0.1,0.1,0.1,10^{-4},0.25)$。\n- 用例3（刚性非线性；预计会频繁回溯）：$(k,s,b,\\beta,\\gamma,f,g,c_a,c_g) = (5,1,0.6,5.0,1.0,0.5,0.1,10^{-4},0.25)$。\n- 用例4（对参数选择敏感；严格的 Armijo 条件和狭窄的 Goldstein 窗口）：$(k,s,b,\\beta,\\gamma,f,g,c_a,c_g) = (10,0.5,0.9,0.5,0.5,1.0,0.5,0.9,0.49)$。\n\n要求的最终输出格式：\n\n- 您的程序应生成单行输出，其中包含一个列表的列表。对于每个测试用例，返回一个包含四个整数的列表 $[N_{\\text{it}}^{A},N_{\\text{res}}^{A},N_{\\text{it}}^{G},N_{\\text{res}}^{G}]$，其中上标 $A$ 和 $G$ 分别代表 Armijo 和 Goldstein。\n- 完整的输出是这些按用例排列的列表所构成的外层列表，打印为无空格的单行，例如，$[[1,2,3,4],[5,6,7,8],\\ldots]$。\n\n角度单位不适用。由于所有量都是无量纲的，因此不需要进行物理单位转换。程序必须完全自包含，并且不得读取任何输入。", "solution": "该问题要求设计并实现 Armijo 和 Goldstein 回溯法这两种线搜索策略，以实现牛顿-拉弗森（Newton-Raphson）方法的全局化，用于求解一个源自准静态多孔介质力学的特定非线性系统。解决方案必须从第一性原理推导得出。\n\n设状态向量为 $\\mathbf{x} = [u, p]^T \\in \\mathbb{R}^2$。控制非线性代数系统通过寻找 $\\mathbf{x}$ 使得残差向量 $\\mathbf{r}(\\mathbf{x}) = \\mathbf{0}$ 来给出，其中：\n$$\n\\mathbf{r}(\\mathbf{x}) = \\mathbf{r}(u,p) = \n\\begin{bmatrix}\nk\\,u + b\\,p + \\beta\\,u^3 - f \\\\\nb\\,u + s\\,p + \\gamma\\,p^3 - g\n\\end{bmatrix}\n$$\n参数 $k, s, b, \\beta, \\gamma, f, g$ 是给定的常数。牛顿-拉弗森方法是一种求解 $\\mathbf{r}(\\mathbf{x}) = \\mathbf{0}$ 的迭代过程。给定一个迭代点 $\\mathbf{x}_k$，下一个迭代点 $\\mathbf{x}_{k+1}$ 通过求解线性化系统得到：\n$$\n\\mathbf{J}(\\mathbf{x}_k)(\\mathbf{x}_{k+1} - \\mathbf{x}_k) = -\\mathbf{r}(\\mathbf{x}_k)\n$$\n其中 $\\mathbf{J}(\\mathbf{x}_k)$ 是 $\\mathbf{r}$ 在 $\\mathbf{x}_k$ 处求值的雅可比矩阵。问题给出了精确的雅可比矩阵：\n$$\n\\mathbf{J}(u,p) = \n\\begin{bmatrix}\nk + 3\\beta u^2  b \\\\\nb  s + 3\\gamma p^2\n\\end{bmatrix}\n$$\n将搜索方向（牛顿步）定义为 $\\mathbf{s}_k = \\mathbf{x}_{k+1} - \\mathbf{x}_k$，每个牛顿迭代的核心是求解线性系统 $\\mathbf{J}(\\mathbf{x}_k)\\mathbf{s}_k = -\\mathbf{r}(\\mathbf{x}_k)$ 以得到 $\\mathbf{s}_k$。完整的牛顿-拉弗森更新将是 $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\mathbf{s}_k$。\n\n为了确保全局收敛（从远离解的初始猜测收敛），引入了线搜索。更新变为 $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{s}_k$，其中 $\\alpha_k \\in (0, \\infty)$ 是一个为确保朝向解取得进展而选择的步长。这种进展使用目标函数 $\\phi(\\mathbf{x}) = \\frac{1}{2}\\|\\mathbf{r}(\\mathbf{x})\\|_2^2$ 来衡量，该函数在解处有全局最小值 $0$。\n\n首先，我们必须确定牛顿方向 $\\mathbf{s}_k$ 在 $\\mathbf{x}_k$ 处是目标函数 $\\phi$ 的一个下降方向。$\\phi$ 在 $\\mathbf{x}_k$ 处沿 $\\mathbf{s}_k$ 的方向导数由 $D_{\\mathbf{s}_k}\\phi(\\mathbf{x}_k) = \\nabla\\phi(\\mathbf{x}_k)^T \\mathbf{s}_k$ 给出。$\\phi(\\mathbf{x}) = \\frac{1}{2}\\mathbf{r}(\\mathbf{x})^T\\mathbf{r}(\\mathbf{x})$ 的梯度是 $\\nabla\\phi(\\mathbf{x}) = \\mathbf{J}(\\mathbf{x})^T\\mathbf{r}(\\mathbf{x})$。因此，方向导数为：\n$$\nD_{\\mathbf{s}_k}\\phi(\\mathbf{x}_k) = (\\mathbf{J}(\\mathbf{x}_k)^T\\mathbf{r}(\\mathbf{x}_k))^T \\mathbf{s}_k = \\mathbf{r}(\\mathbf{x}_k)^T \\mathbf{J}(\\mathbf{x}_k) \\mathbf{s}_k\n$$\n代入牛顿方向的定义 $\\mathbf{J}(\\mathbf{x}_k)\\mathbf{s}_k = -\\mathbf{r}(\\mathbf{x}_k)$：\n$$\nD_{\\mathbf{s}_k}\\phi(\\mathbf{x}_k) = \\mathbf{r}(\\mathbf{x}_k)^T (-\\mathbf{r}(\\mathbf{x}_k)) = -\\|\\mathbf{r}(\\mathbf{x}_k)\\|_2^2\n$$\n由于 $k0, s0, \\beta \\ge 0$ 和 $\\gamma \\ge 0$，对称雅可比矩阵 $\\mathbf{J}$ 的对角元素是正的：$J_{11} = k + 3\\beta u^2  0$ 和 $J_{22} = s + 3\\gamma p^2  0$。如果其行列式也为正，即 $\\det(\\mathbf{J}) = (k + 3\\beta u^2)(s + 3\\gamma p^2) - b^2  0$，则 $\\mathbf{J}$ 是正定的，因此是可逆的。假设可逆，如果 $\\mathbf{r}(\\mathbf{x}_k) \\neq \\mathbf{0}$，则 $D_{\\mathbf{s}_k}\\phi(\\mathbf{x}_k)  0$，这证实了 $\\mathbf{s}_k$ 是一个下降方向。\n\n线搜索算法确定一个合适的 $\\alpha_k$ 值。我们将实现两种这样的策略。设 $\\mathbf{x}_k$ 为当前迭代点，$\\mathbf{s}_k$ 为搜索方向，$\\phi_k = \\phi(\\mathbf{x}_k)$，方向导数为 $D_k = -\\|\\mathbf{r}(\\mathbf{x}_k)\\|_2^2$。试验步长用 $\\alpha$ 表示。试验点为 $\\mathbf{x}_{\\text{trial}} = \\mathbf{x}_k + \\alpha \\mathbf{s}_k$，该点的目标函数值为 $\\phi_{\\text{trial}} = \\phi(\\mathbf{x}_{\\text{trial}})$。\n\n### Armijo 回溯法\nArmijo 条件，或称充分下降条件，要求 $\\phi$ 的实际减少量至少是线性近似预测减少量的一部分。对于给定的参数 $c_a \\in (0, 1)$，我们寻求一个 $\\alpha$ 使得：\n$$\n\\phi(\\mathbf{x}_k + \\alpha \\mathbf{s}_k) \\le \\phi(\\mathbf{x}_k) + c_a \\alpha D_k\n$$\n代入 $\\phi$ 和 $D_k$ 的定义：\n$$\n\\frac{1}{2}\\|\\mathbf{r}(\\mathbf{x}_k + \\alpha \\mathbf{s}_k)\\|_2^2 \\le \\frac{1}{2}\\|\\mathbf{r}(\\mathbf{x}_k)\\|_2^2 - c_a \\alpha \\|\\mathbf{r}(\\mathbf{x}_k)\\|_2^2\n$$\n回溯算法从试验步长 $\\alpha = 1$（完整的牛顿步）开始。如果条件不满足，步长将乘以一个因子 $\\tau \\in (0,1)$ 进行缩减，即 $\\alpha \\leftarrow \\tau \\alpha$，然后重新检查条件。重复此过程，直到找到一个可接受的 $\\alpha$ 或超过最大试验次数。\n\n### Goldstein 回溯法\nGoldstein 条件为可接受的步长定义了一个双边窗口，既确保充分下降，又防止步长过小。对于给定的参数 $c_g \\in (0, \\frac{1}{2})$，我们寻求一个同时满足以下两个条件的 $\\alpha$：\n1.  充分下降（上界）：\n    $$\n    \\phi(\\mathbf{x}_k + \\alpha \\mathbf{s}_k) \\le \\phi(\\mathbf{x}_k) + c_g \\alpha D_k\n    $$\n    $$\n    \\frac{1}{2}\\|\\mathbf{r}(\\mathbf{x}_k + \\alpha \\mathbf{s}_k)\\|_2^2 \\le \\frac{1}{2}\\|\\mathbf{r}(\\mathbf{x}_k)\\|_2^2 - c_g \\alpha \\|\\mathbf{r}(\\mathbf{x}_k)\\|_2^2\n    $$\n2.  曲率条件（下界）：\n    $$\n    \\phi(\\mathbf{x}_k + \\alpha \\mathbf{s}_k) \\ge \\phi(\\mathbf{x}_k) + (1-c_g) \\alpha D_k\n    $$\n    $$\n    \\frac{1}{2}\\|\\mathbf{r}(\\mathbf{x}_k + \\alpha \\mathbf{s}_k)\\|_2^2 \\ge \\frac{1}{2}\\|\\mathbf{r}(\\mathbf{x}_k)\\|_2^2 - (1-c_g) \\alpha \\|\\mathbf{r}(\\mathbf{x}_k)\\|_2^2\n    $$\n搜索策略从 $\\alpha=1$ 开始。如果条件1被违反，则步长太大，$\\alpha$ 减小，即 $\\alpha \\leftarrow \\tau \\alpha$。如果条件2被违反，则步长被认为太小，$\\alpha$ 增大，即 $\\alpha \\leftarrow \\alpha / \\tau$。此过程持续进行，直到找到满足两个条件的 $\\alpha$ 或达到试验次数限制。\n\n### 算法实现\n实现一个通用的牛顿-拉弗森求解器，它接受一个线搜索函数作为参数。该求解器执行以下步骤：\n1.  初始化 $\\mathbf{x}_0 = (u_0, p_0)$，$k=0$。计算初始残差 $\\mathbf{r}_0 = \\mathbf{r}(\\mathbf{x}_0)$ 及其范数 $\\|\\mathbf{r}_0\\|_2$。\n2.  增加残差评估计数 $N_{\\text{res}}$。\n3.  对 $k = 0, 1, \\dots, N_{\\max}-1$ 进行循环：\n    a. 检查收敛性：如果 $\\|\\mathbf{r}_k\\|_2 \\le \\varepsilon$，则成功终止。\n    b. 计算雅可比矩阵 $\\mathbf{J}_k = \\mathbf{J}(\\mathbf{x}_k)$。\n    c. 求解线性系统 $\\mathbf{J}_k \\mathbf{s}_k = -\\mathbf{r}_k$ 以获得牛顿方向 $\\mathbf{s}_k$。\n    d. 使用 $\\mathbf{x}_k, \\mathbf{s}_k, \\mathbf{r}_k$ 调用指定的线搜索函数（Armijo 或 Goldstein），以找到可接受的步长 $\\alpha_k$ 和相应的残差 $\\mathbf{r}_{k+1} = \\mathbf{r}(\\mathbf{x}_k + \\alpha_k \\mathbf{s}_k)$。\n    e. 将线搜索执行的试验评估次数加到 $N_{\\text{res}}$ 上。\n    f. 如果线搜索未能找到步长，则以失败告终。\n    g. 更新解：$\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{s}_k$。\n4.  如果循环结束仍未收敛，则以失败告终。\n\n累积性能指标 $N_{\\text{it}}$（总牛顿迭代次数）和 $N_{\\text{res}}$（总残差评估次数）。$N_{\\text{res}}$ 包括初始评估以及所有牛顿迭代中线搜索循环内的所有试验评估。已接受的残差评估被计为一次试验，以防止重复计数。通过返回 $N_{\\text{it}}=-1$ 和 $N_{\\text{res}}=-1$ 来指示失败。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef r_func(u, p, params):\n    \"\"\"Computes the residual vector r(u,p).\"\"\"\n    k, s, b, beta, gamma, f, g, _, _ = params\n    r_u = k * u + b * p + beta * u**3 - f\n    r_p = b * u + s * p + gamma * p**3 - g\n    return np.array([r_u, r_p])\n\ndef J_func(u, p, params):\n    \"\"\"Computes the Jacobian matrix J(u,p).\"\"\"\n    k, s, b, beta, gamma, _, _, _, _ = params\n    J11 = k + 3.0 * beta * u**2\n    J12 = b\n    J21 = b\n    J22 = s + 3.0 * gamma * p**2\n    return np.array([[J11, J12], [J21, J22]])\n\ndef armijo_backtracking(u_k, p_k, s_k, r_k, params):\n    \"\"\"\n    Performs Armijo backtracking line search.\n    \"\"\"\n    k, s, b, beta, gamma, f, g, c_a, _ = params\n    tau = 0.5\n    M_max = 50\n\n    alpha = 1.0\n    num_trials = 0\n    \n    r_k_norm_sq = r_k[0]**2 + r_k[1]**2\n    \n    # Pre-calculate term for the Armijo condition\n    # Note: directional derivative D_k = -r_k_norm_sq\n    phi_k = 0.5 * r_k_norm_sq\n    \n    s_u, s_p = s_k\n\n    for i in range(M_max):\n        num_trials += 1\n        u_trial = u_k + alpha * s_u\n        p_trial = p_k + alpha * s_p\n        \n        r_trial = r_func(u_trial, p_trial, params)\n        phi_trial = 0.5 * (r_trial[0]**2 + r_trial[1]**2)\n\n        # Armijo condition: phi(x_k + alpha*s_k) = phi(x_k) + c_a * alpha * grad(phi)^T * s_k\n        # which is: phi_trial = phi_k - c_a * alpha * r_k_norm_sq\n        if phi_trial = phi_k - c_a * alpha * r_k_norm_sq:\n            return alpha, r_trial, num_trials\n        \n        alpha *= tau\n        \n    return None, None, num_trials\n\ndef goldstein_search(u_k, p_k, s_k, r_k, params):\n    \"\"\"\n    Performs Goldstein line search.\n    \"\"\"\n    k, s, b, beta, gamma, f, g, _, c_g = params\n    tau = 0.5\n    M_max = 50\n\n    alpha = 1.0\n    num_trials = 0\n    \n    r_k_norm_sq = r_k[0]**2 + r_k[1]**2\n    \n    # Pre-calculate terms for Goldstein conditions\n    phi_k = 0.5 * r_k_norm_sq\n\n    s_u, s_p = s_k\n    \n    # Store visited alphas to prevent simple oscillations\n    # Not a full-proof solution but helps with simple cases.\n    visited_alphas = set()\n\n    for i in range(M_max):\n        if alpha in visited_alphas:\n            # Oscillating between increase/decrease, fail the search\n            return None, None, num_trials\n        visited_alphas.add(alpha)\n\n        num_trials += 1\n        u_trial = u_k + alpha * s_u\n        p_trial = p_k + alpha * s_p\n        \n        r_trial = r_func(u_trial, p_trial, params)\n        phi_trial = 0.5 * (r_trial[0]**2 + r_trial[1]**2)\n\n        # Condition 1: Sufficient decrease (upper bound)\n        cond1 = phi_trial = phi_k - c_g * alpha * r_k_norm_sq\n        \n        # Condition 2: Curvature condition (lower bound)\n        cond2 = phi_trial = phi_k - (1 - c_g) * alpha * r_k_norm_sq\n\n        if cond1 and cond2:\n            return alpha, r_trial, num_trials\n        elif not cond1: # Insufficient decrease, step too large\n            alpha *= tau\n        else: # not cond2, Step too small\n            alpha /= tau\n    \n    return None, None, num_trials\n\ndef newton_solver(u0, p0, line_search_func, params):\n    \"\"\"\n    Globalized Newton-Raphson solver.\n    \"\"\"\n    epsilon = 1e-10\n    N_max = 50\n    \n    u, p = u0, p0\n    N_it = 0\n    N_res = 0\n\n    r = r_func(u, p, params)\n    N_res += 1\n    r_norm = np.linalg.norm(r)\n\n    while r_norm  epsilon:\n        if N_it = N_max:\n            return -1, -1\n\n        J = J_func(u, p, params)\n        \n        try:\n            s_k = np.linalg.solve(J, -r)\n        except np.linalg.LinAlgError:\n            # Jacobian is singular\n            return -1, -1\n        \n        alpha, r_new, trials = line_search_func(u, p, s_k, r, params)\n        N_res += trials\n        \n        if alpha is None:\n            # Line search failed to find a step\n            return -1, -1\n\n        u += alpha * s_k[0]\n        p += alpha * s_k[1]\n        \n        r = r_new\n        r_norm = np.linalg.norm(r)\n        N_it += 1\n\n    return N_it, N_res\n\ndef solve():\n    test_cases = [\n        # (k, s, b, beta, gamma, f, g, c_a, c_g)\n        (10.0, 1.0, 0.8, 0.2, 0.1, 1.0, 0.2, 1e-4, 0.25),\n        (1000.0, 1e-3, 0.95, 0.1, 0.1, 0.1, 0.1, 1e-4, 0.25),\n        (5.0, 1.0, 0.6, 5.0, 1.0, 0.5, 0.1, 1e-4, 0.25),\n        (10.0, 0.5, 0.9, 0.5, 0.5, 1.0, 0.5, 0.9, 0.49),\n    ]\n\n    u0, p0 = 0.0, 0.0\n    \n    all_results = []\n    \n    for params in test_cases:\n        case_results = []\n        \n        # Armijo\n        N_it_A, N_res_A = newton_solver(u0, p0, armijo_backtracking, params)\n        case_results.extend([N_it_A, N_res_A])\n        \n        # Goldstein\n        N_it_G, N_res_G = newton_solver(u0, p0, goldstein_search, params)\n        case_results.extend([N_it_G, N_res_G])\n        \n        all_results.append(case_results)\n\n    # Format output as a single-line string of a list of lists\n    # Example: [[1,2,3,4],[5,6,7,8]]\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3538526"}, {"introduction": "精密的线搜索算法不仅能减小残差，还能施加物理约束。这项高级练习介绍了一种对岩土力学稳定性分析至关重要的“曲率感知”策略。[@problem_id:3538511] 您将实现一个线搜索算法，它通过切线刚度矩阵的特征值来检查能量函数的曲率，并拒绝那些可能导致材料失稳的步长，从而在模拟软化或边坡失稳等现象时增强求解器的稳健性。", "problem": "您的任务是设计并实现一种考虑曲率的回溯线搜索方法，以改善用于求解计算岩土力学中非线性平衡方程的牛顿法的收敛性。该场景模拟了一个具有两个广义自由度的边坡稳定有限元系统的降阶模型。在状态向量 $u \\in \\mathbb{R}^2$ 处，控制离散平衡方程为 $R(u) = f_{\\mathrm{int}}(u) - f_{\\mathrm{ext}} = 0$，其中 $f_{\\mathrm{ext}} \\in \\mathbb{R}^2$ 是一个固定的外荷载，而 $f_{\\mathrm{int}}(u)$ 是内力向量，其源于一个包含稳定和失稳贡献的势能。\n\n基本原理：\n- 力学平衡要求 $R(u) = 0$。\n- 求解 $u$ 的牛顿法更新规则为 $u^{k+1} = u^k + \\alpha^k p^k$，其中搜索方向 $p^k$ 通过求解 $K_t(u^k)p^k = -R(u^k)$ 得到，$K_t(u)$ 是切线刚度矩阵（即 $R(u)$ 的雅可比矩阵）。\n- 评价函数为 $\\phi(u) = \\tfrac{1}{2}\\lVert R(u)\\rVert_2^2$。在 $u^k$ 处沿牛顿方向 $p^k$ 的方向导数满足 $\\left.\\dfrac{d}{d\\alpha}\\phi(u^k+\\alpha p^k)\\right|_{\\alpha=0} = -\\lVert R(u^k)\\rVert_2^2$，前提是 $K_t(u^k)p^k = -R(u^k)$。\n- 曲率通过最小特征值 $\\lambda_{\\min}(K_t(u))$ 来诊断：负的 $\\lambda_{\\min}$ 表示负曲率（失去正定性），这与边坡稳定问题中的失稳机制有关。\n\n模型设定：\n- 内力定义为 $f_{\\mathrm{int}}(u) = (K_0 + C - \\gamma I)u + \\beta\\,[u_1^3,\\,u_2^3]^\\top$，其中 $K_0 \\in \\mathbb{R}^{2 \\times 2}$ 是对称的基准刚度，$C \\in \\mathbb{R}^{2 \\times 2}$ 是对称的耦合矩阵，$\\gamma \\in \\mathbb{R}$ 控制失稳（例如软化），$\\beta \\in \\mathbb{R}$ 控制稳定的高阶刚度，$I$ 是单位矩阵。切线刚度为 $K_t(u) = K_0 + C - \\gamma I + \\operatorname{diag}(3\\beta u_1^2,\\,3\\beta u_2^2)$。\n- 在本练习中，所有量均被视为无量纲。\n\n线搜索要求：\n- 给定 $u^k$ 和 $p^k$ 且 $K_t(u^k)p^k = -R(u^k)$，通过从 $\\alpha^k = 1$ 开始以常数收缩因子 $\\rho \\in (0,1)$ 进行回溯来选择 $\\alpha^k$，直到同时满足以下两个条件：\n  1. 曲率接受条件：$\\lambda_{\\min}(K_t(u^k + \\alpha^k p^k)) \\geq 0$。\n  2. 充分下降条件 (Armijo 条件)：$\\phi(u^k + \\alpha^k p^k) \\leq \\phi(u^k) - c\\,\\alpha^k\\,\\lVert R(u^k)\\rVert_2^2$，其中 $c \\in (0,1)$。\n- 如果回溯导致 $\\alpha^k  \\alpha_{\\min}$，则声明当前测试用例失败并停止。\n\n牛顿法终止条件：\n- 当 $\\lVert R(u^k)\\rVert_2 \\leq \\varepsilon$ 或迭代次数达到 $k_{\\max}$ 时停止，在后一种情况下声明失败。\n\n实现细节：\n- 使用 $K_0 = \\begin{bmatrix}60  -15\\\\ -15  40\\end{bmatrix}$。\n- 使用 $C = \\begin{bmatrix}0  \\kappa\\\\ \\kappa  0\\end{bmatrix}$，其中 $\\kappa = -10$。\n- 使用下面列出的参数集。对于每个集合，初始化 $u^0 = [0,\\,0]^\\top$，使用 $\\rho = 0.5$，$c = 10^{-4}$，$\\alpha_{\\min} = 10^{-6}$，$\\varepsilon = 10^{-10}$ 以及 $k_{\\max} = 50$。\n\n测试套件：\n- 情况 A：$\\gamma = 20$，$\\beta = 3$，$f_{\\mathrm{ext}} = [50,\\,20]^\\top$。\n- 情况 B：$\\gamma = 30$，$\\beta = 4$，$f_{\\mathrm{ext}} = [80,\\,50]^\\top$。\n- 情况 C：$\\gamma = 23.05$，$\\beta = 3$，$f_{\\mathrm{ext}} = [40,\\,15]^\\top$。\n- 情况 D：$\\gamma = 60$，$\\beta = 0.05$，$f_{\\mathrm{ext}} = [70,\\,40]^\\top$。\n\n输出规格：\n- 对于每种情况，报告收敛到容差 $\\varepsilon$ 所需的牛顿迭代的整数次数。如果算法失败（因超过 $k_{\\max}$ 未收敛或在线搜索期间遇到 $\\alpha^k  \\alpha_{\\min}$），则为该情况输出整数 $-1$。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[n_A,n_B,n_C,n_D]$），其中每个 $n$ 是对应情况 A、B、C、D 的整数结果。\n\n注意：角度单位不适用。在此降阶测试中没有物理单位，所有量在此计算任务中均应视为无量纲。", "solution": "用户提供了一个有效的问题陈述。任务是实现一个带有自定义回溯线搜索的 Newton-Raphson 算法，以求解一个代表计算岩土力学问题的非线性方程组。该算法的性能将在四个不同的参数集上进行评估。\n\n问题的核心是找到满足平衡条件 $R(u) = 0$ 的状态向量 $u \\in \\mathbb{R}^2$，其中 $R(u)$ 是残差向量。残差是内力 $f_{\\mathrm{int}}(u)$ 和恒定外荷载 $f_{\\mathrm{ext}}$ 之间的差值。\n\n控制方程定义如下：\n- 内力向量：$f_{\\mathrm{int}}(u) = (K_0 + C - \\gamma I)u + \\beta\\,[u_1^3,\\,u_2^3]^\\top$。\n- 残差向量：$R(u) = f_{\\mathrm{int}}(u) - f_{\\mathrm{ext}}$。\n- 切线刚度矩阵（$R(u)$的雅可比矩阵）：$K_t(u) = \\frac{\\partial R}{\\partial u} = K_0 + C - \\gamma I + \\operatorname{diag}(3\\beta u_1^2,\\,3\\beta u_2^2)$。\n\nNewton-Raphson 方法使用以下更新规则迭代地优化解的估计值 $u^k$：\n$$\nu^{k+1} = u^k + \\alpha^k p^k\n$$\n这里，$k$ 是迭代次数，$p^k$ 是搜索方向，$\\alpha^k$ 是由线搜索过程确定的步长。\n\n搜索方向 $p^k$ 是经典的牛顿方向，通过求解 $R(u^{k+1}) = 0$ 在 $u^k$ 附近的一阶泰勒展开所产生的线性系统得到：\n$$\nK_t(u^k) p^k = -R(u^k)\n$$\n\n此问题的关键特征是用于确定步长 $\\alpha^k$ 的专门的回溯线搜索。从一个完整步长 $\\alpha = 1$ 开始，步长被一个因子 $\\rho \\in (0,1)$ 反复收缩，直到同时满足两个条件：\n\n1.  **曲率接受条件**：试验状态 $u^k + \\alpha p^k$ 下的材料响应必须是稳定的。这是通过要求试验状态下的切线刚度矩阵是半正定的来实现的。在数学上，最小特征值 $\\lambda_{\\min}$ 必须是非负的：\n    $$\n    \\lambda_{\\min}(K_t(u^k + \\alpha p^k)) \\geq 0\n    $$\n    这个条件防止算法进入材料不稳定的区域（其中 $K_t$ 不是正定的），这是岩土力学建模中的一个关键考虑因素。\n\n2.  **充分下降 (Armijo) 条件**：步长必须在目标函数中提供足够的减少。评价函数定义为 $\\phi(u) = \\frac{1}{2}\\lVert R(u)\\rVert_2^2$。Armijo 条件确保新点不仅更好，而且足够好：\n    $$\n    \\phi(u^k + \\alpha p^k) \\leq \\phi(u^k) - c\\,\\alpha\\,\\lVert R(u^k)\\rVert_2^2\n    $$\n    其中 $c \\in (0,1)$ 是一个小常数（给定为 $10^{-4}$）。项 $-\\lVert R(u^k)\\rVert_2^2$ 是 $\\phi$ 在 $u^k$ 处沿牛顿方向 $p^k$ 的方向导数，保证了 $p^k$ 是 $\\phi$ 的一个下降方向。\n\n对于每个测试用例的总体算法如下：\n\n1.  初始化迭代计数器 $k=0$ 和解向量 $u^0 = [0, 0]^\\top$。设置常数参数：$K_0 = \\begin{bmatrix}60  -15\\\\ -15  40\\end{bmatrix}$，$C = \\begin{bmatrix}0  -10\\\\ -10  0\\end{bmatrix}$，$\\rho=0.5$，$c=10^{-4}$，$\\alpha_{\\min}=10^{-6}$，$\\varepsilon=10^{-10}$ 以及 $k_{\\max}=50$。\n\n2.  进入主循环，只要 $k  k_{\\max}$ 就继续：\n    a. 计算残差向量 $R(u^k)$ 及其L2范数的平方 $\\lVert R(u^k)\\rVert_2^2$。\n    b. 检查收敛性：如果 $\\lVert R(u^k)\\rVert_2 \\leq \\varepsilon$，则找到解。终止并返回当前迭代次数 $k$。\n    c. 计算切线刚度矩阵 $K_t(u^k)$。\n    d. 求解线性系统 $K_t(u^k)p^k = -R(u^k)$ 以获得搜索方向 $p^k$。\n    e. 执行回溯线搜索：\n        i. 初始化 $\\alpha = 1$。\n        ii. 当 $\\alpha \\geq \\alpha_{\\min}$ 时：\n            - 计算试验状态 $u_{\\text{trial}} = u^k + \\alpha p^k$。\n            - 评估曲率条件：计算 $\\lambda_{\\min}(K_t(u_{\\text{trial}}))$。\n            - 评估 Armijo 条件：计算 $\\phi(u_{\\text{trial}})$ 并检查其是否满足充分下降不等式。\n            - 如果两个条件都满足，则接受步长并跳出内循环。\n            - 如果任一条件失败，则收缩步长 $\\alpha \\leftarrow \\rho \\alpha$。\n    f. 检查线搜索失败：如果内循环因 $\\alpha  \\alpha_{\\min}$ 而终止，则声明整个案例失败并返回 $-1$。\n    g. 更新解：$u^{k+1} = u^k + \\alpha p^k$。\n    h. 增加迭代计数器：$k \\leftarrow k+1$。\n\n3.  如果主循环在没有收敛的情况下完成（即 $k$ 达到 $k_{\\max}$），则声明失败并返回 $-1$。\n\n对四个指定的测试用例中的每一个都实施此过程，以确定收敛所需的迭代次数或检测失败。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the Newton-Raphson solver for all test cases.\n    \"\"\"\n\n    def solve_one_case(gamma, beta, f_ext, K0, C, u0, rho, c_armijo, alpha_min, tol, k_max):\n        \"\"\"\n        Solves a single case using a Newton-Raphson method with a curvature-aware\n        backtracking line search.\n        \"\"\"\n        # --- Pre-calculate constant matrices for efficiency ---\n        I = np.identity(2)\n        # This is the linear part of the internal force and tangent stiffness\n        K_lin_part = K0 + C - gamma * I\n\n        u = u0.copy().astype(float)\n\n        for k in range(k_max):\n            # --- 1. Calculate Residual and Check for Convergence ---\n            u_cubed = np.array([u[0]**3, u[1]**3])\n            f_int = K_lin_part @ u + beta * u_cubed\n            R_k = f_int - f_ext\n\n            norm_Rk = np.linalg.norm(R_k)\n\n            if norm_Rk = tol:\n                return k  # Success: Converged\n\n            phi_k = 0.5 * norm_Rk**2\n            armijo_check_term = c_armijo * norm_Rk**2\n\n            # --- 2. Compute Tangent Stiffness and Search Direction ---\n            K_t_k = K_lin_part + np.diag([3.0 * beta * u[0]**2, 3.0 * beta * u[1]**2])\n\n            try:\n                p_k = np.linalg.solve(K_t_k, -R_k)\n            except np.linalg.LinAlgError:\n                return -1  # Failure: Singular matrix\n\n            # --- 3. Curvature-Aware Backtracking Line Search ---\n            alpha = 1.0\n            step_accepted = False\n            while alpha = alpha_min:\n                u_trial = u + alpha * p_k\n\n                # 3a. Curvature-Acceptance Condition\n                K_t_trial = K_lin_part + np.diag([3.0 * beta * u_trial[0]**2, 3.0 * beta * u_trial[1]**2])\n                \n                # eigvalsh is for symmetric matrices and is more efficient\n                min_eig = np.min(np.linalg.eigvalsh(K_t_trial))\n                \n                if min_eig  0.0:\n                    alpha *= rho\n                    continue  # Reduce alpha and re-check\n\n                # 3b. Sufficient Decrease (Armijo) Condition\n                u_trial_cubed = np.array([u_trial[0]**3, u_trial[1]**3])\n                f_int_trial = K_lin_part @ u_trial + beta * u_trial_cubed\n                R_trial = f_int_trial - f_ext\n                phi_trial = 0.5 * np.linalg.norm(R_trial)**2\n\n                if phi_trial = phi_k - alpha * armijo_check_term:\n                    step_accepted = True\n                    break  # Both conditions met, exit line search\n\n                alpha *= rho\n\n            # --- 4. Update State or Handle Failure ---\n            if not step_accepted:\n                return -1  # Failure: Line search failed (alpha became too small)\n            \n            u = u + alpha * p_k\n\n        return -1  # Failure: Max iterations reached\n\n    # --- Problem Setup ---\n    # Global constants\n    K0 = np.array([[60.0, -15.0], [-15.0, 40.0]])\n    kappa = -10.0\n    C = np.array([[0.0, kappa], [kappa, 0.0]])\n    \n    # Algorithmic parameters\n    u0 = np.array([0.0, 0.0])\n    rho = 0.5\n    c_armijo = 1e-4\n    alpha_min = 1e-6\n    tol = 1e-10\n    k_max = 50\n\n    # Test suite from the problem statement\n    test_cases = [\n        # Case A\n        {'gamma': 20.0, 'beta': 3.0, 'f_ext': np.array([50.0, 20.0])},\n        # Case B\n        {'gamma': 30.0, 'beta': 4.0, 'f_ext': np.array([80.0, 50.0])},\n        # Case C\n        {'gamma': 23.05, 'beta': 3.0, 'f_ext': np.array([40.0, 15.0])},\n        # Case D\n        {'gamma': 60.0, 'beta': 0.05, 'f_ext': np.array([70.0, 40.0])},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_one_case(\n            gamma=case['gamma'],\n            beta=case['beta'],\n            f_ext=case['f_ext'],\n            K0=K0, C=C, u0=u0, rho=rho, c_armijo=c_armijo,\n            alpha_min=alpha_min, tol=tol, k_max=k_max\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3538511"}]}