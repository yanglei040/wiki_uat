{"hands_on_practices": [{"introduction": "要理解文件系统的能力边界，我们首先需要分析其用于表示文件的核心数据结构——索引节点（inode）。本练习将引导你基于直接和间接指针的数量，从第一性原理出发，推导文件的最大尺寸。这个计算过程将巩固你对索引分配如何支持文件从微小扩展到巨大的理解。[@problem_id:3635998]", "problem": "考虑一个使用索引节点 (inode) 来描述文件的块寻址文件系统。该 inode 包含 $n$ 个指向数据块的直接指针，$a$ 个单间接指针和 $b$ 个双间接指针。磁盘块的大小为 $B$ 字节。存储在间接块中的每个块地址指针大小固定为 $P$ 字节。假设 $B$ 是 $P$ 的整数倍，因此一个间接块恰好可以存储 $r = B/P$ 个块地址，并且间接块除了这些地址外不包含额外的元数据。一个数据块将其全部 $B$ 字节贡献给文件内容。所有指针都指向数据块或指针块，并且没有三重间接指针。\n\n从块寻址分配中直接和间接指针的基本定义出发——即，一个直接指针寻址一个数据块，一个单间接指针寻址一个其本身包含数据块地址的块，一个双间接指针寻址一个包含指向（存有数据块地址的）块的地址的块——推导此 inode 结构所能提供的最大文件大小 $S_{\\max}$（以字节为单位）的闭式表达式。在推导过程中，请根据每种指针类型可访问多少数据块的基本原理，论证其中的乘法因子。\n\n然后，简要讨论可能将可用最大文件大小降低到 $S_{\\max}$ 以下的实际限制因素（例如，由于文件偏移量宽度或卷上可寻址块总数的限制），无需提供任何数值估算。\n\n请以包含 $n$、$a$、$b$、$B$ 和 $P$ 的单个闭式解析表达式的形式给出 $S_{\\max}$ 的最终答案。最终结果以字节表示。无需四舍五入。", "solution": "目标是计算通过 inode 的指针结构可以访问到的最大数据块数量，然后将该数量乘以块大小 $B$，以获得以字节为单位的最大文件大小 $S_{\\max}$。推导过程从直接和间接指针的基本定义，以及一个间接块中可以容纳多少个地址的几何结构出发。\n\n使用的基本事实和定义：\n- 一个直接指针恰好引用一个数据块；该数据块为文件贡献 $B$ 字节。\n- 一个单间接指针引用一个间接块。一个间接块存储块地址，每个块地址引用一个数据块。如果每个地址为 $P$ 字节，块大小为 $B$ 字节，并且 $B$ 是 $P$ 的整数倍，那么该间接块中可以容纳的地址数量为\n$$\nr = \\frac{B}{P}.\n$$\n因此，一个单间接指针可以引用 $r$ 个不同的数据块，每个数据块贡献 $B$ 字节。\n- 一个双间接指针引用一个指向间接块的指针块（即二级间接寻址）。第一级间接块（由双间接指针指向）有 $r$ 个地址，其中每个地址都引用一个第二级间接块，该第二级间接块本身包含 $r$ 个指向数据块的地址。因此，每个双间接指针可以引用\n$$\nr \\times r = r^{2}\n$$\n个不同的数据块，每个数据块贡献 $B$ 字节。\n\n使用这些定义，我们计算 inode 可寻址的数据块总数：\n- $n$ 个直接指针贡献 $n$ 个数据块。\n- $a$ 个单间接指针贡献 $a \\cdot r$ 个数据块。\n- $b$ 个双间接指针贡献 $b \\cdot r^{2}$ 个数据块。\n\n将这些贡献相加，得到通过 inode 可访问的数据块总数：\n$$\n\\text{Total data blocks} = n + a r + b r^{2}.\n$$\n每个数据块为文件贡献 $B$ 字节。因此，最大文件大小为\n$$\nS_{\\max} = B \\left( n + a r + b r^{2} \\right).\n$$\n代入 $r = \\frac{B}{P}$，得到一个完全由 $n$、$a$、$b$、$B$ 和 $P$ 表示的闭式表达式：\n$$\nS_{\\max} = B \\left( n + a \\left( \\frac{B}{P} \\right) + b \\left( \\frac{B}{P} \\right)^{2} \\right).\n$$\n\n实际限制的讨论（定性）：\n- 有限的文件偏移量宽度：如果文件偏移量存储在 $w$ 位中（例如，$w=32$ 或 $w=64$），那么文件内的寻址不能超过 $2^{w}$ 字节。因此，一个实际的限制是 $\\min\\!\\left(S_{\\max}, 2^{w}\\right)$。\n- 卷容量和可寻址性：如果卷上可寻址块的总数限制为 $N$ 个块，那么单个文件不能超过 $N B$ 字节。实际系统还会对可以同时分配给一个文件的块数施加约束。\n- 实现开销：一些文件系统在间接块内保留少量元数据空间，或维护额外的结构（例如，校验和或块映射），这可能会减少每个间接块的有效指针数。我们的推导假设没有这些开销。\n- 分配策略和碎片：虽然 $S_{\\max}$ 计算的是可达容量，但实际分配可能受到碎片或策略（例如，文件系统超级块中的最大文件大小参数）的限制，从而可能减小可用大小。\n\n上述闭式表达式在给定假设下捕捉了通过指定指针结构可达到的理论最大值；实际约束可能会使可用最大值变小。", "answer": "$$\\boxed{B\\left(n + a\\left(\\frac{B}{P}\\right) + b\\left(\\frac{B}{P}\\right)^{2}\\right)}$$", "id": "3635998"}, {"introduction": "理论上的文件大小是一回事，但真实世界的性能是另一回事。文件碎片化，即文件被分割成不连续的部分（称为“区段”），会严重影响读取速度，尤其是在机械硬盘上。本练习要求你建立并验证一个简单的线性模型，用以量化文件碎片化与读取时间之间的关系。通过使用假设的测量数据，你将确定关键的磁盘性能参数，并亲眼见证碎片化所带来的开销。[@problem_id:3636040]", "problem": "一个在硬盘驱动器（HDD）上使用基于区段分配的操作系统（OS）将每个文件存储为一系列称为区段的连续区域。读取一个跨越多个区段的文件，在读取每个区段之前都需要进行机械磁头定位和旋转对齐，然后以磁盘的持续速率进行顺序传输。使用以下基本事实来建模读取时间：以持续顺序速率 $R$ 传输大小为 $\\text{size}$ 的数据所需的时间是 $\\text{size}/R$，并且由于寻道和旋转延迟，每个区段都会产生平均定位开销 $S$。令 $m$ 表示文件占用的区段数。假设定位开销适用于文件的每个区段，包括第一个区段。\n\n给定在稳态条件下从同一硬盘驱动器上读取三个文件的三个测量结果：\n- 文件 A：$m = 4$，$\\text{size} = 500$ MiB，测得 $T_{\\text{read}} = 4.048$ 秒。\n- 文件 B：$m = 10$，$\\text{size} = 250$ MiB，测得 $T_{\\text{read}} = 2.120$ 秒。\n- 文件 C：$m = 14$，$\\text{size} = 800$ MiB，测得 $T_{\\text{read}} = 6.590$ 秒。\n\n任务：\n- 仅从上述定义出发，推导一个用 $m$、$\\text{size}$、$S$ 和 $R$ 表示 $T_{\\text{read}}$ 的线性模型。\n- 使用文件 A 和 B 的数据通过求解 $S$ 和 $R$ 来参数化该模型。\n- 使用你参数化的模型预测文件 C 的 $T_{\\text{read}}$，然后将此预测值与文件 C 的实测 $T_{\\text{read}}$ 进行比较，并计算绝对误差。\n\n将最终的绝对误差四舍五入到四位有效数字。以秒为单位表示最终误差。", "solution": "首先，我们推导总读取时间 $T_{\\text{read}}$ 的模型。读取文件的过程被描述为对每个区段执行两个不同操作的序列：机械定位和数据传输。\n总时间是所有定位开销所花费的时间与传输数据所花费的时间之和。\n一个文件存储在 $m$ 个区段中。对于每个区段，都会产生平均定位开销 $S$（由于寻道和旋转延迟）。由于该开销适用于每个区段，因此定位的总时间是区段数与每个区段开销的乘积：\n$$T_{\\text{positioning}} = mS$$\n文件总大小为 $\\text{size}$。数据以持续顺序速率 $R$ 传输。传输数据的总时间是总大小与传输速率之比：\n$$T_{\\text{transfer}} = \\frac{\\text{size}}{R}$$\n总读取时间 $T_{\\text{read}}$ 是这两个分量之和：\n$$T_{\\text{read}}(m, \\text{size}) = mS + \\frac{\\text{size}}{R}$$\n该方程是一个关于变量 $m$ 和 $\\text{size}$ 的线性模型，其参数 $S$ 和 $R$ 有待确定。\n\n接下来，我们使用文件 A 和文件 B 的数据，通过确定 $S$ 和 $R$ 的值来参数化此模型。所有大小均以 MiB 为单位，时间以秒为单位，因此我们将以 MiB/s 为单位确定 $R$，以秒为单位确定 $S$。\n\n对于文件 A：$m_A = 4$，$\\text{size}_A = 500$ MiB，$T_{\\text{read}, A} = 4.048$ 秒。\n$$4.048 = 4S + \\frac{500}{R} \\quad (1)$$\n对于文件 B：$m_B = 10$，$\\text{size}_B = 250$ MiB，$T_{\\text{read}, B} = 2.120$ 秒。\n$$2.120 = 10S + \\frac{250}{R} \\quad (2)$$\n我们得到了一个关于两个未知数 $S$ 和 $\\frac{1}{R}$ 的二元线性方程组。为了求解这个方程组，我们可以使用消元法。让我们将方程 $(2)$ 乘以 $2$，使得包含 $\\frac{1}{R}$ 的项与方程 $(1)$ 中的项相等：\n$$2 \\times (2.120) = 2 \\times (10S + \\frac{250}{R})$$\n$$4.240 = 20S + \\frac{500}{R} \\quad (3)$$\n现在，我们从方程 $(3)$ 中减去方程 $(1)$：\n$$(20S + \\frac{500}{R}) - (4S + \\frac{500}{R}) = 4.240 - 4.048$$\n$$16S = 0.192$$\n求解 $S$：\n$$S = \\frac{0.192}{16} = 0.012 \\text{ s}$$\n因此，平均定位开销为 $0.012$ 秒，即 $12$ 毫秒。\n\n现在我们将 $S$ 的值代入其中一个原始方程来求解 $R$。使用方程 $(2)$：\n$$2.120 = 10(0.012) + \\frac{250}{R}$$\n$$2.120 = 0.120 + \\frac{250}{R}$$\n$$2.120 - 0.120 = \\frac{250}{R}$$\n$$2.000 = \\frac{250}{R}$$\n求解 $R$：\n$$R = \\frac{250}{2.000} = 125 \\text{ MiB/s}$$\n因此，持续传输速率为 $125$ MiB/s。\n\n参数化后的模型为：\n$$T_{\\text{read}}(m, \\text{size}) = 0.012m + \\frac{\\text{size}}{125}$$\n\n最后，我们使用此模型预测文件 C 的读取时间，并计算与测量值的绝对误差。\n对于文件 C：$m_C = 14$，$\\text{size}_C = 800$ MiB，测得时间为 $T_{\\text{meas}, C} = 6.590$ 秒。\n预测的读取时间 $T_{\\text{pred}, C}$ 为：\n$$T_{\\text{pred}, C} = 0.012 \\times 14 + \\frac{800}{125}$$\n首先，计算定位时间分量：\n$$0.012 \\times 14 = 0.168 \\text{ s}$$\n接下来，计算传输时间分量：\n$$\\frac{800}{125} = 6.4 \\text{ s}$$\n预测的总读取时间是这两个分量之和：\n$$T_{\\text{pred}, C} = 0.168 + 6.4 = 6.568 \\text{ s}$$\n绝对误差 $E$ 是预测时间与测量时间之间的绝对差值：\n$$E = |T_{\\text{pred}, C} - T_{\\text{meas}, C}|$$\n$$E = |6.568 - 6.590| = |-0.022| = 0.022 \\text{ s}$$\n问题要求将最终答案四舍五入到四位有效数字。计算出的误差为 $0.022$。为了用四位有效数字表示，我们添加尾随零：$0.02200$。", "answer": "$$\\boxed{0.02200}$$", "id": "3636040"}, {"introduction": "分配方法的选择对不同工作负载下的性能有着深远的影响。一种看似简单的分配方法，如链接分配（在FAT文件系统中使用），在特定的“对抗性”使用模式下可能会遭受严重的性能下降。在这个问题中，你将分析链接分配的一种最坏情况：对多个文件进行频繁的追加写操作。你将量化因查找文件末尾的 $O(n)$ 复杂度所导致的显著性能放缓，并评估能将此开销降至 $O(1)$ 的有效缓解措施。[@problem_id:3636039]", "problem": "一个操作系统使用文件分配表（FAT）的链接分配方法。在链接分配中，每个文件表示为一个磁盘簇链，目录条目仅存储起始簇。为了在文件末尾追加内容，如果没有维护辅助元数据，系统必须从起始簇开始遍历该链，直到找到链尾标记，这需要对文件中的每个簇，在FAT条目中跟随其“下一簇”指针。假设每次访问FAT条目的平均成本是常数，则此操作的时间复杂度相对于当前文件长度 $n$（以簇为单位）为 $O(n)$。文件分配表（FAT）存储在磁盘上，并在内存中进行缓冲，但在访问局部性差的情况下，缓冲效果有限。\n\n考虑以下旨在探究对抗性行为的场景：\n\n- 有 $k$ 个文件，每个文件初始长度为 $n_0$ 个簇。\n- 系统执行 $r$ 轮。在每一轮中，它以严格的轮询顺序为 $k$ 个文件中的每一个都追加恰好 $1$ 个簇。\n- 分配器选择空闲簇时不尝试保证连续性，因此文件保持为链接的簇链，没有区段（extents）或段摘要。\n- 目录条目仅记录起始簇，且实现上没有在元数据中持久化存储指向最后一个簇的指针。\n- 读取或写入一个尚未在缓存中的FAT条目的摊销成本是 $t_f$ 时间单位，而写入新追加的簇（数据写入）的摊销时间是 $t_w$ 时间单位。\n- 使用参数 $k = 10$, $n_0 = 1000$, $r = 50$, $t_f = 0.1$ 毫秒, 以及 $t_w = 1$ 毫秒。\n\n一名学生声称，在这些条件下，他构建了一种对抗性模式，该模式会强制进行频繁的 $O(n)$ 链遍历，并且他测量到，与一种为每个文件保留持久化的“最后一个簇”指针（或使用基于区段的分配）的设计相比，出现了显著的减速。后者的设计将每次追加操作的FAT更新减少到 $O(1)$。该学生通过对对抗性模式所需的FAT条目访问总数进行建模，并与每次追加具有恒定FAT工作量的设计进行比较，进一步估算了减速因子。\n\n哪个选项最好地识别了一种在给定约束下最大化链尾遍历的对抗性模式，根据所提供的参数从第一性原理正确估算了减速因子，并提出了一种经证明可将每次追加的复杂度从 $O(n)$ 降低到 $O(1)$（即使在重启后也有效）的缓解措施？\n\nA. 对所有 $k$ 个文件进行轮询式单簇追加，因此在第 $j$ 轮中，每次追加都会遍历当前长度为 $n_0 + j$ 的整个链。$r$ 轮中的总FAT条目访问次数为 $k \\sum_{j=0}^{r-1} (n_0 + j)$，这产生了占主导地位的对抗性FAT工作量，远超数据写入。当 $k = 10$, $n_0 = 1000$, $r = 50$, $t_f = 0.1$ 毫秒, $t_w = 1$ 毫秒时，对抗性总时间在几十秒的量级，而 $O(1)$ 设计（每个文件有持久化的最后一个簇元数据或基于区段的分配）将每次追加的FAT工作量减少到常数个条目；测得的减速因子约为 $86$。缓解措施：在磁盘上的文件元数据中持久化一个指向最后一个簇的指针，或采用基于区段的分配，这两种方法都能确保每次追加操作在重启后仍为 $O(1)$。\n\nB. 一次只对一个文件进行批量追加（先将所有 $r$ 个簇追加到文件1，然后是文件2，依此类推），因此每个文件的遍历成本保持在 $n_0$ 附近，总FAT访问次数为 $k r n_0$。在给定参数下，减速因子约为 $10$。缓解措施：增加簇的大小以减少 $n$，这将使每次追加的复杂度变为 $O(1)$，而与工作负载无关。\n\nC. 在 $k$ 个文件上均匀地发出随机读取而不是追加请求，因此FAT遍历只是零星发生，并且大部分被缓存所隐藏。减速因子接近 $1$。缓解措施：使用空闲空间位图来加速分配；这消除了追加操作的链遍历开销。\n\nD. 采用与选项A中相同的轮询追加方式，但仅在内存中缓存最后一个簇的指针（非持久化），使得遍历在稳态下可以忽略不计，因此即使在给定参数下，减速因子也接近 $1.2$。缓解措施：扩大FAT表缓冲区；这会将每次追加的渐近复杂度从 $O(n)$ 变为 $O(1)$（即使在重启后也有效）。", "solution": "核心任务是对指定工作负载所花费的总时间进行建模，并将其与一个优化的（$O(1)$）设计进行比较，以确定减速因子。\n\n**1. 对抗性（$O(n)$）工作负载分析**\n工作负载包含 $r=50$ 轮。在每一轮 $j$（其中 $j$ 的索引从 $0$ 到 $r-1$）中，一个簇被追加到 $k=10$ 个文件中的每一个。\n\n在第 $j$ 轮开始时，每个文件的长度为 $n_j = n_0 + j$ 个簇。\n\n对长度为 $n_j$ 的文件的一次追加操作：\n- **查找文件结尾：** 系统必须遍历簇的链表。这需要读取 $n_j$ 个簇中每一个的FAT条目以跟随链。此步骤产生 $n_j$ 次FAT读取。\n- **更新指针：** 一旦找到最后一个簇，其FAT条目必须更新以指向新分配的簇。新簇的FAT条目必须设置为链尾标记。这需要 2 次FAT写入。\n- **写入数据：** 实际数据必须写入新的簇。这需要 1 次数据写入。\n\n对长度为 $n_j$ 的文件进行一次追加的总FAT访问次数为 $n_j + 2$。跨 $k=10$ 个文件的“轮询”工作负载性质确保了文件特定元数据（例如，如果临时缓存了最后一个簇的指针）的缓存局部性很差，从而在每次追加时强制进行 $O(n_j)$ 遍历。\n\n所有 $k$ 个文件在所有 $r$ 轮中的总FAT访问次数 $N_{FAT}$ 为：\n$$N_{FAT} = \\sum_{j=0}^{r-1} k \\cdot ((n_0 + j) + 2)$$\n$$N_{FAT} = k \\cdot \\sum_{j=0}^{r-1} (n_0 + 2 + j) = k \\left( \\sum_{j=0}^{r-1} (n_0 + 2) + \\sum_{j=0}^{r-1} j \\right)$$\n第一个和是 $r \\cdot (n_0 + 2)$。第二个和是等差数列 $\\frac{(r-1)r}{2}$。\n$$N_{FAT} = k \\left( r(n_0 + 2) + \\frac{r(r-1)}{2} \\right)$$\n代入给定值：$k = 10$, $n_0 = 1000$, $r = 50$：\n$$N_{FAT} = 10 \\left( 50(1000 + 2) + \\frac{50(50-1)}{2} \\right)$$\n$$N_{FAT} = 10 \\left( 50 \\cdot 1002 + \\frac{50 \\cdot 49}{2} \\right) = 10 \\left( 50100 + 1225 \\right) = 10(51325) = 513250$$\n\n数据写入总数 $N_{writes}$ 为每轮每个文件一次追加：\n$$N_{writes} = k \\cdot r = 10 \\cdot 50 = 500$$\n\n对抗性工作负载的总时间 $T_{adv}$ 是：\n$$T_{adv} = N_{FAT} \\cdot t_f + N_{writes} \\cdot t_w$$\n$$T_{adv} = 513250 \\cdot (0.1 \\times 10^{-3} \\text{ s}) + 500 \\cdot (1 \\times 10^{-3} \\text{ s})$$\n$$T_{adv} = 51.325 \\text{ s} + 0.5 \\text{ s} = 51.825 \\text{ s}$$\n这在“几十秒的数量级”。花在FAT访问上的时间（$51.325$ 秒）明显主导了花在数据写入上的时间（$0.5$ 秒）。\n\n**2. 优化（$O(1)$）设计分析**\n在具有持久化的最后一个簇指针的优化设计中，查找文件结尾是一个 $O(1)$ 操作。每次追加的工作量减少到常数次的FAT更新和一次数据写入。最小的FAT工作量是链接新簇所需的 2 次写入。\n总追加次数是 $k \\cdot r = 500$。\n让我们假设每次追加的恒定FAT工作量是 $C_{FAT} = 2$ 次访问（用于两次写入）。\n优化设计的总FAT访问次数 $N'_{FAT}$ 是：\n$$N'_{FAT} = (k \\cdot r) \\cdot C_{FAT} = 500 \\cdot 2 = 1000$$\n数据写入次数不变：$N'_{writes} = 500$。\n\n优化设计的总时间 $T_{opt}$ 是：\n$$T_{opt} = N'_{FAT} \\cdot t_f + N'_{writes} \\cdot t_w$$\n$$T_{opt} = 1000 \\cdot (0.1 \\times 10^{-3} \\text{ s}) + 500 \\cdot (1 \\times 10^{-3} \\text{ s})$$\n$$T_{opt} = 0.1 \\text{ s} + 0.5 \\text{ s} = 0.6 \\text{ s}$$\n\n**3. 减速因子计算**\n减速因子是总时间的比率：\n$$\\text{Slowdown} = \\frac{T_{adv}}{T_{opt}} = \\frac{51.825 \\text{ s}}{0.6 \\text{ s}} \\approx 86.375$$\n估算的减速因子约为 $86$。\n\n**4. 识别缓解策略**\n问题在于 $O(n)$ 遍历。一个有效的缓解措施必须改变算法，使其查找文件结尾的复杂度为 $O(1)$，并且该措施必须在重启后仍然有效。\n- **持久化最后一个簇的指针：** 在文件的磁盘元数据中（例如，在目录条目中）存储一个指向最后一个簇的指针，可以直接解决问题。这是一个 $O(1)$ 的查找操作，并且是持久的。\n- **基于区段的分配：** 这将文件结构从单个簇的链表更改为连续的、多簇区段的列表。查找追加位置涉及到查看最后一个区段，这是一个 $O(1)$ 操作（摊销后）。这也是一个持久的结构性改变。\n\n### 逐项分析\n\n**A. 对所有 $k$ 个文件进行轮询式单簇追加，因此在第 $j$ 轮中，每次追加都会遍历当前长度为 $n_0 + j$ 的整个链。$r$ 轮中的总FAT条目访问次数为 $k \\sum_{j=0}^{r-1} (n_0 + j)$，这产生了占主导地位的对抗性FAT工作量，远超数据写入。当 $k = 10$, $n_0 = 1000$, $r = 50$, $t_f = 0.1$ 毫秒, $t_w = 1$ 毫秒时，对抗性总时间在几十秒的量级，而 $O(1)$ 设计（每个文件有持久化的最后一个簇元数据或基于区段的分配）将每次追加的FAT工作量减少到常数个条目；测得的减速因子约为 $86$。缓解措施：在磁盘上的文件元数据中持久化一个指向最后一个簇的指针，或采用基于区段的分配，这两种方法都能确保每次追加操作在重启后仍为 $O(1)$。**\n- **模式：** 正确地将轮询工作负载识别为对抗性的。\n- **分析：** FAT访问的公式是一个很好的近似（它忽略了每次追加的常数2次写入，但抓住了主导的 $O(n)$ 项）。FAT工作量占主导地位的结论是正确的。计算出的“几十秒”的总时间是正确的（$51.8$ 秒）。计算出的“约 86”的减速因子与我们的推导（$86.4$）相符。\n- **缓解措施：** 提出了两种正确、标准且持久的解决方案，将复杂度更改为 $O(1)$。\n- **结论：** **正确**。\n\n**B. 一次只对一个文件进行批量追加（先将所有 $r$ 个簇追加到文件1，然后是文件2，依此类推），因此每个文件的遍历成本保持在 $n_0$ 附近，总FAT访问次数为 $k r n_0$。在给定参数下，减速因子约为 $10$。缓解措施：增加簇的大小以减少 $n$，这将使每次追加的复杂度变为 $O(1)$，而与工作负载无关。**\n- **模式与分析：** 描述了一个不同的、对抗性较弱的工作负载。成本分析存在缺陷，计算出的减速因子 $10$ 是不正确的。\n- **缓解措施：** 提议的缓解措施（增加簇大小）降低了 $O(n)$ 成本的常数因子，但没有将渐近复杂度更改为 $O(1)$。\n- **结论：** **不正确**。\n\n**C. 在 $k$ 个文件上均匀地发出随机读取而不是追加请求，因此FAT遍历只是零星发生，并且大部分被缓存所隐藏。减速因子接近 $1$。缓解措施：使用空闲空间位图来加速分配；这消除了追加操作的链遍历开销。**\n- **模式与分析：** 考虑了一个不相关的工作负载（随机读取，而非追加）。\n- **缓解措施：** 提议的缓解措施（空闲空间位图）解决了另一个问题（查找空闲块），而不是遍历文件到其末尾的问题。\n- **结论：** **不正确**。\n\n**D. 采用与选项A中相同的轮询追加方式，但仅在内存中缓存最后一个簇的指针（非持久化），使得遍历在稳态下可以忽略不计，因此即使在给定参数下，减速因子也接近 $1.2$。缓解措施：扩大FAT表缓冲区；这会将每次追加的渐近复杂度从 $O(n)$ 变为 $O(1)$（即使在重启后也有效）。**\n- **模式与分析：** 正确识别了模式，但错误地假设缓存会有效，这与问题的前提（“在访问局部性差的情况下效果有限”）相矛盾。由此得出的 $1.2$ 的减速因子被严重低估了。\n- **缓解措施：** 提议的缓解措施（扩大缓冲区）没有改变基本的 $O(n)$ 算法，并且在重启后不是持久的，未能满足一个关键要求。\n- **结论：** **不正确**。\n\n基于详细分析，选项A是唯一一个正确建模了情况、执行了准确计算并提出了有效缓解措施的选项。", "answer": "$$\\boxed{A}$$", "id": "3636039"}]}