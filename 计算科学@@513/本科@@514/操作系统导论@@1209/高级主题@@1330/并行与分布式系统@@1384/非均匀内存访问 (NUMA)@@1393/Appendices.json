{"hands_on_practices": [{"introduction": "本练习旨在探讨NUMA感知编程的核心权衡：内存访问速度与内存占用空间之间的平衡。你将通过计算在NUMA节点间复制数据所带来的性能提升，并将其与额外的内存成本进行比较[@problem_id:3663572]。这种分析是设计在NUMA环境中高效运行的数据结构的基础。", "problem": "一台多处理器机器使用非统一内存访问（NUMA），其中访问内存的时间取决于线程是访问其自身节点的本地内存还是访问连接到不同节点的内存。考虑一个主要用于读取的配置键值数据结构，它被均匀分布在各个节点上的线程使用。假设有以下符合科学现实的参数和条件：\n\n- 有 $8$ 个 NUMA 节点。线程均匀分布在这 $8$ 个节点上。\n- 平均本地 DRAM 访问延迟为 $80$ 纳秒，记为 $L_{\\text{loc}} = 80~\\text{ns}$。\n- 平均远程 DRAM 访问延迟（到任何非本地节点）为 $150$ 纳秒，记为 $L_{\\text{rem}} = 150~\\text{ns}$。\n- 每次配置查找都会经历一次由 DRAM 主导的缓存未命中，其延迟等于该次查找的平均内存访问延迟。\n- 基准方案通过首次接触分配策略，将配置存储的单个共享副本完全放置在单一节点的内存中。在基准方案下，只有当执行线程恰好位于该节点上时，查找才是本地的。\n- 一种提议的读取副本策略在每个节点上都保留一个配置存储的只读副本。复制在启动时完成，没有运行时写入成本。在此策略下，查找总是由每个节点上的本地内存提供服务。\n- 配置存储的大小为 $64$ 兆字节（MiB），记为 $S = 64~\\text{MiB}$。\n\n仅使用期望值的核心定义以及 NUMA 系统中本地和远程 DRAM 访问的区别，完成以下任务：\n\n1. 推导在基准方案和每节点副本策略下，每次查找的期望延迟表达式。\n2. 根据这些表达式，推导由复制带来的平均每次查找的延迟减少量。\n3. 计算每个节点保留一个副本（而不是单个副本）所引入的额外内存开销（以 MiB 为单位）。\n4. 定义比率 $\\rho$ 为平均每次查找的延迟减少量（以微秒为单位）除以额外内存开销（以 MiB 为单位）。计算 $\\rho$。\n\n以微秒每兆字节（MiB）为单位表示最终比率 $\\rho$，并将您的答案四舍五入到四位有效数字。", "solution": "此题要求分析非统一内存访问（NUMA）系统中内存复制的性能权衡。我将首先验证问题陈述。\n\n### 第 1 步：提取已知条件\n- NUMA 节点数，$N = 8$。\n- 线程均匀分布在这 $8$ 个节点上。\n- 平均本地 DRAM 访问延迟，$L_{\\text{loc}} = 80~\\text{ns}$。\n- 平均远程 DRAM 访问延迟，$L_{\\text{rem}} = 150~\\text{ns}$。\n- 每次查找导致一次缓存未命中，其延迟等于平均内存访问延迟。\n- 基准策略：配置存储的单个副本位于一个节点上。\n- 副本策略：每个节点上都有一个存储的只读副本。\n- 配置存储的大小，$S = 64~\\text{MiB}$。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题具有科学依据，因为 NUMA 是一种标准的计算机体系结构，所提供的延迟值（$80~\\text{ns}$ 和 $150~\\text{ns}$）对于现代系统是符合现实的。该问题是适定(well-posed)的；它提供了所有必要的常数和一组清晰的假设（例如，线程均匀分布），从而可以得出一个唯一的、可计算的解。语言客观而精确。该问题没有违反任何基本原则，不基于错误的前提，不是隐喻性的，与操作系统主题直接相关，并且没有缺少任何关键信息。问题设置是自洽的，并导向对内存开销和延迟减少之间权衡的有意义分析，这是系统性能工程中的一个核心概念。\n\n### 第 3 步：结论与行动\n问题有效，可进行完整解答。\n\n该问题要求进行四部分分析：推导期望延迟、计算延迟减少量、计算内存开销，最后计算延迟减少量与内存开销的比率。\n\n设 $N$ 为 NUMA 节点数，因此 $N=8$。设 $L_{\\text{loc}}$ 为本地访问延迟，$L_{\\text{loc}} = 80~\\text{ns}$，而 $L_{\\text{rem}}$ 为远程访问延迟，$L_{\\text{rem}} = 150~\\text{ns}$。数据存储的大小为 $S = 64~\\text{MiB}$。\n\n**1. 每次查找的期望延迟**\n\n一个操作的期望延迟是所有可能结果的延迟与其概率的加权和。我们将给定策略的期望延迟表示为 $E[L]$。\n\n- **每节点副本策略：**\n在此策略中，配置存储的完整副本驻留在 $N=8$ 个节点中的每一个上。由于线程分布在所有节点上，任何给定节点上的线程总能找到数据的本地副本。因此，每次内存访问都是本地访问。每次查找的延迟确定性地为 $L_{\\text{loc}}$。\n在副本策略下，期望延迟 $E[L_{\\text{rep}}]$ 为：\n$$E[L_{\\text{rep}}] = L_{\\text{loc}} = 80~\\text{ns}$$\n\n- **基准策略：**\n在基准策略中，存储的单个副本被放置在一个特定节点（“内存节点”）上。由于线程均匀分布在所有 $N=8$ 个节点上，发出请求的线程与内存位于同一节点的概率为 $P(\\text{本地}) = \\frac{1}{N}$。线程位于不同节点的概率为 $P(\\text{远程}) = 1 - \\frac{1}{N} = \\frac{N-1}{N}$。\n根据全期望定律，基准策略下的期望延迟 $E[L_{\\text{base}}]$ 为：\n$$E[L_{\\text{base}}] = P(\\text{本地}) \\cdot L_{\\text{loc}} + P(\\text{远程}) \\cdot L_{\\text{rem}}$$\n$$E[L_{\\text{base}}] = \\frac{1}{N} L_{\\text{loc}} + \\frac{N-1}{N} L_{\\text{rem}}$$\n代入给定值：\n$$E[L_{\\text{base}}] = \\frac{1}{8} (80~\\text{ns}) + \\frac{8-1}{8} (150~\\text{ns}) = \\frac{1}{8} (80~\\text{ns}) + \\frac{7}{8} (150~\\text{ns})$$\n$$E[L_{\\text{base}}] = 10~\\text{ns} + \\frac{1050}{8}~\\text{ns} = 10~\\text{ns} + 131.25~\\text{ns} = 141.25~\\text{ns}$$\n\n**2. 平均每次查找的延迟减少量**\n\n平均延迟减少量 $\\Delta L$ 是基准策略和副本策略的期望延迟之差。\n$$\\Delta L = E[L_{\\text{base}}] - E[L_{\\text{rep}}]$$\n$$\\Delta L = 141.25~\\text{ns} - 80~\\text{ns} = 61.25~\\text{ns}$$\n用符号表示，减少量为：\n$$\\Delta L = \\left(\\frac{1}{N} L_{\\text{loc}} + \\frac{N-1}{N} L_{\\text{rem}}\\right) - L_{\\text{loc}} = \\frac{N-1}{N} L_{\\text{rem}} - \\left(1 - \\frac{1}{N}\\right) L_{\\text{loc}} = \\frac{N-1}{N} (L_{\\text{rem}} - L_{\\text{loc}})$$\n使用符号形式并代入我们的值：\n$$\\Delta L = \\frac{8-1}{8} (150~\\text{ns} - 80~\\text{ns}) = \\frac{7}{8} (70~\\text{ns}) = 61.25~\\text{ns}$$\n问题要求在最终比率中使用微秒作为单位。因为 $1~\\mu s = 1000~\\text{ns}$：\n$$\\Delta L = 61.25 \\times 10^{-3}~\\mu s = 0.06125~\\mu s$$\n\n**3. 额外内存开销**\n\n内存开销是副本策略相比基准策略额外消耗的内存。\n- 基准策略使用的内存：$M_{\\text{base}} = S = 64~\\text{MiB}$。\n- 副本策略使用的内存：$M_{\\text{rep}} = N \\times S = 8 \\times 64~\\text{MiB} = 512~\\text{MiB}$。\n\n额外内存开销 $\\Delta M$ 为：\n$$\\Delta M = M_{\\text{rep}} - M_{\\text{base}} = NS - S = (N-1)S$$\n代入给定值：\n$$\\Delta M = (8-1) \\times 64~\\text{MiB} = 7 \\times 64~\\text{MiB} = 448~\\text{MiB}$$\n\n**4. 比率 $\\rho$**\n\n比率 $\\rho$ 定义为平均每次查找的延迟减少量（以微秒为单位）除以额外内存开销（以 MiB 为单位）。\n$$\\rho = \\frac{\\Delta L \\text{ (in } \\mu s)}{\\Delta M \\text{ (in MiB)}}$$\n使用前面步骤中计算出的值：\n$$\\rho = \\frac{0.06125}{448}~\\frac{\\mu s}{\\text{MiB}}$$\n现在，我们进行除法运算：\n$$\\rho \\approx 0.00013671875~\\frac{\\mu s}{\\text{MiB}}$$\n问题要求将答案四舍五入到四位有效数字。\n前四位有效数字是 $1$、$3$、$6$ 和 $7$。随后的数字是 $1$，所以我们向下舍入。\n$$\\rho \\approx 0.0001367~\\frac{\\mu s}{\\text{MiB}}$$\n按要求用科学记数法表示此结果：\n$$\\rho = 1.367 \\times 10^{-4}~\\frac{\\mu s}{\\text{MiB}}$$", "answer": "$$\\boxed{1.367 \\times 10^{-4}}$$", "id": "3663572"}, {"introduction": "本练习考察操作系统如何管理不同容量的NUMA节点间的内存布局。通过对一种交错分配策略进行建模，你将确定在某个节点的资源被耗尽之前，系统能支持的最大应用程序内存占用[@problem_id:3663621]。此分析突显了操作系统的内存策略与应用程序在真实硬件上的可伸缩性之间的关键联系。", "problem": "一个双节点非一致性内存访问 (NUMA) 系统的内存容量为：节点0上 $C_0 = 64$ GiB，节点1上 $C_1 = 32$ GiB。一个单一进程的内存足迹大小为 $F$ GiB，操作系统以页为单位进行分配。假设页面大小固定为 $P = 4$ KiB，并且除了所述容量外，没有其他后台内存使用，也没有内核保留。在交错放置策略下，在分配的整个生命周期中，进程页面的一个比例 $w$ 被放置在节点1上，剩余的比例 $1 - w$ 被放置在节点0上。将节点1的“饿死”定义为这样一个事件：在进程的整个足迹被分配完毕之前，节点1就耗尽了其可用容量，从而迫使任何本应放置在节点1上的剩余页面被放置到节点0上。\n\n仅从页粒度分配、容量约束和上述交错放置策略的核心定义出发，推导出一个闭式表达式，用于表示在参数为 $w$ 的交错放置下可避免节点1饿死的最大足迹 $F^{\\star}(w)$ (以GiB为单位)。然后，将您的表达式特化到等量交错情况 $w = \\frac{1}{2}$，并使用给定的容量 $C_0 = 64$ GiB 和 $C_1 = 32$ GiB。报告 $F^{\\star}(\\frac{1}{2})$ 的最终数值（以GiB为单位）。在最终的方框答案中不要包含单位。无需四舍五入。", "solution": "用户想要解决一个关于双节点非一致性内存访问 (NUMA) 系统中内存分配的问题。\n\n### 第1步：提取已知条件\n-   系统：一个双节点NUMA系统（节点 $0$ 和节点 $1$）。\n-   节点0容量：$C_0 = 64$ GiB。\n-   节点1容量：$C_1 = 32$ GiB。\n-   进程内存足迹：$F$ GiB。\n-   页面大小：$P = 4$ KiB。\n-   交错策略：进程页面的一个比例 $w$ 放置在节点1上，剩余的比例 $1-w$ 放置在节点0上。\n-   假设：没有其他后台内存使用或内核保留。\n-   饿死的定义：节点1的饿死被定义为这样一个事件：在进程的整个足迹被分配完毕之前，节点1就耗尽了其可用容量，从而迫使任何本应放置在节点1上的剩余页面被放置到节点0上。\n-   目标1：推导出一个闭式表达式，用于表示在参数为 $w$ 的交错放置下可避免节点1饿死的最大足迹 $F^{\\star}(w)$ (以GiB为单位)。\n-   目标2：使用给定的容量计算 $F^{\\star}(\\frac{1}{2})$ 的数值。\n\n### 第2步：使用提取的已知条件进行验证\n1.  **科学或事实上的不健全性**：问题描述了一个简化但基本合理的NUMA内存管理模型。概念（节点、容量、交错、基于页的分配）是操作系统和计算机体系结构中的标准概念。该模型是用于分析的有效抽象。未发现缺陷。\n2.  **不可形式化或不相关**：问题定义明确，可以用数学方式形式化。它与NUMA内存策略的主题直接相关。未发现缺陷。\n3.  **不完整或矛盾的设置**：所有必要的参数（$C_0$、$C_1$、$w$）都已提供。饿死的定义是明确的。问题是自包含的。提到页面大小 $P$ 与将分配描述为页面的一部分是一致的，因为节点上的总内存是页面数乘以页面大小。这意味着在以总足迹 $F$ 计算内存使用量时，页面大小将相互抵消。设置是完整且一致的。未发现缺陷。\n4.  **不切实际或不可行**：内存容量对于现代服务器是现实的。没有其他内存使用的简化假设是创建易于分析问题的标准做法。未发现缺陷。\n5.  **不适定或结构不良**：问题陈述清晰。它要求在一个明确定义的约束（“避免饿死”）下的最大值。这种结构导致一个独特且有意义的解。未发现缺陷。\n6.  **伪深刻、琐碎或同义反复**：问题需要仔细解释约束和系统限制，涉及的不仅仅是简单的替换。这是资源约束分析中的一个合理练习。未发现缺陷。\n7.  **超出科学可验证性**：推导是数学的，完全可以验证。未发现缺陷。\n\n### 第3步：结论与行动\n该问题是 **有效的**。将提供一个合理的解决方案。\n\n### 求解推导\n问题要求的是，在一个双节点NUMA系统上，可以分配而不导致节点1“饿死”的最大进程足迹，记为 $F^{\\star}(w)$。分配过程受交错策略的支配。\n\n设 $F$ 为进程的总内存足迹（以GiB为单位）。根据交错策略，进程页面的一个比例 $w$ 分配在节点1上，剩余的比例 $1-w$ 分配在节点0上。由于页面大小 $P$ 是统一的，这些比例直接适用于内存足迹的大小。\n\n分配给节点0的内存 $M_0$ 为：\n$$M_0 = (1 - w)F$$\n\n分配给节点1的内存 $M_1$ 为：\n$$M_1 = wF$$\n\n问题将“节点1的饿死”定义为节点1在整个足迹被分配完毕之前耗尽其容量的事件。如果为节点1准备的内存超过了其容量 $C_1$，就会发生这种情况。为了*避免*节点1的饿死，分配给它的内存不能超过其容量：\n$$M_1 \\le C_1$$\n代入 $M_1$ 的表达式：\n$$wF \\le C_1$$\n这个不等式给出了基于节点1容量的足迹 $F$ 的一个上界：\n$$F \\le \\frac{C_1}{w} \\quad (\\text{对于 } w > 0)$$\n\n然而，问题隐含地要求*整个*进程足迹 $F$ 都被成功分配。在指定策略下，一次成功的分配意味着为*两个*节点准备的内存都必须符合它们各自的容量。因此，分配给节点0的内存也必须不超过其容量 $C_0$：\n$$M_0 \\le C_0$$\n代入 $M_0$ 的表达式：\n$$(1 - w)F \\le C_0$$\n这个不等式给出了基于节点0容量的足迹 $F$ 的第二个上界：\n$$F \\le \\frac{C_0}{1-w} \\quad (\\text{对于 } w  1)$$\n\n为了使足迹 $F$ 的分配能够完整且成功地进行（这内在地避免了任何一个节点的饿死），两个条件必须同时满足。因此，$F$ 必须小于或等于这两个上界中的最小值。分配能够成功的最大足迹 $F^{\\star}(w)$ 是由最严格的约束决定的。\n\n$$F^{\\star}(w) = \\min\\left(\\frac{C_0}{1-w}, \\frac{C_1}{w}\\right)$$\n\n这就是所要求的、避免饿死的最大足迹的闭式表达式，因为它代表了根据该策略可以完全分配而不会耗尽任一节点容量的最大足迹。\n\n接下来，我们将这个表达式特化到给定的参数：\n-   容量：$C_0 = 64$ GiB, $C_1 = 32$ GiB。\n-   交错比例：$w = \\frac{1}{2}$。\n\n将这些值代入 $F^{\\star}(w)$ 的表达式中：\n$$F^{\\star}\\left(\\frac{1}{2}\\right) = \\min\\left(\\frac{C_0}{1 - \\frac{1}{2}}, \\frac{C_1}{\\frac{1}{2}}\\right)$$\n$$F^{\\star}\\left(\\frac{1}{2}\\right) = \\min\\left(\\frac{C_0}{\\frac{1}{2}}, \\frac{C_1}{\\frac{1}{2}}\\right)$$\n$$F^{\\star}\\left(\\frac{1}{2}\\right) = \\min(2C_0, 2C_1)$$\n\n现在，我们插入容量 $C_0 = 64$ 和 $C_1 = 32$ 的数值：\n$$F^{\\star}\\left(\\frac{1}{2}\\right) = \\min(2 \\times 64, 2 \\times 32)$$\n$$F^{\\star}\\left(\\frac{1}{2}\\right) = \\min(128, 64)$$\n这两个值的最小值是 $64$。\n$$F^{\\star}\\left(\\frac{1}{2}\\right) = 64$$\n\n因此，在该系统上使用等量交错策略可以分配的最大足迹是 $64$ GiB。在此大小时，节点1被完全填满（$M_1 = \\frac{1}{2} \\times 64 = 32$ GiB，等于 $C_1$），而节点0尚有空余空间（$M_0 = \\frac{1}{2} \\times 64 = 32$ GiB，小于 $C_0 = 64$ GiB）。任何更大的足迹都将导致节点1的饿死。", "answer": "$$\\boxed{64}$$", "id": "3663621"}, {"introduction": "这个高级案例研究模拟了一个生产服务器上的真实故障场景，挑战你诊断内存泄漏所带来的影响。你将分析现代Linux内核机制（如内存控制组和NUMA内存策略）如何相互作用，以控制故障范围或导致性能下降[@problem_id:3663644]。本练习将理论与管理大型NUMA系统的实践复杂性联系起来。", "problem": "考虑一台部署在具有非统一内存访问（NUMA）架构的机器上的生产 Web 服务器。该系统有 $N=2$ 个节点：节点 $0$ 和节点 $1$，每个节点拥有 $128$ 吉比字节（GiB）的物理内存。服务器使用 $W=16$ 个工作进程，其中 $8$ 个工作进程被固定在节点 $0$ 的中央处理器（CPU）核心上，另外 $8$ 个被固定在节点 $1$ 的 CPU 核心上。操作系统采用首次接触（first-touch）页面分配策略：页面会被分配在分配线程首次接触该内存的 NUMA 节点上，但这受制于进程的内存策略。\n\n所有工作进程都是相同的，除了一个 bug 导致在节点 $0$ 上的 $8$ 个工作进程中出现了内存泄漏。每个节点 $0$ 的工作进程有一个 $3$ GiB 的稳态工作集，并且每分钟额外泄漏 $0.5$ GiB 的匿名、不可交换内存。假设交换空间（swap）被禁用。操作系统自身在节点 $0$ 上的内存使用量约为 $4$ GiB。工作负载主要是计算和网络密集型，文件缓存可忽略不计，因此页面缓存的回收不会显著减慢泄漏对空闲内存的消耗速度。\n\n进行了两个实验：\n\n- 实验 $1$：节点 $0$ 的工作进程被置于一个内存控制组（memcg）中，该控制组的容量被限制为节点 $0$ 的容量，并配置了严格的内存策略（MPOL_BIND），只允许在节点 $0$ 上进行分配（`cpuset.mems` 被限制为节点 $0$）。节点 $1$ 的工作进程使用节点 $1$，没有泄漏，除了被固定在节点 $1$ 的 CPU 上之外没有其他特殊限制。\n\n- 实验 $2$：节点 $0$ 的工作进程配置了首选节点 $0$ 的内存策略（MPOL_PREFERRED），但在节点 $0$ 内存不足时允许从节点 $1$ 进行分配（`cpuset.mems` 包括节点 $0$ 和节点 $1$）。为节点 $0$ 工作进程设置的 memcg 允许其内存使用增长到跨越两个节点的总容量。\n\n根据非统一内存访问（NUMA）、首次接触分配、内存策略和内存控制组（memcg）的基本定义，选择所有正确的陈述。\n\nA. 在实验 $1$ 中，当节点 $0$ 的空闲内存耗尽时，内存不足（OOM）事件被限制在节点 $0$ 的内存控制组内，并且其工作进程的分配不会溢出到节点 $1$。\n\nB. 在实验 $2$ 中，一旦节点 $0$ 的空闲内存耗尽，节点 $0$ 工作进程的后续分配将从节点 $1$ 中满足，并且由于远程访问，它们的平均内存访问时间会增加。\n\nC. 考虑到节点 $0$ 上的泄漏率和初始空闲内存，假设泄漏使用的是匿名不可交换内存且交换空间被禁用，在实验 $2$ 中，节点 $0$ 首次停止本地分配并开始回退到远程页面的时间大约是 $25$ 分钟。\n\nD. 在实验 $1$ 中，Linux 的内存不足（OOM）杀手会终止两个节点上的工作进程，因为 OOM 决策总是系统范围的，并且会忽略内存控制组和允许的节点集。\n\nE. 在实验 $2$ 中，可以保证节点 $1$ 的工作进程在远程溢出期间不会出现吞吐量下降，因为它们的页面保持在本地；跨节点流量不会与节点 $1$ 的内存控制器或互连设备产生竞争。", "solution": "在此，我将首先验证问题陈述的有效性，并在确认其有效后，继续对系统行为进行详细分析，并评估每个选项。\n\n### 问题验证\n\n**步骤 1：提取给定条件**\n\n*   系统架构：非统一内存访问（NUMA）\n*   NUMA 节点数量：$N=2$（节点 $0$ 和节点 $1$）\n*   每个节点的内存：$128$ 吉比字节（GiB）\n*   总工作进程数：$W=16$\n*   工作进程固定：$8$ 个工作进程固定在节点 $0$ 的 CPU 核心上；$8$ 个工作进程固定在节点 $1$ 的 CPU 核心上。\n*   操作系统分配策略：首次接触页面分配。\n*   内存泄漏：仅限于节点 $0$ 上的 $8$ 个工作进程。\n*   节点 $0$ 工作进程的内存概况：\n    *   稳态工作集：每个工作进程 $3$ GiB。\n    *   泄漏率：每个工作进程每分钟 $0.5$ GiB。\n    *   泄漏内存类型：匿名、不可交换。\n*   交换空间：禁用。\n*   操作系统在节点 $0$ 上的内存使用量：约 $4$ GiB。\n*   文件缓存：影响可忽略不计。\n*   实验 $1$ 中节点 $0$ 工作进程的配置：\n    *   内存控制组（memcg）限制为节点 $0$ 的容量。\n    *   严格的内存策略（MPOL_BIND），只允许在节点 $0$ 上分配。\n    *   `cpuset.mems` 限制为节点 $0$。\n*   实验 $2$ 中节点 $0$ 工作进程的配置：\n    *   首选节点 $0$ 的内存策略（MPOL_PREFERRED）。\n    *   允许在备用时从节点 $1$ 分配。\n    *   `cpuset.mems` 包括节点 $0$ 和节点 $1$。\n    *   memcg 允许跨越两个节点进行增长。\n\n**步骤 2：使用提取的给定条件进行验证**\n\n*   **科学依据：** 该问题牢固地植根于现代计算机体系结构和操作系统的原理，特别是 NUMA、CPU/内存固定（`cpuset`）、内存分配策略（使用 `MPOL_BIND`/`MPOL_PREFERRED` 的 `mbind`）和资源隔离（`memcg`）。这些都是定义明确的真实世界机制，尤其是在 Linux 内核中。\n*   **定义明确：** 问题陈述清晰，设置了两个截然不同的实验。提供的数值数据足以分析一个与时间相关的行为（内存泄漏）。提出的问题直接关系到所述配置的预期结果。\n*   **客观性：** 语言技术性强且精确。它描述了系统配置和行为，没有主观性或模糊性。所用术语在操作系统上下文中具有特定的、正式的含义。\n*   **一致性与完整性：** 设置是自洽的。提供了参数（内存大小、工作进程数量、泄漏率），可以进行定量分析。例如，指定了总内存、操作系统开销和初始工作集，从而可以计算初始空闲内存。没有矛盾之处。\n*   **现实性：** 这个场景非常现实。生产服务器通常在 NUMA 硬件上运行，而内存泄漏是一类常见的软件错误。使用 cgroups（`memcg`、`cpuset`）来管理工作负载是容器化和虚拟化环境中的标准做法。所描述的策略及其效果符合实际情况。\n\n**步骤 3：结论与行动**\n\n问题陈述有效。它在科学上是合理的、定义明确的、客观且完整的。我将继续进行完整解答。\n\n### 推导与选项分析\n\n首先，我将确定节点 $0$ 上的初始内存状态。\n*   节点 $0$ 的总内存：$128$ GiB。\n*   节点 $0$ 上操作系统消耗的内存：$4$ GiB。\n*   节点 $0$ 上 $8$ 个工作进程初始稳态消耗的内存：$8 \\text{ 个工作进程} \\times 3 \\text{ GiB/工作进程} = 24$ GiB。\n*   节点 $0$ 上的总初始内存使用量：$4 \\text{ GiB} + 24 \\text{ GiB} = 28$ GiB。\n*   节点 $0$ 上可供泄漏消耗的初始空闲内存：$128 \\text{ GiB} - 28 \\text{ GiB} = 100$ GiB。\n\n接下来，我将确定泄漏消耗内存的总速率。\n*   节点 $0$ 上 $8$ 个工作进程的总泄漏率：$8 \\text{ 个工作进程} \\times 0.5 \\text{ GiB/分钟/工作进程} = 4$ GiB/分钟。\n\n现在，我将分析每个实验中的行为并评估相应的选项。\n\n**A. 在实验 1 中，当节点 0 的空闲内存耗尽时，内存不足（OOM）事件被限制在节点 0 的内存控制组内，并且其工作进程的分配不会溢出到节点 1。**\n\n*   **分析：** 在实验 $1$ 中，节点 $0$ 的工作进程受到两个约束，阻止在节点 $1$ 上进行分配：\n    1.  `cpuset.mems` 被限制为节点 $0$。这是一个强大的基于 cgroup 的约束，禁止内核为这些进程在任何其他节点上分配页面。\n    2.  还指定了 `MPOL_BIND` 策略，它严格要求在给定的节点掩码（节点 $0$）上进行分配。如果指定节点上没有可用内存，则分配失败。\n    因此，当节点 $0$ 的 $100$ GiB 空闲内存被耗尽时，来自节点 $0$ 工作进程的任何进一步分配请求都将失败。此分配失败将触发内存不足（OOM）条件。\n    问题指出这些工作进程位于一个内存控制组（`memcg`）中。`memcg` 的一个主要功能是隔离内存资源。当 `memcg` 内的进程因超出 cgroup 的限制而触发 OOM 条件时，内核会专门针对该 `memcg` 调用 OOM killer（即“memcg OOM”）。它不会触发系统范围的 OOM。因此，OOM 事件被限制在节点 $0$ 的 `memcg` 内，而该组之外的进程（如节点 $1$ 上的工作进程）不被视为终止的候选对象。该陈述完全符合这些 Linux 内核机制的预期行为。\n*   **结论：正确**\n\n**B. 在实验 2 中，一旦节点 0 的空闲内存耗尽，节点 0 工作进程的后续分配将从节点 1 中满足，并且由于远程访问，它们的平均内存访问时间会增加。**\n\n*   **分析：** 在实验 $2$ 中，策略是针对节点 $0$ 的 `MPOL_PREFERRED`，并且 `cpuset.mems` 允许在节点 $0$ 和节点 $1$ 上进行分配。“首选”策略指示内核首先尝试在节点 $0$ 上进行分配。然而，与 `MPOL_BIND` 不同，如果首选节点内存不足，它允许内核回退到其他允许的节点（根据 `cpuset.mems` 的设置）。\n    因此，一旦节点 $0$ 满了，来自节点 $0$ 工作进程的后续分配请求将通过从节点 $1$ 分配页面来满足。由于工作进程在节点 $0$ 的 CPU 上运行，任何对这些新分配在节点 $1$ 上的页面的访问都将是“远程”访问。由于需要穿越 NUMA 互连（例如 QPI 或 UPI），远程内存访问会产生更高的延迟和更低的带宽。随着进程工作集中远程页面比例的增加，其平均内存访问时间将会恶化（增加）。\n*   **结论：正确**\n\n**C. 考虑到节点 0 上的泄漏率和初始空闲内存，假设泄漏使用的是匿名不可交换内存且交换空间被禁用，在实验 2 中，节点 0 首次停止本地分配并开始回退到远程页面的时间大约是 25 分钟。**\n\n*   **分析：** 这是一个可以用给定条件验证的定量声明。\n    *   节点 $0$ 的初始空闲内存：$100$ GiB（如上计算）。\n    *   总泄漏率：$4$ GiB/分钟（如上计算）。\n    耗尽空闲内存的时间是总空闲内存除以消耗速率。\n    $$ \\text{时间} = \\frac{\\text{初始空闲内存}}{\\text{总泄漏率}} = \\frac{100 \\text{ GiB}}{4 \\text{ GiB/分钟}} = 25 \\text{ 分钟} $$\n    在 $25$ 分钟时，节点 $0$ 将耗尽其空闲内存。在实验 $2$ 中，这正是 `MPOL_PREFERRED` 策略导致内核开始回退到节点 $1$ 进行新分配的时刻。计算是正确的。\n*   **结论：正确**\n\n**D. 在实验 1 中，Linux 的内存不足（OOM）杀手会终止两个节点上的工作进程，因为 OOM 决策总是系统范围的，并且会忽略内存控制组和允许的节点集。**\n\n*   **分析：** 这个陈述从根本上是错误的。它歪曲了内存控制组（`memcg`）的目的和功能。`memcg` 的一个关键特性是实现按组进行内存核算和限制执行。当一个 cgroup 的内存限制被突破时，它会触发一个特定于 `memcg` 的 OOM 事件。OOM killer 随后只会在那个违规的 cgroup 内的进程上被调用。“OOM 决策总是系统范围的”这一说法是错误的；`memcg` OOM 事件在设计上是局部化的。因此，节点 $1$ 上的工作进程不在节点 $0$ 工作进程的 `memcg` 中，它们完全不会受到 OOM 事件的影响。\n*   **结论：不正确**\n\n**E. 在实验 2 中，可以保证节点 1 的工作进程在远程溢出期间不会出现吞吐量下降，因为它们的页面保持在本地；跨节点流量不会与节点 1 的内存控制器或互连设备产生竞争。**\n\n*   **分析：** 这个陈述是错误的。它对 NUMA 硬件的性质做出了错误的断言。连接节点 $0$ 和节点 $1$ 的 NUMA 互连是一个共享资源。节点 $1$ 上的内存控制器也是一个共享资源。当节点 $0$ 的 CPU 开始访问物理上位于节点 $1$ 上的内存（即“远程溢出”）时，这些流量必须穿越互连并由节点 $1$ 的内存控制器提供服务。这会产生竞争。来自节点 $1$ 工作进程的本地内存请求必须与来自节点 $0$ 工作进程的远程内存请求竞争访问节点 $1$ 的内存控制器和互连带宽。这种竞争将增加节点 $1$ 工作进程的有效内存延迟，可能导致性能和吞吐量下降。“保证”这个词使该陈述绝对错误，因为任何程度的竞争都违反了这一保证。\n*   **结论：不正确**", "answer": "$$\\boxed{ABC}$$", "id": "3663644"}]}