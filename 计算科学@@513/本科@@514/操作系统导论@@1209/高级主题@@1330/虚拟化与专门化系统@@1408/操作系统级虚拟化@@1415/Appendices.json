{"hands_on_practices": [{"introduction": "操作系统级虚拟化的核心优势之一是能够精确控制和分配资源。对于计算密集型任务，CPU资源的管理至关重要。这个练习 [@problem_id:3665364] 将带你深入了解Linux完全公平调度器（CFS）的权重机制，通过从基本原理出发进行推导，你将掌握如何将抽象的CPU份额（shares）转化为容器实际获得的处理器时间比例，从而深刻理解容器环境中资源公平分配的数学基础。", "problem": "您正在一台恰好提供 $1$ 个中央处理器 (CPU) 容量的主机上配置操作系统级虚拟化和 Linux 控制组 (cgroups)。现有 $k$ 个容器，每个容器都有一个单一的、始终可运行的、CPU 密集型进程，并被分配了控制组 CPU 份额 $w_1, w_2, \\dots, w_k$，其中每个 $w_i \\in \\mathbb{R}_{>0}$。该主机使用 Linux 完全公平调度器 (CFS)。请仅使用以下关于带 cgroup 份额的 CFS 的基本事实作为您的出发点：\n- 每个可运行实体（此处指每个容器的可调度实体）都维护一个虚拟运行时间 $v_i$。当实体 $i$ 运行一段实际时间 $\\Delta t$ 时，其虚拟运行时间增加的量与 $\\Delta t$ 成正比，与其权重 $w_i$ 成反比，因此当 $i$ 运行时，瞬时速率满足 $\\frac{dv_i}{dt} \\propto \\frac{1}{w_i}$；当它不运行时，$\\frac{dv_i}{dt} = 0$。\n- 调度器总是选择 $v_i$ 最小的实体来下一次运行，并随着时间的推移，试图使所有可运行实体的 $v_i$ 保持均等。\n假设在稳态下总需求严格超过容量（即所有 $k$ 个实体始终保持可运行状态），因此 CPU 被完全利用。在任何可运行实体集合不发生变化的期间内，设 $f_i$ 表示分配给容器 $i$ 的 CPU 时间的期望分数，因此 $f_i \\in (0,1)$ 且 $\\sum_{i=1}^{k} f_i = 1$。\n\n任务：\n1. 从上述两个事实出发，且不使用其他任何信息，推导出 $f_i$ 关于 $w_1, \\dots, w_k$ 的稳态表达式。\n2. 将您的最终结果表示为向量 $\\mathbf{f} = (f_1, f_2, \\dots, f_k)$ 的闭式解析表达式，以单个 CPU 的无量纲分数表示。无需进行数值代入。\n3. 简要讨论（评分时无需计算）：在这个不考虑最小粒度效应的理想化模型中，论证对于任何 $w_i > 0$ 的容器是否会发生饥饿，并给出一个关于容器 $i$ 两次运行之间的最大时间间隔的界限（用长度为 $L > 0$ 的公平性窗口表示）。\n\n仅提供 $\\mathbf{f}$ 的表达式作为最终答案。由于您的答案是符号化的，因此不需要四舍五入。如要求，分数是无量纲的。", "solution": "问题陈述已经过验证，被认为是有效的。它在科学上基于操作系统调度器的原理，特别是一个理想化的 Linux 完全公平调度器 (CFS) 模型。该问题是适定的、客观的、自洽的且可形式化的，允许对所需表达式进行严格的推导。\n\n### 第 1 部分：稳态 CPU 分数 $f_i$ 的推导\n\n问题提供了两个支配调度器行为的基本事实。我们将只使用这两个事实来推导分配给容器 $i$ 的 CPU 时间分数 $f_i$ 的表达式。\n\n已知条件如下：\n- 单个 CPU，因此总容量为 $1$。\n- $k$ 个容器，其 CPU 份额为 $w_1, w_2, \\dots, w_k$，其中每个 $w_i \\in \\mathbb{R}_{>0}$。\n- 所有 $k$ 个容器始终可运行。\n- CPU 时间被完全利用，因此 $\\sum_{i=1}^{k} f_i = 1$。\n- 事实 1：对于一个正在运行的容器 $i$，其虚拟运行时间 $v_i$ 的变化率是 $\\frac{dv_i}{dt} \\propto \\frac{1}{w_i}$。设 $c$ 为正常数比例常数。因此，当容器 $i$ 运行时，其虚拟运行时间以 $\\frac{dv_i}{dt} = \\frac{c}{w_i}$ 的速率增加。当它不运行时，$\\frac{dv_i}{dt} = 0$。\n- 事实 2：调度器总是选择虚拟运行时间 $v_i$ 最小的可运行实体，并随着时间的推移，旨在为所有可运行实体 $i, j$ 维持 $v_i \\approx v_j$。\n\n在一个足够长的时间间隔 $T$ 内观察的稳态系统中，调度器为使所有虚拟运行时间均等的努力意味着每个容器累积的总虚拟运行时间 $\\Delta v_i$ 必须是相同的。\n$$ \\Delta v_1 = \\Delta v_2 = \\dots = \\Delta v_k $$\n\n设 $T_i$ 为在此时间间隔 $T$ 内容器 $i$ 运行的实际 CPU 总时间。容器 $i$ 的 CPU 时间分数定义为 $f_i$。在我们考虑的时间间隔 $T$ 的背景下，这意味着 $f_i = \\frac{T_i}{T}$，或 $T_i = f_i T$。由于 CPU 始终繁忙，所有容器的运行时间之和必须等于该时间间隔的总持续时间：\n$$ \\sum_{i=1}^{k} T_i = T $$\n\n容器 $i$ 累积的虚拟运行时间 $\\Delta v_i$ 是其变化率在时间间隔 $T$ 上的积分。由于容器不运行时该速率为零，我们只需考虑它以恒定速率 $\\frac{c}{w_i}$ 运行的总时间 $T_i$。\n$$ \\Delta v_i = \\left( \\frac{c}{w_i} \\right) T_i $$\n\n使用所有累积的总虚拟运行时间相等的稳态条件，我们可以将任意两个容器 $i$ 和 $j$ 的表达式相等：\n$$ \\Delta v_i = \\Delta v_j $$\n$$ \\left( \\frac{c}{w_i} \\right) T_i = \\left( \\frac{c}{w_j} \\right) T_j $$\n\n由于 $c > 0$，我们可以除以 $c$ 得到：\n$$ \\frac{T_i}{w_i} = \\frac{T_j}{w_j} $$\n这表明总运行时间与权重的比率对所有容器都是一个常数。我们用 $K_T$ 表示这个常数。\n$$ \\frac{T_i}{w_i} = K_T \\implies T_i = K_T w_i $$\n\n现在，我们使用 CPU 被完全利用的约束。我们将 $T_i$ 的表达式代入求和式中：\n$$ \\sum_{i=1}^{k} (K_T w_i) = T $$\n$$ K_T \\sum_{i=1}^{k} w_i = T $$\n\n我们可以解出比例常数 $K_T$：\n$$ K_T = \\frac{T}{\\sum_{j=1}^{k} w_j} $$\n请注意，由于所有 $w_j > 0$，分母 $\\sum_{j=1}^{k} w_j$ 严格为正。\n\n现在我们将 $K_T$ 的这个表达式代回 $T_i$ 的方程中：\n$$ T_i = \\left( \\frac{T}{\\sum_{j=1}^{k} w_j} \\right) w_i $$\n\n最后，我们通过将 $T_i$ 除以 $T$ 来求得 CPU 时间的分数 $f_i$：\n$$ f_i = \\frac{T_i}{T} = \\frac{1}{T} \\left( \\frac{T w_i}{\\sum_{j=1}^{k} w_j} \\right) = \\frac{w_i}{\\sum_{j=1}^{k} w_j} $$\n这就是分配给容器 $i$ 的 CPU 时间的稳态表达式。\n\n### 第 2 部分：$\\mathbf{f}$ 的向量表达式\n\n问题要求将结果表示为向量 $\\mathbf{f} = (f_1, f_2, \\dots, f_k)$。使用推导出的每个分量 $f_i$ 的表达式，我们得到：\n$$ \\mathbf{f} = \\left( \\frac{w_1}{\\sum_{j=1}^{k} w_j}, \\frac{w_2}{\\sum_{j=1}^{k} w_j}, \\dots, \\frac{w_k}{\\sum_{j=1}^{k} w_j} \\right) $$\n\n### 第 3 部分：关于饥饿和运行间隔的讨论\n\n**饥饿：** 在这个理想化的模型中，任何分配了权重 $w_i > 0$ 的容器 $i$ 都不会发生饥饿。调度器的核心原则是始终运行虚拟运行时间 $v_i$ 最小的实体。当任何其他容器 $j \\neq i$ 运行时，其虚拟运行时间 $v_j$ 增加，而 $v_i$ 保持不变。最终，所有其他正在运行的容器的虚拟运行时间将超过 $v_i$。届时，容器 $i$ 在所有可运行实体中将具有最小的虚拟运行时间，调度器将被迫选择它来执行。因为 $w_i > 0$，所以 $v_i$ 的增加速率是有限的，确保它不会无限期地保持最小。这种机制保证了每个可运行的容器最终都会被调度。\n\n**运行间隔的界限：** 容器 $i$ 连续两次执行之间的最大时间可以用一个长度为 $L > 0$ 的理想化公平性窗口来推断。在这样一个窗口中，容器 $i$ 获得的总运行时间为 $f_i L$。对容器 $i$ 来说，最坏的情况发生在它刚运行完毕时，此时它的虚拟运行时间相对于其他容器是最大的。然后它必须等待其他 $k-1$ 个容器运行足够长的时间，以使其中一个容器的虚拟运行时间超过它自己的，或者更简单地说，等待它自己的虚拟运行时间再次变为最小。对此等待时间的一个宽松但直观的上限是，所有其他容器在公平性窗口 $L$ 内获得其成比例的 CPU 份额所需的时间。这个时间是所有其他容器份额的总和，即 $(1 - f_i)L$。代入推导出的 $f_i$ 表达式，这个最大等待时间的界限为：\n$$ L \\left(1 - \\frac{w_i}{\\sum_{j=1}^{k} w_j}\\right) = L \\frac{\\sum_{j \\neq i} w_j}{\\sum_{j=1}^{k} w_j} $$\n在真实的 CFS 实现中，这个周期 $L$ 与 `sched_latency` 参数相关，该参数定义了每个可运行任务至少应运行一次的目标时间段。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{w_1}{\\sum_{j=1}^{k} w_j}  \\frac{w_2}{\\sum_{j=1}^{k} w_j}  \\dots  \\frac{w_k}{\\sum_{j=1}^{k} w_j}\n\\end{pmatrix}\n}\n$$", "id": "3665364"}, {"introduction": "除了CPU，内存是另一个需要严格管理的共享资源。然而，容器的内存管理并非简单地设置一个上限。这个练习 [@problem_id:3665429] 探讨了一个更微妙的场景：当多个容器访问同一文件时，它们如何与宿主机的共享页面缓存（page cache）进行交互。通过分析内存的归属和记账方式，你将学会辨析容器隔离与资源共享之间的复杂关系，这对于设计高效且可预测的应用程序至关重要。", "problem": "两个 Linux 容器 $C_1$ 和 $C_2$ 在同一个主机内核上运行，并使用 Linux 控制组版本 2 (cgroups v2)。两个容器都对主机上一个大小为 $S = 2\\,\\text{GiB}$ 的大型只读文件进行了绑定挂载，并且都执行顺序缓冲读取（例如，在循环中使用系统调用 $\\text{read}()$），直到文件末尾。内核页面大小为 $p = 4\\,\\text{KiB}$。每个容器的内存控制器配置如下：对于 $C_1$，$\\text{memory.high} = 600\\,\\text{MiB}$ 且 $\\text{memory.max} = 1\\,\\text{GiB}$；对于 $C_2$，$\\text{memory.high} = 400\\,\\text{MiB}$ 且 $\\text{memory.max} = 512\\,\\text{MiB}$。假设该文件最初不在页面缓存中。\n\n使用以下基本依据来推断页面缓存共享和内存记账行为：\n\n- 定义：在所有容器共享的单体内核中，页面缓存以元组 $(\\text{inode}, \\text{offset})$ 为键。对于任何给定的 $(\\text{inode}, \\text{offset})$，在主机内核的页面缓存中最多只存在一个缓存页面。\n- 事实：在 cgroups v2 下，内存控制器将页面缓存页面的内存开销记在最先实例化它们的内存控制组（表示为 $\\text{memcg}$）的账上（例如，在第一次发生缺页或通过预读将页面填入缓存时）。其他 $\\text{memcg}$ 组中的任务后续访问会重用该缓存页面而不会复制它；页面的记账所有者仍然是最初的那个 $\\text{memcg}$。\n- 事实：$\\text{memory.high}$ 是一个软限制。当一个 $\\text{memcg}$ 的使用量超过 $\\text{memory.high}$ 时，内核会尝试回收内存并应用成比例的节流（延迟进一步的内存记账），而不是立即终止进程；仅超过 $\\text{memory.high}$ 本身并不保证会发生内存不足（Out-Of-Memory）终止。\n- 事实：$\\text{memory.max}$ 是一个硬限制。如果一笔新的内存记账将导致使用量超过 $\\text{memory.max}$，内核会首先尝试在该 $\\text{memcg}$ 内部回收内存；如果无法回收足够的内存，该记账操作将失败，并且内核可能会在该 $\\text{memcg}$ 内触发内存不足（Out-Of-Memory）终止。\n\n假设是典型的顺序缓冲 I/O，内核会执行预读，并能回收读取光标之后的干净页面缓存页面。设 $n = S / p$ 为文件总页面数，设 $w$ 表示在流式读取文件时记入某个 $\\text{memcg}$ 的文件页面近似稳态数量（即工作集，由预读和流水线深度决定），在正常情况下 $w \\ll n$。\n\n在此场景下，以下哪些陈述是正确的？\n\nA. 主机页面缓存对每个 $(\\text{inode}, \\text{offset})$ 页面仅存储一次，因此 $C_1$ 和 $C_2$ 重用相同的缓存页面；容器边界不会导致对相同文件内容产生重复的缓存页面。\n\nB. 每个容器维护其自己独立的页面缓存命名空间，因此从两个容器中读取相同文件会复制缓存，并大致使主机上用于这些页面的内存使用量翻倍。\n\nC. 如果 $C_1$ 首先读取并填充了缓存，那么当 $C_2$ 随后读取相同文件时，$C_2$ 的 $\\text{memory.current}$ 不会因已缓存页面的大小而增加，因为这些页面仍然记账在 $C_1$ 上。\n\nD. 如果一个容器的 $\\text{memcg}$ 使用量超过 $\\text{memory.high}$，内核会立即在该 $\\text{memcg}$ 内执行内存不足终止；相反，超过 $\\text{memory.max}$ 只会引起节流而不会终止。\n\nE. 因为 $S = 2\\,\\text{GiB}$ 而 $C_1$ 的 $\\text{memory.max} = 1\\,\\text{GiB}$，$C_1$ 将不可避免地无法完成文件读取：页面缓存必须同时持有所有 $n$ 个页面，而硬限制阻止了这一点。\n\nF. 如果在 $C_1$ 填充了页面缓存之后 $C_2$ 再读取该文件，$C_2$ 可以以接近全速的速度进行，而不会因其 $\\text{memory.high}$ 而被节流，前提是 $C_2$ 除了微小的瞬时内核开销外，不执行任何会记账到 $C_2$ 的额外内存分配。\n\n选择所有适用的选项。", "solution": "问题陈述在内部是一致的，科学上基于 Linux 内核的内存管理和控制组（cgroups v2）的原理，并且定义良好。所提供的定义和事实准确地描述了系统行为，数值也是现实的。因此，该问题是有效的，我们可以继续进行分析。\n\n控制此场景的核心原则如下：\n1.  **统一的页面缓存**：主机上的 Linux 内核维护一个单一的、全局的页面缓存。任何文件的任何页面都由其 inode 和文件内偏移量唯一标识，表示为元组 $(\\text{inode}, \\text{offset})$。无论有多少进程或容器访问它，一个给定的页面在此缓存中最多只存在一次。\n2.  **Cgroups v2 内存记账**：当一个文件页面首次从磁盘读取并填充到页面缓存中时，其内存成本被“记账”到触发该读取操作的进程所属的内存控制组（$\\text{memcg}$）上。该 $\\text{memcg}$ 的 `memory.current` 计数器会增加。如果来自不同 $\\text{memcg}$ 的进程稍后访问同一页面，它会重用已存在的缓存页面，并且不会产生新的记账。内存记账仍然归属于最初的那个 $\\text{memcg}$。\n3.  **流式 I/O**：对大文件的顺序读取不需要整个文件都驻留在内存中。内核在一个页面的“窗口”内读取数据，采用预读来获取即将到来的页面，并回收不再需要的旧页面（即那些在当前读取位置“之后”的页面）。因此，用于文件数据的并发内存使用量，表示为 $w$，通常远小于总文件大小 $S$（即 $w \\ll n$，其中 $n=S/p$）。\n4.  **内存限制**：对于给定的 $\\text{memcg}$，$\\text{memory.high}$ 是一个软限制，超过该限制会触发内存回收和节流。$\\text{memory.max}$ 是一个硬限制；任何试图分配内存并将使用量推高到超过此限制的尝试都将失败，并可能导致内存不足（OOM）终止。\n\n基于这些原则，我们评估每个陈述。\n\n**A. 主机页面缓存对每个 $(\\text{inode}, \\text{offset})$ 页面仅存储一次，因此 $C_1$ 和 $C_2$ 重用相同的缓存页面；容器边界不会导致对相同文件内容产生重复的缓存页面。**\n\n这个陈述是 Linux 页面缓存基本设计的直接结果。问题的“定义”部分明确指出：“在所有容器共享的单体内核中，页面缓存以元组 $(\\text{inode}, \\text{offset})$ 为键。对于任何给定的 $(\\text{inode}, \\text{offset})$，最多只存在一个缓存页面...”。容器 $C_1$ 和 $C_2$ 在同一个内核上运行并访问同一个文件（相同的 inode）。因此，它们在主机内核的页面缓存中共享每个文件页面的单一实例。容器化隔离了许多资源，但页面缓存是统一的，以最大化内存效率。\n\n**结论：正确**\n\n**B. 每个容器维护其自己独立的页面缓存命名空间，因此从两个容器中读取相同文件会复制缓存，并大致使主机上用于这些页面的内存使用量翻倍。**\n\n这个陈述与统一页面缓存的原则相矛盾。如在对 A 的分析中所确立的，Linux 不会为每个容器创建独立的页面缓存。这样做会抵消内存管理的一个主要好处：共享相同数据以节约物理内存。该陈述描述的行为对于 Linux 容器来说是根本上不正确的。\n\n**结论：错误**\n\n**C. 如果 $C_1$ 首先读取并填充了缓存，那么当 $C_2$ 随后读取相同文件时，$C_2$ 的 $\\text{memory.current}$ 不会因已缓存页面的大小而增加，因为这些页面仍然记账在 $C_1$ 上。**\n\n这个陈述准确地描述了 cgroups v2 对页面缓存的内存记账规则。问题的“事实”部分指出：“在 cgroups v2 下，内存控制器将页面缓存页面的内存开销记在最先实例化它们的内存控制组（$\\text{memcg}$）的账上... 页面的记账所有者仍然是最初的那个 $\\text{memcg}$。”由于 $C_1$ 首先读取文件，其 $\\text{memcg}$ 因填充页面而被记账。当 $C_2$ 随后读取文件时，它会在缓存中找到这些页面并重用它们。这些页面的内存费用不会转移到 $C_2$ 的 $\\text{memcg}$，因此 $C_2$ 的 `memory.current` 使用量不会因为访问这些预先存在的缓存数据而增加。\n\n**结论：正确**\n\n**D. 如果一个容器的 $\\text{memcg}$ 使用量超过 $\\text{memory.high}$，内核会立即在该 $\\text{memcg}$ 内执行内存不足终止；相反，超过 $\\text{memory.max}$ 只会引起节流而不会终止。**\n\n这个陈述错误地颠倒了 $\\text{memory.high}$ 和 $\\text{memory.max}$ 的功能。问题的“事实”部分清楚地定义了它们的作用：\n- $\\text{memory.high}$：一个软限制。超过它会导致节流和回收，而不是 OOM 终止。\n- $\\text{memory.max}$：一个硬限制。如果回收不足，超过它可能触发 OOM 终止。\n这个陈述声称 `high` 会导致终止而 `max` 只会导致节流，这与它们的实际行为正好相反。\n\n**结论：错误**\n\n**E. 因为 $S = 2\\,\\text{GiB}$ 而 $C_1$ 的 $\\text{memory.max} = 1\\,\\text{GiB}$，$C_1$ 将不可避免地无法完成文件读取：页面缓存必须同时持有所有 $n$ 个页面，而硬限制阻止了这一点。**\n\n这个陈述基于一个错误的前提，即读取文件需要同时将整个文件保留在内存中。问题描述的是“顺序缓冲读取”，这意味着一个流式操作。内核在缓存中维护一个移动的页面窗口，其大小为 $w$，其中 $w$ 是工作集大小。问题正确地指出，对于这样的工作负载，$w \\ll n$。只要这个窗口的内存（$w \\times p$）加上容器使用的任何其他内存保持在 $1\\,\\text{GiB}$ 的 $\\text{memory.max}$ 限制以下，读取就会继续进行。一个典型的预读窗口大小在兆字节（MB）量级，远低于 $1\\,\\text{GiB}$ 的限制。因此，$C_1$ 可以成功地流式读取 $2\\,\\text{GiB}$ 的文件而不会超过其硬限制。\n\n**结论：错误**\n\n**F. 如果在 $C_1$ 填充了页面缓存之后 $C_2$ 再读取该文件，$C_2$ 可以以接近全速的速度进行，而不会因其 $\\text{memory.high}$ 而被节流，前提是 $C_2$ 除了微小的瞬时内核开销外，不执行任何会记账到 $C_2$ 的额外内存分配。**\n\n这个陈述是陈述 A 和 C 的逻辑推论。由于 $C_1$ 已经填充了页面缓存，$C_2$ 的读取请求将从内存中得到服务（缓存命中），这速度极快（“接近全速”）。此外，如在 C 中所确立的，这些页面的内存仍然记账在 $C_1$ 上。因此，$C_2$ 的 `memory.current` 不会因为读取文件而显著增加。由于其内存使用量保持在较低水平，它不会接近其 $400\\,\\text{MiB}$ 的 $\\text{memory.high}$ 限制。结果，$C_2$ 将不会受到与超过 $\\text{memory.high}$ 相关的、由内存压力引起的节流。\n\n**结论：正确**", "answer": "$$\\boxed{ACF}$$", "id": "3665429"}, {"introduction": "有效的隔离不仅在于限制“多少”资源可用，更在于控制容器“能做什么”。系统调用（system call）是应用程序与内核交互的最终边界，也是安全策略实施的关键点。此练习 [@problem_id:3665412] 模拟了一个常见的兼容性挑战，即现代应用程序运行在较旧的内核上，并通过安全计算模式（seccomp）进行限制。通过这个思想实验，你将理解`seccomp`如何与C库（glibc）的备用机制协同工作，从而在不牺牲安全性的前提下解决兼容性问题。", "problem": "一个容器化应用程序是基于 GNU C 库 (glibc) 2.36 的一个新近版本构建的，并使用了较新的 Linux 系统调用，例如 `openat2` 和 `pidfd_open`。该容器运行在一个 x86_64 主机上，其 Linux 内核版本为 5.4，该内核版本并未实现那些新的系统调用。容器运行时应用了一个默认的安全计算模式 (`seccomp`) 配置文件，其对于任何未列出的系统调用的默认操作是向调用者返回一个错误（即，过滤器使用的操作等同于“返回错误”，而不是“允许”或“杀死”）。假设该过滤器明确拒绝了 `openat2` 和 `pidfd_open`，并允许一个常规的基线调用集，如 `openat`、`fstat`、`mmap`、`mprotect`、`futex` 和 `rt_sigaction`。\n\n从基本原理出发，考虑以下事实：\n\n- 在操作系统级虚拟化中，容器内的进程共享宿主机的内核及其系统调用应用程序二进制接口 (ABI)。不存在独立的容器内核。\n- 系统调用是一次从用户空间通过定义良好的系统调用 ABI 对内核的调用。如果内核没有实现所请求的系统调用，内核会返回 -1 并将全局错误指示符 `errno` 设置为 `ENOSYS`（功能未实现）。如果内核因沙箱（通过 `seccomp`）而拒绝一个调用，内核会返回 -1 并根据过滤器选择的错误操作来设置 `errno`（通常是 `EPERM`，表示操作不允许），或者根据所选操作可能会传递一个信号。\n- GNU C 库 (glibc) 为系统调用提供包装器，并且在检测到 `ENOSYS`（表示缺少实现）时，可能会尝试回退到更旧、被广泛实现的系统调用序列。当错误是 `EPERM`（表示权限失败）时，它不会执行此类回退，因为 `EPERM` 表示策略拒绝，而非实现缺失。\n\n预测当应用程序在此主机上，在所述的 `seccomp` 配置文件下尝试使用 `openat2` 时的行为，并选择一个既能正确解释结果，又能推荐一个安全的配置文件调整方案的选项，该方案能在保持沙箱的同时实现兼容性。\n\nA. 由于容器共享主机内核，在 Linux 5.4 上，当 `seccomp` 的默认“返回错误”操作将 `errno` 设置为 `EPERM` 时，`openat2` 将返回 -1 且 `errno` 为 `EPERM`，glibc 不会回退。一个安全的兼容性修正是将针对较新系统调用（如 `openat2` 和 `pidfd_open`）的 `seccomp` 操作更改为“返回 `ENOSYS`”，并明确允许较旧的等效调用（例如，回退所需的 `openat` 及相关调用），同时对真正有风险的调用保持限制性操作。\n\nB. 容器拥有独立于主机的内核，因此 glibc 2.36 将看到正确的实现，并且 `seccomp` 配置文件对 `openat2` 没有影响；调用会成功。不需要更改配置文件。\n\nC. glibc 在调用失败时总是会回退，包括在遇到 `EPERM` 时，因此拒绝 `openat2` 是无害的。正确的安全配置文件是继续为 `openat2` 和 `pidfd_open` 返回 `EPERM`，而不允许任何较旧的等效调用。\n\nD. 通过 `seccomp` 拒绝 `openat2` 将会传递 `SIGSYS` 信号，glibc 会自动捕获该信号并用 `openat` 进行模拟，因此不需要特定的允许列表更改；最安全的配置文件是捕获所有新调用，并依赖 glibc 在用户空间中模拟它们。\n\n选择唯一的最佳选项。", "solution": "用户希望我扮演一位严谨的 STEM 教授，验证所提供的问题陈述，然后解决它。\n\n### 问题验证\n\n首先，我将根据指定标准验证问题陈述。\n\n**第 1 步：提取已知条件**\n\n问题陈述提供了以下信息：\n*   应用程序是基于 GNU C 库 (glibc) 2.36 版本构建的。\n*   应用程序使用了较新的 Linux 系统调用：`openat2` 和 `pidfd_open`。\n*   托管该应用程序的容器运行在 Linux 内核版本为 5.4 的 `x86_64` 主机上。\n*   主机内核（版本 5.4）未实现系统调用 `openat2` 和 `pidfd_open`。\n*   容器运行时使用了一个安全计算模式 (`seccomp`) 配置文件。\n*   `seccomp` 配置文件对非白名单系统调用的默认操作是返回一个错误。\n*   `seccomp` 过滤器明确拒绝了 `openat2` 和 `pidfd_open`。\n*   `seccomp` 过滤器允许一个常规系统调用的基线集，包括 `openat`、`fstat`、`mmap`、`mprotect`、`futex` 和 `rt_sigaction`。\n\n问题还提供了三个基本原则：\n1.  操作系统级虚拟化（容器化）涉及共享主机内核及其系统调用应用程序二进制接口 (ABI)；不存在独立的容器内核。\n2.  一个未实现的系统调用会导致内核返回 -1，并将全局错误指示符 `errno` 设置为 `ENOSYS`。一个被 `seccomp` 过滤器以“返回错误”操作阻止的系统调用，会导致内核返回 -1，并根据过滤器的操作设置 `errno`（通常是 `EPERM`）。其他 `seccomp` 操作，如传递信号，也是可能的。\n3.  GNU C 库 (`glibc`) 在检测到 `errno` 为 `ENOSYS` 的系统调用失败时，可能会使用回退机制（例如，尝试更旧的系统调用）。当 `errno` 为 `EPERM` 时，它不会执行此类回退，因为这表示策略拒绝。\n\n**第 2 步：使用提取的已知条件进行验证**\n\n我现在将评估问题的有效性：\n\n*   **科学依据充分：** 该问题牢固地植根于操作系统原理，特别是 Linux 内核行为、系统调用接口、容器化和 `seccomp` 沙箱机制。所描述的 `glibc`、`seccomp` 和内核关于系统调用处理和错误码（`ENOSYS` vs. `EPERM`）的行为是事实正确的，并代表了一个真实的软件工程挑战。例如，`openat2` 是在 Linux 内核 5.6 中引入的，因此在内核 5.4 中确实不存在。`glibc` 关于系统调用回退的行为是该库一个有据可查的方面。\n*   **问题定义良好：** 该问题提供了一整套完整的条件和明确陈述的原则。问题要求预测行为并推荐一个安全的修复方案，可以从所提供的信息中推导出一个唯一的、合乎逻辑的解决方案。\n*   **客观性：** 该问题以精确、客观、技术性的语言陈述，没有歧义或主观论断。\n\n问题陈述没有表现出任何列出的缺陷（例如，科学上不健全、不完整、矛盾或模糊）。它描述了在容器化环境中遇到的一个标准且不简单的兼容性问题。\n\n**第 3 步：结论与行动**\n\n问题陈述是 **有效的**。我将继续进行解决方案的推导。\n\n### 解决方案推导\n\n分析过程通过追踪从应用程序到内核再返回的系统调用执行流来进行。\n\n1.  **应用程序调用与 `glibc` 包装器：** 链接到 `glibc` 2.36 版本的应用程序进行一个需要打开文件的库调用（例如 `open()`）。由于 `glibc` 2.36 是现代版本，其包装函数将尝试使用可用于此目的的功能最丰富的底层系统调用，即 `openat2`。\n2.  **系统调用：** `glibc` 包装器执行 `syscall` 指令，从用户模式转换到内核模式，请求 `openat2` 系统调用。\n3.  **内核侧 `seccomp` 拦截：** 根据原则 1 的规定，该系统调用被导向共享的主机内核。在内核的主系统调用分派器处理请求之前，与容器进程关联的 `seccomp-bpf` 过滤器会拦截该调用。\n4.  **`seccomp` 过滤器操作：** 问题陈述中指出 `seccomp` 配置文件以“返回错误”的操作明确拒绝了 `openat2`。正如原则 2 所解释的，此操作会指示内核立即终止系统调用处理，并向用户空间调用者返回一个错误。这种类型的拒绝所使用的典型 `errno` 值是 `EPERM`（操作不允许）。调用在此阶段被拒绝，永远不会到达内核检查 `openat2` 是否已实现的代码路径。因此，此时不会生成 `ENOSYS`。\n5.  **返回用户空间：** 内核将控制权返回给 `glibc` 包装函数。返回值为 -1，且 `errno` 被设置为 `EPERM`。\n6.  **`glibc` 回退逻辑：** `glibc` 包装函数检查 `errno` 值以决定其下一步操作。根据原则 3，`glibc` 区分 `ENOSYS`（此内核上未实现该功能）和 `EPERM`（操作被策略拒绝）。在看到 `EPERM` 后，`glibc` 推断这是一个安全限制，*不会* 尝试回退到像 `openat` 这样的旧系统调用。相反，它会保留 `EPERM` 错误并向应用程序返回 -1。\n7.  **结果：** 应用程序的文件打开操作因“操作不允许”错误而失败。除非应用程序经过专门编码以处理这种对于常见操作的意外 `EPERM` 错误，否则它很可能会出现故障或终止。\n\n### 建议的安全配置文件调整\n\n为了在保持最小权限原则的同时实现兼容性，必须调整 `seccomp` 配置文件。目标是让 `glibc` 的回退机制能够按预期工作。\n\n1.  问题在于 `EPERM` 错误码。要触发 `glibc` 回退，`seccomp` 过滤器应改为返回 `ENOSYS`。`seccomp` BPF 机制允许过滤器使用 `SECCOMP_RET_ERRNO` 操作返回特定的错误码。\n2.  应修改 `seccomp` 配置文件，将对 `openat2`（以及其他类似的新系统调用，如 `pidfd_open`）的操作从 `SECCOMP_RET_ERRNO | EPERM`（或其等效形式）更改为 `SECCOMP_RET_ERRNO | ENOSYS`。\n3.  通过此更改，当应用程序尝试调用 `openat2` 时，`seccomp` 过滤器将导致内核返回 -1，并将 `errno` 设置为 `ENOSYS`。\n4.  `glibc` 将看到 `ENOSYS`，并根据原则 3，正确推断出内核版本较旧。然后它会自动尝试回退到更旧的等效系统调用，例如 `openat`。\n5.  问题陈述中指出 `seccomp` 配置文件明确允许 `openat`，并且主机内核 5.4 实现了它。因此，回退调用将会成功。\n6.  这种方法是安全的，因为它维持了一个严格的允许系统调用白名单。它没有扩大攻击面；它只是为特定的、已知不存在的系统调用更改了拒绝信号，以启用 `glibc` 内部一个定义良好且安全兼容层，同时继续阻止真正危险或不需要的系统调用。\n\n### 逐项选项分析\n\n*   **A. 由于容器共享主机内核，在 Linux 5.4 上，当 `seccomp` 的默认“返回错误”操作将 `errno` 设置为 `EPERM` 时，`openat2` 将返回 -1 且 `errno` 为 `EPERM`，glibc 不会回退。一个安全的兼容性修正是将针对较新系统调用（如 `openat2` 和 `pidfd_open`）的 `seccomp` 操作更改为“返回 `ENOSYS`”，并明确允许较旧的等效调用（例如，回退所需的 `openat` 及相关调用），同时对真正有风险的调用保持限制性操作。**\n    这个选项正确地描述了整个事件序列：`seccomp` 过滤器返回 `EPERM`，这阻止了 `glibc` 的回退。然后，它正确地指出了标准的解决方案：将 `seccomp` 返回码更改为 `ENOSYS` 以触发 `glibc` 回退，同时确保回退目标系统调用（`openat`）在允许列表中。这保留了沙箱的安全态势。\n    **结论：正确。**\n\n*   **B. 容器拥有独立于主机的内核，因此 glibc 2.36 将看到正确的实现，并且 `seccomp` 配置文件对 `openat2` 没有影响；调用会成功。不需要更改配置文件。**\n    这个选项有根本性缺陷。它错误地描述了操作系统级虚拟化，声称容器有独立的内核。这与原则 1 以及容器的定义相矛盾。容器共享主机内核。\n    **结论：不正确。**\n\n*   **C. glibc 在调用失败时总是会回退，包括在遇到 `EPERM` 时，因此拒绝 `openat2` 是无害的。正确的安全配置文件是继续为 `openat2` 和 `pidfd_open` 返回 `EPERM`，而不允许任何较旧的等效调用。**\n    这个选项对 `glibc` 的行为做出了错误的声明。它与原则 3 相矛盾，原则 3 明确指出 `glibc` 在遇到 `EPERM` 错误时*不会*回退。因此，用 `EPERM` 拒绝 `openat2` 并非无害；它会破坏应用程序。\n    **结论：不正确。**\n\n*   **D. 通过 `seccomp` 拒绝 `openat2` 将会传递 `SIGSYS` 信号，glibc 会自动捕获该信号并用 `openat` 进行模拟，因此不需要特定的允许列表更改；最安全的配置文件是捕获所有新调用，并依赖 glibc 在用户空间中模拟它们。**\n    这个选项错误地假设 `seccomp` 的操作是 `trap`（会产生 `SIGSYS`），而问题描述的是一个返回错误码的操作。虽然 `seccomp` 可以配置为产生 `SIGSYS`，但这并非问题中所描述的情况。标准的“返回错误”操作映射到 `SECCOMP_RET_ERRNO`。针对这种情况，主要、最可靠且预期的 `glibc` 兼容性机制依赖于 `ENOSYS`，而不是信号捕获和模拟。\n    **结论：不正确。**", "answer": "$$\\boxed{A}$$", "id": "3665412"}]}